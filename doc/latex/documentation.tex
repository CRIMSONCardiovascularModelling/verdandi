% ========================================================================
%  Documentation Verdandi
%  D. Chapelle, K. Charpentier, M. Fragu, V. Mallet P. Moireau
%
%  Copyright (c) 2012 INRIA. All rights reserved.
% ========================================================================
\documentclass{tufte-book}

% ========================================================================
% Book metadata
% ========================================================================
\title{Verdandi}
\author[D. Chapelle, K. Charpentier, M. Fragu, V. Mallet, P. Moireau]{D. Chapelle, K. Charpentier, M. Fragu,\\ V. Mallet, P. Moireau,  C. Mouton}
\publisher{INRIA}

% ========================================================================
% Style
% ========================================================================
\usepackage[latin1]{inputenc}
\usepackage[english]{babel}

\usepackage[table]{xcolor}
\usepackage{hyperref}
\hypersetup{colorlinks=true}
\usepackage[normalem]{ulem}

\usepackage{url}

% Prints a trailing space in a smart way.
\usepackage{xspace}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{wasysym}
\usepackage[mathcal]{eucal}

\usepackage{latexsym}
\usepackage{stmaryrd}
\usepackage{makeidx}
\usepackage{ifthen}
\usepackage{url}

% Just some sample text
\usepackage{lipsum}

% Prints argument within hanging parentheses (i.e., parentheses that take
% up no horizontal space).  Useful in tabular environments.
\newcommand{\hangp}[1]{\makebox[0pt][r]{(}#1\makebox[0pt][l]{)}}

%%
% Prints an asterisk that takes up no horizontal space.
% Useful in tabular environments.
\newcommand{\hangstar}{\makebox[0pt][l]{*}}

% ========================================================================
% Format
% ========================================================================
\usepackage[final]{pdfpages}

% The fancyvrb package lets us customize the formatting of verbatim
% environments.  We use a slightly smaller font.
\usepackage{fancyvrb}
\fvset{fontsize=\normalsize}
% For nicely typeset tabular material
\usepackage{booktabs}

% ========================================================================
% Graphics
% ========================================================================
\usepackage{graphicx}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
\graphicspath{{graphics/}}
\graphicspath{{figure/}}
\usepackage{epstopdf}

\usepackage{tikz}
\usetikzlibrary{arrows,shapes}

% ========================================================================
% Doxygen
% ========================================================================
\usepackage{doxygen}

%%
% Some shortcuts for Tufte's book titles.  The lowercase commands will
% produce the initials of the book title in italics.  The all-caps commands
% will print out the full title of the book in italics.
\newcommand{\vdqi}{\textit{VDQI}\xspace}
\newcommand{\ei}{\textit{EI}\xspace}
\newcommand{\ve}{\textit{VE}\xspace}
\newcommand{\be}{\textit{BE}\xspace}
\newcommand{\VDQI}{\textit{The Visual Display of Quantitative Information}\xspace}
\newcommand{\EI}{\textit{Envisioning Information}\xspace}
\newcommand{\VE}{\textit{Visual Explanations}\xspace}
\newcommand{\BE}{\textit{Beautiful Evidence}\xspace}

\newcommand{\TL}{Tufte-\LaTeX\xspace}

% Prints the month name (e.g., January) and the year (e.g., 2008)
\newcommand{\monthyear}{%
  \ifcase\month\or January\or February\or March\or April\or May\or June\or
  July\or August\or September\or October\or November\or
  December\fi\space\number\year
}


% Prints an epigraph and speaker in sans serif, all-caps type.
\newcommand{\openepigraph}[2]{%
  %\sffamily\fontsize{14}{16}\selectfont
  \begin{fullwidth}
  \sffamily\large
  \begin{doublespace}
  \noindent\allcaps{#1}\\% epigraph
  \noindent\allcaps{#2}% author
  \end{doublespace}
  \end{fullwidth}
}

% Inserts a blank page
\newcommand{\blankpage}{\newpage\hbox{}\thispagestyle{empty}\newpage}

\usepackage{units}

% Typesets the font size, leading, and measure in the form of 10/12x26 pc.
\newcommand{\measure}[3]{#1/#2$\times$\unit[#3]{pc}}

% Macros for typesetting the documentation
\newcommand{\hlred}[1]{\textcolor{Maroon}{#1}}% prints in red
\newcommand{\hangleft}[1]{\makebox[0pt][r]{#1}}
\newcommand{\hairsp}{\hspace{1pt}}% hair space
\newcommand{\hquad}{\hskip0.5em\relax}% half quad space
\newcommand{\TODO}{\textcolor{red}{\bf TODO!}\xspace}
\newcommand{\ie}{\textit{i.\hairsp{}e.}\xspace}
\newcommand{\eg}{\textit{e.\hairsp{}g.}\xspace}
\newcommand{\na}{\quad--}% used in tables for N/A cells
\providecommand{\XeLaTeX}{X\lower.5ex\hbox{\kern-0.15em\reflectbox{E}}\kern-0.1em\LaTeX}
\newcommand{\tXeLaTeX}{\XeLaTeX\index{XeLaTeX@\protect\XeLaTeX}}
% \index{\texttt{\textbackslash xyz}@\hangleft{\texttt{\textbackslash}}\texttt{xyz}}
\newcommand{\tuftebs}{\symbol{'134}}% a backslash in tt type in OT1/T1
\newcommand{\doccmdnoindex}[2][]{\texttt{\tuftebs#2}}% command name -- adds backslash automatically (and doesn't add cmd to the index)
\newcommand{\doccmddef}[2][]{%
  \hlred{\texttt{\tuftebs#2}}\label{cmd:#2}%
  \ifthenelse{\isempty{#1}}%
    {% add the command to the index
      \index{#2 command@\protect\hangleft{\texttt{\tuftebs}}\texttt{#2}}% command name
    }%
    {% add the command and package to the index
      \index{#2 command@\protect\hangleft{\texttt{\tuftebs}}\texttt{#2} (\texttt{#1} package)}% command name
      \index{#1 package@\texttt{#1} package}\index{packages!#1@\texttt{#1}}% package name
    }%
}% command name -- adds backslash automatically
\newcommand{\doccmd}[2][]{%
  \texttt{\tuftebs#2}%
  \ifthenelse{\isempty{#1}}%
    {% add the command to the index
      \index{#2 command@\protect\hangleft{\texttt{\tuftebs}}\texttt{#2}}% command name
    }%
    {% add the command and package to the index
      \index{#2 command@\protect\hangleft{\texttt{\tuftebs}}\texttt{#2} (\texttt{#1} package)}% command name
      \index{#1 package@\texttt{#1} package}\index{packages!#1@\texttt{#1}}% package name
    }%
}% command name -- adds backslash automatically
\newcommand{\docopt}[1]{\ensuremath{\langle}\textrm{\textit{#1}}\ensuremath{\rangle}}% optional command argument
\newcommand{\docarg}[1]{\textrm{\textit{#1}}}% (required) command argument
\newenvironment{docspec}{\begin{quotation}\ttfamily\parskip0pt\parindent0pt\ignorespaces}{\end{quotation}}% command specification environment
\newcommand{\docenv}[1]{\texttt{#1}\index{#1 environment@\texttt{#1} environment}\index{environments!#1@\texttt{#1}}}% environment name
\newcommand{\docenvdef}[1]{\hlred{\texttt{#1}}\label{env:#1}\index{#1 environment@\texttt{#1} environment}\index{environments!#1@\texttt{#1}}}% environment name
\newcommand{\docpkg}[1]{\texttt{#1}\index{#1 package@\texttt{#1} package}\index{packages!#1@\texttt{#1}}}% package name
\newcommand{\doccls}[1]{\texttt{#1}}% document class name
\newcommand{\docclsopt}[1]{\texttt{#1}\index{#1 class option@\texttt{#1} class option}\index{class options!#1@\texttt{#1}}}% document class option name
\newcommand{\docclsoptdef}[1]{\hlred{\texttt{#1}}\label{clsopt:#1}\index{#1 class option@\texttt{#1} class option}\index{class options!#1@\texttt{#1}}}% document class option name defined
\newcommand{\docmsg}[2]{\bigskip\begin{fullwidth}\noindent\ttfamily#1\end{fullwidth}\medskip\par\noindent#2}
\newcommand{\docfilehook}[2]{\texttt{#1}\index{file hooks!#2}\index{#1@\texttt{#1}}}
\newcommand{\doccounter}[1]{\texttt{#1}\index{#1 counter@\texttt{#1} counter}}


% ========================================================================
% Listings %
% ========================================================================

\usepackage{textcomp}
% A useful package to print source code.
\usepackage{listings}

\definecolor{colKeys}{rgb}{0,0,1}
\definecolor{colIdentifier}{rgb}{0,0,0}
\definecolor{colComments}{rgb}{0,0.5,1}
\definecolor{colString}{rgb}{0.6,0.1,0.1}

\lstset{%configuration de listings
float=hbp,%
basicstyle=\ttfamily\small, %
%identifierstyle=\color{colIdentifier}, %
keywordstyle=\color{colKeys}, %
stringstyle=\color{colString}, %
commentstyle=\color{colComments}, %
columns=flexible, %
tabsize=2, %
extendedchars=true, %
showspaces=false, %
showstringspaces=false, %
numbers=left, %
numberstyle=\tiny, %
breaklines=true, %
breakautoindent=true, %
captionpos=b,%
xleftmargin=0.2cm
}

% My Bash environment.
\lstnewenvironment{bash}[1][-35pt]
{
  \lstset{language=bash,
    basicstyle=\scriptsize\ttfamily,
    keywordstyle=\color{ColorBashKeyWord},
    % stringstyle=\color{MyYellow},
    xleftmargin=#1
  }}{}

% My Bash environment with frame.
\lstnewenvironment{frame_bash}
{
  \lstset{%language=bash,
    basicstyle=\scriptsize\ttfamily\color{white},
    keywordstyle=\color{white},
    commentstyle=\color{white},
    columns=[l]flexible,
    moredelim=[is][\color{MyGreen}]{|:}{:|},
    moredelim=[is][\color{red}]{|*}{*|},
    moredelim=[is][\color{MyOrange}]{**}{**},
    moredelim=[is][\color{MyYellow}]{!*}{*!},
    moredelim=[is][\color{MyPurple}]{/*}{*/},
    moredelim=[is][\color{MyBlueGrey}]{/!}{!/},
    moredelim=[is][\color{MyPurple}]{|!}{!|},
    % xleftmargin=-5pt,
    % xrightmargin=-12pt,
    frame=trbl,
    backgroundcolor=\color{black}
  }}{}


  % My C++ environment with frame.
\lstnewenvironment{frame_cpp}
{
  \lstset{
   language=C++,                % the language of the code
  basicstyle=\footnotesize,           % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it's 1, each line
                                  % will be numbered
   }}{}


   % My Python environment with frame.
\lstnewenvironment{frame_python}
{
  \lstset{
   language=python,                % the language of the code
  basicstyle=\footnotesize,           % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it's 1, each line
                                  % will be numbered
   }}{}


    % My Lua environment with frame.
\lstnewenvironment{frame_lua}
{
  \lstset{
   language=Python,                % the language of the code
  basicstyle=\footnotesize,           % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it's 1, each line
                                  % will be numbered
  morecomment=[l]{\--},
   }}{}



 % My LISP environment with frame.
\lstnewenvironment{frame_lisp}
{
  \lstset{
   language=lisp,                % the language of the code
  basicstyle=\footnotesize,           % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it's 1, each line
                                  % will be numbered
   }}{}


% ========================================================================
% Some Commands
% ========================================================================
\usepackage{command-euHeart}

\newcounter{points}

\newcommand{\code}[1]{\texttt{#1}}
\renewcommand{\rule}[1]{\textsc{#1}}
\newcommand{\commentcs}[1]{\newline #1}
\newcommand{\commentf}[1]{#1}
\newcommand{\justification}[1]{\newline {\it Justification} --- #1}
\newcommand{\njustification}[1]{{\it Justification} --- #1}
\newcommand{\justificationf}[1]{#1}

\newenvironment{cenumerate}
{
  \begin{enumerate}\setcounter{enumi}{\value{points}}%
  }
  {
    \setcounter{points}{\value{enumi}}\end{enumerate}
}

% ========================================================================
% Table of Contents
% ========================================================================
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

% ========================================================================
% Document
% ========================================================================

\begin{document}


\maketitle

\tableofcontents

% ========================================================================
% Chapter Data assimilation principles}
% ========================================================================
\chapter{Data assimilation principles}

\section{Motivations and basic definitions}

In order to obtain some information --~as detailed as possible --~on a \emph{natural system}, such as in geophysics, or regarding the important subcategory of \emph{living systems} which constitute the objects of study in biology and medicine, the most straightforward strategy consists in obtaining \emph{measurements} on the system at hand. Note that we deliberately use the term measurement, related but not reduced to \emph{experiments}, to signify that it is not in general possible to design specific experiments allowing to determine all kinds of physical properties of the system --~as is done for instance for industrial systems. By contrast, natural systems induce drastic limitations in measurements, in that they generally must be ``taken as they are'', namely, observed in their current operating conditions, whether this is due to the practical impossibility of apprehending them comprehensively (e.g.~in geophysics), or to the undesirable character of any strong perturbation of the system (invasiveness in living systems).

Specializing now our discussion on living systems, abundant measurements are frequently at hand, in the form of clinical images and signals of various origins. Despite the diversity and rich information contents of these data, they are also inevitably limited in many respects. Beside considerations on sampling and noise, this holds in particular as regards:
\begin{itemize}
	\item their extent: for example only 2D measurements, or boundary information, may be available for a 3D system, or only part of the whole domain;
	\item their type: some quantities are never measured, such as internal stresses in a living tissue, or various physical constitutive parameters (stiffness, contractility, etc.).
\end{itemize}

Nevertheless, we may want to consider \emph{physical models} to describe and predict the behavior of these systems. Clearly, these models may be seen as providing some complementary information on the system. However, their predictivity requires the careful adjustment of many parameters --~in particular regarding the detailed geometry (anatomy), physical properties, boundary conditions and initial conditions needed in the model --~most of which being out of reach of the available measurements.

The purpose of \emph{data assimilation} is then to combine the information available from these two sources --~measurements on the one hand, and models and the other hand --~by seeking an adequate compromise between:
\begin{itemize}
	\item the discrepancy computed between simulations of the model and the corresponding measurements;
	\item the \emph{a priori} confidence in the model, since errors are also present in the measurements.
\end{itemize}
The desired output of this procedure is an estimation of the unknown quantities of interest, namely,
\begin{itemize}
	\item state variables (the ``trajectories'' of the system), and in particular their initial values at a given reference time;
	\item physical parameters which must be prescribed in the model equations.
\end{itemize}
In terms of clinical applications, the expected benefits are to assist and improve both \emph{diagnosis} and \emph{prognosis}:
\begin{itemize}
	\item diagnosis, by providing more complete information on the patient (spatially-distributed quantities, and various otherwise unreachable indicators), and with improved accuracy;
	\item prognosis, since once data assimilation has been performed the model can be more confidently used to predict natural or artificial evolutions of the system, for example to simulate the effect of various possible therapeutic strategies.
\end{itemize}

We will now introduce some basic notation necessary to discuss the fundamental principles of data assimilation. First of all, we consider physical models in the form of dynamical systems governed by equations of the type
\begin{equation}\label{eq:modelNotation}
	\dot{x} = \mathcal{M}(x,p,t).
\end{equation}
In this equation, $x$ denotes the so-called \emph{state variable}, namely, the physical quantity which the model aims at describing in its time-wise evolution --~hence, the time derivative in the left-hand side --~and also frequently spatial variations for distributed quantities. In this generic notation, the whole model is essentially summarized in the so-called \emph{dynamical operator} $\mathcal{M}$, which applies on the state variable itself, and may depend on time $t$ as well as on a set of physical parameters denoted by $p$. This operator may arise from various types of physical formulations, e.g.~in solid and fluid mechanics or electrophysiology. Mathematically speaking, it may take the form of partial differential equations (PDEs) or ordinary differential equations (ODEs, namely, only differentiated with respect to the time variable), or algebraic systems, in particular.

Clearly, in such model formulations we need to prescribe --~hence to estimate when unknown via the data assimilation procedure --~the initial condition $\mathcal{M}(0)$ and the parameter vector $p$. Typically, in the models considered the state variable may contain a large number of scalar coefficients --~typically $10^3$ to $10^7$ degrees of freedom in a continuum mechanics model --~whereas the size of the parameter vector is generally much more limited, and in practice we seldom have to estimate more than a few hundreds of parameter values. Once the initial condition and the parameter vector associated with \eqref{eq:modelNotation} are estimated, the model can be simulated in time, using appropriate numerical techniques.

Another important notation concerns the measurements, typically represented by an equation of the type
\begin{equation}\label{eq:measNotation}
	y = \mathcal{H}(x,t) + e^o,
\end{equation}
where $y$ denotes the actual data, $\mathcal{H}$ is the so-called \emph{observation operator}, and $e^o$ accounts for the error inherent to the measurement process, often called the \emph{noise}. Note that the quantity $y$ will frequently correspond to pre-processed --~not raw --~data, for example images processed with segmentation or optical flow techniques in order to extract some position, displacement or velocity information. We further emphasize that this equation also represents a model --~in this case of the measurements --~where modeling ingredients are embedded both in the expression of $\mathcal{H}$ and the characterization of $e^o$, which may be of probabilistic or deterministic nature.


\section{Fundamental principles}

We are now in a position to introduce some fundamental principles for data assimilation procedures. First of all, there are two main categories of methods: variational and sequential methods.

\subsection{Variational procedures}

In variational procedures, we consider a criterion to be minimized in order to achieve the above-mentioned compromise between simulation-measurements discrepancy and model confidence, see e.g.~\cite{Bensoussan71,Chavent10} and references therein. A typical criterion would read
\begin{equation}\label{eq:varCriterion}
	\mathcal{J}_T(\varstate_\state,\varstate_{\param}) = \int_0^T \|\observ-\obsOp(\state)\|_{\obsNoiseNorm}^2 \, dt + \|\varstate_\state\|_{(\initNoiseCov)^{-1}}^2 + \|\varstate_{\param}\|_{(\paramNoiseCov)^{-1}}^2,
\end{equation}
where $\|.\|_{\obsNoiseNorm}$, $\|.\|_{(\initNoiseCov)^{-1}}$ and $\|.\|_{(\paramNoiseCov)^{-1}}$ denote suitable norms for each quantity concerned, and associated with the matrices appearing as subscripts. In this criterion, $\state$ is constrained to satisfy the model equation \eqref{eq:modelNotation} starting from the initial condition $\state(0)=\state_0+\initNoise_\state$ and with parameter values given by $\param=\param_0+\initNoise_\param$. In order to perform this minimization, a classical strategy consists in computing the gradient of the criterion, which requires the simulation of the so-called \emph{adjoint model}. The adjoint model equation is an evolution system closely related to --~and inferred from, indeed --~the direct model equation \eqref{eq:modelNotation}, viz.
\begin{equation}\label{eq:adjointPb}
	\begin{cases}
	\dot{\adjoint}_\state + \frac{\partial \modelOp}{\partial \state}^\intercal \adjoint_\state = -\frac{\partial \obsOp}{\partial \state}^\intercal\obsNoiseNorm(\observ-\obsOp(\state)) \\
	\adjoint_\state(T) = 0 \\
	\dot{\adjoint}_{\param} + \frac{\partial \modelOp}{\partial \param}^\intercal\adjoint_\state= 0 \\
	\adjoint_{\param}(T) = 0
	\end{cases}
\end{equation}
These equations must be simulated backwards in time from the final time $T$ to the initial time in order to obtain the gradient value criterion expressed as
\[
	\begin{cases}
		\diff_{\varstate_\state}\mathcal{J} \cdot \delta \varstate_\state = {\varstate_\state}^\intercal (\initNoiseCov)^{-1} \delta \varstate_\state - \adjoint_\state(0)^\intercal \delta \varstate_\state\\
		\diff_{\varstate_{\param}}\mathcal{J} \cdot \delta \param = {\varstate_\param}^\intercal (\paramNoiseCov)^{-1} \delta \varstate_\param - \adjoint_{\param}(0)^\intercal \delta \varstate_\param,
	\end{cases}
\]
Hence, each gradient computation requires the forward simulation of the direct model and the backward simulation of the adjoint, and this must be repeated until convergence of the minimization algorithm. Figure \ref{fig:variat} illustrates this iterative procedure, and the fact that observability can be improved by considering a longer time window, hence, also more measurements. This type of variational procedure is also referred to as ``4DVar'' in the data assimilation community, while ``3DVar'' is used to refer to minimization estimation performed for static models, or for dynamic models at a given time (namely, without time integral).

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=.5\textwidth]{image/seqVSvaria.pdf}
\caption{Schematic of minimization iterations and Kalman filter tracking on a sliding time window (as seen via one single output)}
\label{fig:variat}
\end{center}
\end{figure}

Concerning the time discretization, it is classical to formulate an optimal discrete time minimization criterion and find its corresponding adjoint rather than discretizing directly \eqref{eq:adjointPb}. Hence, we consider a criterion of the form
\begin{equation}\label{eq:varCriterionTimeDisc}
	J_N(\varstate_\state,\varstate_{\param}) = \sum_{k=0}^N \|\observDof_k-\obsOpDof(\stateDof_k)\|_{\obsNoiseNormDof_k}^2 \,  + \|\varstateDof_\state\|_{(\initNoiseCovDof)^{-1}}^2 + \|\varstateDof_{\param}\|_{(\paramNoiseCovDof)^{-1}}^2,
\end{equation}
with for example $\obsNoiseNormDof_k = \Delta t \obsNoiseNormDof$.

\subsection{Sequential procedures}

By contrast, sequential procedures --~also often referred to as \emph{filtering} --~proceed by simulating equations closely resembling the direct model equations, with an additional correction term taking into account the discrepancy between the simulation and the actual measurements, namely $y-\mathcal{H}(x)$, quantity called the \emph{innovation}. For example when only the initial condition is unknown the filtering equation would be of the type
\begin{equation}\label{eq:filterNotation}
	\dot{\state^a} = \modelOp(\state^a,t) + K(\observ-\obsOp(\state^a)),
\end{equation}
where the operator $K$ --~frequently linear --~is called the \emph{filter}. The filtering equation simulation is then started from the candidate initial condition $X_0$, and the aim of the correction is to bring the simulated trajectory close to the target system, see Fig.~\ref{fig:variat}.

This type of strategy was made extremely popular by the Kalman theory, which formulated an optimal setting for deriving the filter operator, initially when the operators $A$ and $H$ are both linear. In this case, the Kalman equations read
\begin{equation}\label{eq:Kalman}
	\begin{cases}
		\dot{\state^a} = \modelOp\state^a + \Cov\obsOp^\intercal \obsNoiseNorm (\observ-\obsOp\state^a)\\
		\dot{\Cov} - \Cov\modelOp^\intercal - \modelOp\Cov + \Cov\obsOp^\intercal \obsNoiseNorm \obsOp\Cov = 0\\
		\Cov(0)=\initNoiseCov\\
		\state^a(0) = \stateAug_\diamond
	\end{cases}
\end{equation}
where $W$ and $P_0$ denote the  so-called covariance matrices of the measurement noise and initial condition uncertainty, respectively. We can see that the filter expression is based on the computation of the time-dependent covariance matrix $P$ which satisfies a Riccatti equation. In fact, in the linear case the variational and Kalman procedures can be shown to be exactly equivalent, and the minimizing direct and adjoint states ($X_\text{inf}$ and $p_\text{inf}$, respectively) are related to the Kalman filter by the identity \cite{Bensoussan71}
\[
	\stateAug_\infty = \state^a + \Cov \adjoint_\infty.
\]
This is also illustrated in Figure \ref{fig:variat} where we show that the Kalman estimation coincides with the minimizing solution at the end of the time window considered.

When nonlinearities are to be considered, various extensions are available, and in particular the Extended Kalman Filtering (EKF) approach, in which the linearized forms of the operators are used in the filter equation. However, in such a case the approach is no longer equivalent to the variational setting. Nevertheless, some alternative filter equations can be derived from the variational formulation, but the filter computation then requires solving a Hamilton-Jacobi-Bellman equation in a space which has the dimension of the state variable \cite{Moireau08}, which is in general not practical.

Note that, in practice, the Kalman (or EKF) approach itself is also quite limited as regards the size of the system which can be handled, since the covariance matrix $\Cov$ has the size of the state variable, and is a dense matrix, unlike the dynamical operators. In order to circumvent this limitation some alternative approaches must be considered.

Concerning time discretization, it is classical to formulate the optimal filter directly from the optimal time-discrete minimization criteria rather than discretizing directly \eqref{eq:Kalman}. Hence, after some quite tedious computations, we can formulate a prediction-correction scheme
\begin{subequations}\label{eq:KalmanDiscrete}
	\begin{enumerate}
	\item Prediction:
   \begin{align}
   	\begin{cases}
   		\hat{\stateDof}_{h+1}^f &= \modelOp_{h}(\stateDof_h^a) \\
   		\CovDof_{h+1}^f &= \frac{\partial \modelOpDof_{h}}{\partial \stateDof} \CovDof_{h}^a \frac{\partial \modelOpDof_{h}}{\partial \stateDof}^\intercal
   	\end{cases}
   \end{align}
	\item Correction:
   \begin{align}\label{eq:KalmanCorrection}
   	\begin{cases}
   		\CovDof_{h+1}^a &= \left(\frac{\partial \obsOpDof_{h+1}}{\partial \stateDof} ^\intercal\obsNoiseCovDof_{h+1}^{-1} \frac{\partial \obsOpDof_{h+1}}{\partial \stateDof} + (\CovDof_{h+1}^f)^{-1}\right)^{-1} \\
		\gainOpDof_{h+1} &= \CovDof_{h+1}^a \frac{\partial \obsOpDof_{h+1}}{\partial \stateDof}^\intercal \obsNoiseCovDof_{h+1}^{-1} \\
		\hat{\stateDof}_{h+1}^a  &= \hat{\stateDof}_{h+1}^f + \gainOpDof_{h+1}(\observDof_{h+1}- \obsOpDof_{h+1}(\hat{\stateDof}_{h+1}^f))
   	\end{cases}
   \end{align}
\end{enumerate}
\end{subequations}


For the sake of simplicity, we have introduced the Kalman filter in a deterministic context, but the probabilistic counterpart exists. In a linear framework the expressions are exactly the same, albeit with the additional interpretation
\begin{equation}\label{eq:proba}
	\begin{cases}
			\text{a priori mean: } \hat{\stateDof}_{h+1}^f = \E(\stateDof_{h+1}|\observDof_0,\ldots,\observDof_h),	\\
			\text{a priori covariance: }  \CovDof_{h+1}^f = \E\bigl((\stateDof_{h+1}-\hat{\stateDof}_{h+1}^f)(\stateDof_{h+1}-\hat{\stateDof}_{h+1}^f)^\intercal\bigr), \\
			\text{a posteriori mean: } \hat{\stateDof}_{h+1}^a = \E\bigl(\stateDof_{h+1}|\observDof_0,\ldots,\observDof_{h+1}\bigr), \\
			\text{a posteriori covariance: } \CovDof_{h+1}^a = \E((\stateDof_{h+1}-\hat{\stateDof}_{h+1}^a)(\stateDof_{h+1}-\hat{\stateDof}_{h+1}^a)^\intercal),
	\end{cases}
\end{equation}

This results extend to the non-linear context with the EKF \eqref{eq:KalmanDiscrete} but the identities \eqref{eq:proba} are then only approximate. To improve the quality of this approximation, the Unscented Kalman Filter has then been introduced \cite{Julier00}, based on the idea of substituting means and covariances by empirical quantities computed from sample points:
\begin{equation}\label{eq:probaEmpirical}
	\begin{cases}
			\hat{\stateDof}_{h+1}^f = \sum_{i=1}^d \alpha_i\stateDof_{h+1}^{[i]-},	\\
			\CovDof_{h+1}^f = \sum_{i=1}^d \alpha_i(\stateDof_{h+1}^{[i]-}-\hat{\stateDof}_{h+1}^f)(\stateDof_{h+1}^{[i]-}-\hat{\stateDof}_{h+1}^f)^\intercal, \\
			\hat{\stateDof}_{h+1}^a = \sum_{i=1}^d \alpha_i\stateDof_{h+1}^{[i]+}, \\
			\CovDof_{h+1}^a = \sum_{i=1}^d \alpha_i(\stateDof_{h+1}^{[i]+}-\hat{\stateDof}_{h+1}^a)(\stateDof_{h+1}^{[i]+}-\hat{\stateDof}_{h+1}^a)^\intercal,
	\end{cases}
\end{equation}
with $\sum_{i=1}^d \alpha_i = 1$.

In practice, the correction particles are sampled around the mean $\hat{\stateDof}_{h}^a$ with a covariance $\CovDof_{h}^a$ and the prediction samples then verify
\begin{subequations}\label{eq:UKFDiscrete}
\begin{equation}
	\stateDof_{h+1}^{[i]-} = \modelOpDof(\stateDof_{h}^{[i]+}).
\end{equation}
Then, by computing
\begin{equation}
	\observDof_{h+1}^{[i]-} = \obsOpDof(\stateDof_{h+1}^{[i]-}),\quad  \observDof_{h+1}^{-} = \sum_{i=1}^d \alpha_i \observDof_{h+1}^{[i]}
\end{equation}
The gain is defined by
\begin{equation}
\begin{cases}
		\gainOpDof_{h+1} = (\CovDof_{h+1}^{\stateDof,\observDof}) \cdot (\CovDof_{h+1}^{\observDof,\observDof})^{-1} \\
		\CovDof_{h+1}^{\stateDof,\observDof} = \sum_{i=1}^d \alpha_i(\stateDof_{h+1}^{[i]-}-\hat{\stateDof}_{h+1}^f)(\observDof_{h+1}^{[i]-}-\observDof_{h+1}^{-})^\intercal\\
		\CovDof_{h+1}^{\observDof,\observDof} = \sum_{i=1}^d \alpha_i(\observDof_{h+1}^{[i]-}-\observDof_{h+1}^{-})(\observDof_{h+1}^{[i]-}-\observDof_{h+1}^{-})^\intercal + W_{h+1}
\end{cases}
\end{equation}
so that we keep having
\begin{equation}
\begin{cases}
	\hat{\stateDof}_{h+1}^a  = \hat{\stateDof}_{h+1}^f + \gainOpDof_{h+1}(\observDof_{h+1}- \observDof_{h+1}^{-}) \\
	\CovDof_{h+1}^a = \CovDof_{h+1}^f - \CovDof_{h+1}^{\stateDof,\observDof}  (\CovDof_{h+1}^{\observDof,\observDof})^{-1} 	(\CovDof_{h+1}^{\stateDof,\observDof})^\intercal
\end{cases}
\end{equation}
\end{subequations}
and proceed recursively with new correction particles $\stateDof_{h+1}^{[i]+}$.


The Ensemble Kalman Filter, introduced in \cite{EVENSEN:1994tl}, follows the same principles of approximating the covariances by sampled particles with, most of the time, an increased number of particles with respect to the UKF filter, and various ways of sampling the particles around the mean value. Finally Monte Carlo strategies exploit  a very large number of particles to give a better approximation of the non-linear optimal filter but the practical details of these methods are beyond the scope of this review focused on large dimensional systems coming from the discretization of PDEs.


\subsection{Reduced-order sequential strategies}\label{sec:RO}

\paragraph{Reduced-Order Extended Kalman Filtering (ROEKF)}

In order to deal with the limitations of sequential strategies due to the system size, a classical strategy consists in assuming a specific reduced-order form for the covariance operators. For example, making the ansatz
\begin{equation}\label{eq:red-order-princ}
	\forall t,\quad \Cov(t) = L(t) U(t)^{-1} L(t)^\intercal
\end{equation}
with $U$ an invertible matrix of small size $r$ and $L$ an extension operator, we can show that within linear assumptions the solution of the Riccatti equation in \eqref{eq:Kalman} reduces to
\begin{equation}\label{eq:reducedDynamics}
	\dot{L} = \modelOp L \text{ and }
	\dot{U} = L^\intercal \obsOp^\intercal \obsNoiseNorm \obsOp L.
\end{equation}
which is actually computable in practice.

In a non-linear framework, we can then approximate the covariance dynamics by extending \eqref{eq:reducedDynamics} as
\begin{equation}\label{eq:nl-reducedDynamics}
	\dot{L} = \frac{\partial \modelOp}{\partial \stateAug} L \text{ and }
	\dot{U} = L^\intercal \frac{\partial \obsOp}{\partial \stateAug}^\intercal \obsNoiseNorm \frac{\partial \obsOp}{\partial \stateAug} L.
\end{equation}
These strategies have relevant applications in the case of parameter identification \emph{per se}. It is common, indeed, to assume more space regularity for the parameters than for the state initial condition. Hence, after discretization the parameters can be represented by a small number of degrees of freedom. Assuming that we can limit $U(0)$ to the parametric space, the extension operator can then be decomposed into two components $L = \left( \begin{smallmatrix} \LX \\ \Ltheta \end{smallmatrix} \right)$ with $\Ltheta = \1$ and
\begin{equation}\label{eq:sensitivity}
	\dot{L}_\state = \frac{\partial \modelOp}{\partial \state} \LX + \frac{\partial \modelOp}{\partial \param}.
\end{equation}
We recognize in this expression the dynamics of the sensitivity operator $\frac{\partial \state}{\partial \param}$, which provides a nice interpretation for this strategy of uncertainty covariance reduction. Furthermore, in the linear framework we can prove that this sequential estimator corresponds to the optimal filter associated with the criterion
\begin{equation}\label{eq:paramCriterion}
	\mathcal{J}(\varstate_{\param}) = \int_0^T \|\observ-\obsOp(\state)\|_{\obsNoiseNorm}^2 \, dt +  \|\varstate_{\param}\|_{(\paramNoiseCov)^{-1}}^2,
\end{equation}
where $\state$ follows the trajectory associated with $\varstate_{\param}$ and fixed initial condition, which is commonly used in variational identification procedures. All this justifies naming this strategy \emph{Reduced-Order Extended Kalman Filter} (ROEKF), but it is also known as \emph{Singular Evolutive Extended Kalman Filter} following the work of \cite{Pham:1998p44}.

This concept can be applied directly on time and space discretized versions of the equations, which leads to a \emph{discrete time Reduced-Order Extended Kalman Filter}.
\begin{subequations}\label{eq:ROKalmanDiscrete}
	\begin{enumerate}
	\item Prediction:
   \begin{align}
   	\begin{cases}
   		\hat{\stateDof}_{h+1}^f &= \modelOpDof_{h} (\stateDof_{h}^a) \\
   		L_{h+1} &= \frac{\partial \modelOpDof_{h}}{\partial \stateDof}  L_h
   	\end{cases}
   \end{align}
	\item Correction:
   \begin{align}
   	\begin{cases}
   		U_{h+1} &= U_{h} + L_{h+1}^\intercal \frac{\partial \obsOpDof_{h+1}}{\partial \stateDof}^\intercal \obsNoiseCovDof^{-1}_{h+1} \frac{\partial \obsOpDof_{h+1}}{\partial \stateDof} L_{h+1} \\
		\gainOpDof_{h+1} &= \CovDof_{h+1}^a \frac{\partial \obsOpDof_{h+1}}{\partial \stateDof}^\intercal\obsNoiseCovDof_{h+1}^{-1} \\
		\hat{\stateDof}_{h+1}^a  &= \hat{\stateDof}_{h+1}^f + \gainOpDof_{h+1}(\observDof_{h+1}- \obsOpDof_{h+1} \hat{\stateDof}_{h+1}^f)
   	\end{cases}
   \end{align}
\end{enumerate}
\end{subequations}

\paragraph{Reduced-Order Unscented Kalman Filtering (ROUKF)}

Alternatively, this strategy can be coupled with the UKF approach by showing that particles can be generated only in the space of small dimension and the computation made in the UKF filter \eqref{eq:UKFDiscrete} can be compatible with the time discretized counterpart of \eqref{eq:red-order-princ}. This was proven in \cite{PM-DC-10,moireau-chapelle-11err} which also provided a very general version of the \emph{Reduced Order Unscented Kalman Filter} (ROUKF). In particular this algorithm is close to the \emph{Singular Evolutive Interpolated Kalman Filter} \cite{pham01stochastic,hoteit-pham-blum-02} for a choice of particles $d = r+1$ and reads as follows.
\paragraph{Algorithm~--} Given an adequate sampling rule, we store the corresponding weights in the diagonal matrix $\mathbf{D}_\alpha$ and precompute so-called unitary sigma-points (i.e.~with zero mean and unit covariance) denoted by $(\vec{I}^{[i]})_{1\leq i \leq r+1}$; we then perform at each time step
\begin{subequations}
	\begin{enumerate}
		\item Sampling:
	\begin{align}
		\begin{cases}
			C_h &= \sqrt{(U_h)^{-1}} \\[0.1cm]
			\hat{\stateDof}^{[i]+}_{h} &= \hat{\stateDof}_{h}^a + L_h \cdot C_h^\intercal \cdot \vec{I}^{[i]},\quad 1\leq i \leq r+1 \\[0.1cm]
		\end{cases}
	\end{align}
	\item Prediction:
   \begin{align}
   	\begin{cases}
   		\hat{\stateDof}^{[i]-}_{h+1} &= \modelOpDof_{h}(\hat{\stateDof}^{[i]+}_{h}),\quad 1\leq i \leq r+1 \\[0.1cm]
   	   	\hat{\stateDof}^f_{h+1} &= \sum_{i=1}^{r+1} \alpha_i \hat{\stateDof}_{h+1}^{[i]-}\\[0.1cm]
   	\end{cases}
   \end{align}
	\item Correction:
   \begin{align}
   	\begin{cases}
   		L_{h+1} &= [\hat{\stateDof}^{[*]-}_{h+1}]\mathbf{D}_\alpha [\vec{I}^{[*]}]^\intercal \\[0.1cm]
   		\observDof_{h+1}^{[i]-} &= \obsOpDof_{h+1}(\hat{\stateDof}^{[i]-}_{h+1}) \\[0.1cm]
		\observDof_{h+1}^f &= \sum_{i=1}^{r+1} \alpha_i \observDof_{h+1}^{[i]-} \\[0.1cm]
   		\mathbf{\Gamma}_{h+1} &=  [\observDof^{[*]-}_{h+1}]\mathbf{D}_\alpha [\vec{I}^{[*]}]^\intercal \\[0.1cm]
   		U^{n+1} &=  \mathbf{1} + \mathbf{\Gamma}_{h+1}^\intercal  \obsNoiseCovDof_{h+1}^{-1} \mathbf{\Gamma}_{h+1} \\[0.1cm]
   		\hat{\stateDof}_{h+1}^a &= \hat{\stateDof}_{h+1}^f - L_{h+1} U^{n+1}  \mathbf{\Gamma}_{h+1}^\intercal \obsNoiseCovDof_{h+1}^{-1}  (\observDof_{h+1} - \observDof_{h+1}^f)
   	\end{cases}
   \end{align}
\end{enumerate}
\end{subequations}
where we denote by $[\vec{I}^{[*]}]$ the matrix concatenating the $(\vec{I}^{[i]})$ vectors side by side, and similarly for other vectors.


\subsection{Luenberger observers}

The so-called \emph{observer theory}, initiated by Luenberger \cite{Luenberger63}, is based on the simple realization that, defining the estimation error
\[
	\tilde{\state} = \state - \state^a,
\]
we obtain in the linear case, when subtracting the direct model and filtered equations, the dynamics
\begin{equation}
	\dot{\tilde{\state}} = (\modelOp-\gainFilter\obsOp) \tilde{\state} - \gainFilter\chi.
\end{equation}
This type of dynamical equation is well-known is control theory: it is similar to the closed-loop controlled equation of a system of natural dynamics governed by $\modelOp$, and submitted to a feedback control defined by the operator $\gainFilter$ applied on the quantity observed through $\obsOp$. Hence, obtaining an accurate estimation of the state variable is exactly equivalent to driving the estimation error $\tilde{\state}$ to zero --~namely, stabilizing this error --~using the feedback control $\gainFilter$.

This approach opened new avenues for formulating novel filtering approaches, because for actual dynamical systems control and stabilization motivations have frequently already led to the formulation of effective feedback controls, used in a large variety of industrial systems. Hence, these approaches can be quite directly adapted to obtain adequate filters which --~unlike the Kalman filter --~are tractable in practice for large systems. Moreover, these filters are often deeply rooted in the physics of the system considered, hence the computational building blocks needed are likely to be already available in the system simulation software. However, in the Luenberger approach we lose the Kalman optimality, which of course only holds in quite restricted (linear) cases.

For examples of such approaches applicable to biomechanics we refer to \cite{PM-DC-PLT-09}. We also point out that the Luenberger observer approach is also sometimes referred to as ``nudging'' in the data assimilation community \cite{Auroux:2008p2884}.


\subsection{Joint state-parameter estimation with Luenberger observers}

As apparent in the above discussion, Luenberger observers were originally designed for state estimation. When parameters are to be jointly estimated, it is quite classical in the filtering context to complement the state equation \eqref{eq:modelNotation} with the artificial parameter dynamics
\begin{equation}
	\dot{p} = 0.
\end{equation}
Then the whole estimation objective is to estimate the initial condition of the so-called \emph{augmented state} $(X,p)$. Of course, when a Kalman approach is out of reach for the state variable alone, it holds \emph{a fortiori} for the augmented state. On the other hand, devising a Luenberger observer for the augmented state is difficult, because part of the dynamics is non-physical, hence feedback controls are not readily available for the joint system.

Nevertheless, an effective approach for joint state-parameter estimation was proposed in \cite{PM-DC-PLT-08}, based on a Luenberger observer applied on the state equation alone. In essence, this first stage state estimation reduces the uncertainty to the parameter space, which allows to consider a Kalman-like approach (or EKF-like in nonlinear cases) for handling the remaining parameter uncertainty. This algorithm can be summarized as
\begin{equation}\label{eq:jointEst}
	\begin{cases}
			\dot{\state^a} = \modelOp(\state^a,\hat{\param}) + \gainFilter_\state(\observ-\obsOp\state^a) + \LX\dot{\hat{\param}}\\
			\dot{\hat{\param}} = U^{-1} {\LX}^\intercal \obsOp^\intercal \obsNoiseNorm (\observ-\obsOp\state^a) \\
			\dot{L}_\state = \bigl( \frac{\partial \modelOp}{\partial \state} - \gainFilter_\state\obsOp \bigr) \LX + \frac{\partial \modelOp}{\partial \param}\\
			\dot{U} = {\LX}^\intercal \obsOp^\intercal \obsNoiseNorm \obsOp \LX \\
			\state^a(0) = \state_0\\
			\hat{\param}(0) = \param_0 \\
			\LX(0) = 0 \\
			U(0) = U_0
	\end{cases}
\end{equation}
where $K_X$ denotes the state filter (Luenberger observer), $\LX$ represents the sensitivity of the state variable with respect to the parameters, and $U$ the inverse of the parameter estimation error covariance. This methodology is strongly related to so-called \emph{reduced filtering} approaches, see e.g.~\cite{Pham:1998p44}, since essentially only the part of the dynamics concerning parameters is handled using optimal filtering.

This joint estimation approach was later extended in \cite{PM-DC-10} towards strategies inspired from so-called unscented filtering methods --~also related to Ensemble Kalman filtering and particle filtering --~allowing to avoid the computation of differentiated operators required in \eqref{eq:jointEst}.



\hypertarget{mathematical_hotation}{}\section{Notation Reminder}\label{mathematical_notation}

\-Unless otherwise specified, the notation used throughout the whole documentation (including the reference documentation) is that described below.

\-For details about the \-C++ notation of the variables involved in data assimilation algorithms see Section \ref{plugging_in_verdandi_reference_notation}.


\hypertarget{notation_model}{}\subsection{\-Model and State Vectors}\label{notation_model}

\-The time index $h$ is associated with the time $t_h$. \-The model time steps are denoted $\Delta t_h$, so that $t_h = t_0 + \sum_{h' = 0}^{h' < h} \Delta t_{h'}$.

\-The state equation is \[x^t_{h+1} = \mathcal{M}_h(x^t_h, p_h) + e^m_h\,,\] where $x^t_h \in \mathbb{R}^n$ is the true model state vector, $\mathcal{M}_h$ is the model operator, $p_h \in \mathbb{R}^l$ is the vector of model parameters, and $e^m_h$ is the model error. \par


\-The model error can be decomposed into a systematic error $\bar e^m_h$ and a fluctuation $\tilde e^m_h$\-: \[e^m_h = \bar e^m_h + \tilde e^m_h\,.\]

\-If the model error is a random vector, then $\bar e^m_h$ is its expectation\-: $\bar e^m_h = \mathrm{E}(e^m_h)$.

\-A tangent linear model is denoted $M_h$.

\-In the course of a simulation with data assimilation, one distinguishes the forecast state vector $x^f_h$ and the analysis state vector $x^a_h$. \-The later is the result of the assimilation, while the former is often defined as \[x^f_{h+1} = \mathcal{M}_h(x^a_h, p_h)\,.\]

\-The forecast and analysis errors are defined as \[e^f_h = x^f_h - x^t_h\,,\] \[e^a_h = x^a_h - x^t_h\,.\]

\-The variances of the errors are denoted $P^f_h$ for the forecast error, $P^a_h$ for the analysis error and $Q_h$ for the model error\-: \[P^f_h = \mathrm{E}\left(\left(e^f_h - \mathrm{E}(e^f_h)\right)\,\left(e^f_h - \mathrm{E}(e^f_h)\right)^T\right)\,,\] \[P^a_h = \mathrm{E}\left(\left(e^a_h - \mathrm{E}(e^a_h)\right)\,\left(e^a_h - \mathrm{E}(e^a_h)\right)^T\right)\,,\] \[Q_h = \mathrm{E}\left(\tilde e^m_h (\tilde e^m_h)^T\right)\,.\]

\hypertarget{notation_observations}{}\subsection{\-Observations}\label{notation_observations}

\-The observation vector at time $t_h$ is denoted $y_h \in \mathbb{R}^m$. \-It satisfies \[y_h = \mathcal{H}_h(x^t_h) + e^o_h\]

\-The observation operator $\mathcal{H}_h$ maps the model state space into the observation space. \-A tangent linear operator is denoted $H_h$.

\-The observation error can be decomposed into a systematic error $\bar e^o_h$ and a fluctuation $\tilde e^o_h$\-: \[e^o_h = \bar e^o_h + \tilde e^o_h\,,\] with $\bar e^o_h = \mathrm{E}(e^o_h)$ in a stochastic framework.

\-The observational error covariance matrix is \[R_h = \mathrm{E}\left(\tilde e^o_h (\tilde e^o_h)^T\right)\,.\]

\-The innovation, defined as the discrepancy between the observations and the corresponding model forecast, is denoted \[d_h = y_h - \mathcal{H}_h(x^f_h)\,.\]


\section{Data assimilation library specifications}


\subsection{Objectives}\label{sec:objectives}


The primary objective is to develop a data assimilation library applicable to a wide class of systems, with a particular emphasis on models represented by partial differential equations (PDEs) that typically lead to large-scale numerical systems. Relevant application fields include examples as diverse as geophysics (e.g.~weather forecasting and pollution modeling) and biophysical modeling (e.g.~biomechanics). For instance, the library is used within the euHeart consortium to combine various types of biophysical models pertaining to cardiac modeling (fluid and/or solid mechanics, perfusion, electrophysiology, etc.) with some corresponding clinical data, the objective of data assimilation being to provide ``patient-specific'' (personalized) predictive cardiac models in this case. Hence, the library will be targeted at providing generic data assimilation procedures well-adapted to large-dimensional systems. These procedures should cover the most widespread needs in such application fields, but the software is designed in a modular and extensible form in order to easily allow some further developments of specific methods that advanced users would be keen on including in the library.

\paragraph{Library principle}

We can schematically identify three main components in the overall design of \emph{Verdandi}: (1) the numerical model, which provides the state vector, the dynamics operator (and possibly its tangent linear and adjoint versions), and statistics for the initial state error (and the model error, when applicable);
(2) the observation manager, which provides the observations, their error covariance matrix and the observation operator; (3) the data assimilation algorithm, which drives the model and the observation manager along the assimilation procedure. Each component is implemented in a separate C++ class. A class is an entity that contains variables, called attributes, and member functions that usually operate on the attributes. For instance, the model class has the state vector as attribute, and a member function called \verb|GetState| to access this state vector.

An assimilation algorithm encapsulates the model and the observation manager. It is in charge of all assimilation computations, such as the correction step in the sequential (filtering) methods. It delegates the other specific computations to the model --~e.g.~the time integration over one time step --~and the observation operator. An assimilation algorithm is implemented with essentially no assumption on the inner implementations of the model and the observation manager, which are both only required to provide  specified interfaces to work with \emph{Verdandi} data assimilation algorithms. See Figure~\ref{fig:verdandi_class} which illustrates the links between the three components.

\begin{figure}[htbp]
  \caption{In \emph{Verdandi}, the data assimilation algorithm is implemented in a class that encapsulates a model and an observation manager. The model defines the state vector, the dynamics, the associated error statistics, \ldots{} The observation manager provides the observations, the observation operator, the associated error statistics, \ldots{} These variables are accessed through member functions like \texttt{GetState} or \texttt{GetObservation}.}
  \label{fig:verdandi_class}

   \begin{tikzpicture}[every node/.style = {anchor = base},scale=0.75]

     % Assimilation class.
     \draw[rounded corners, fill = gray!40] (0., 0.)
     -- (0., 12.) node [anchor=north west,font=\large\bf] {Data assimilation algorithm}
     -- (15., 12.) -- (15., 0.) -- cycle;

     % Model class.
     \draw[rounded corners, fill = white!50] (1., 1.)
     -- (1., 10.) node (model left) {} node [anchor=north west,font=\large\bf] {Numerical model}
     -- (7., 10.) node (model right) {}
     -- (7., 1.) -- cycle;

     \node [anchor=north west,font=\large,yshift=-8mm] at (model left) {$\stateDof^t_h$ state vector};
     \node [anchor=north west,font=\large,yshift=-16mm] at (model left) {$\modelOpDof_h$ dynamics};
     \node [anchor=north west,font=\large,yshift=-24mm] at (model left) {$\initNoiseCovDof$ initial error variance};
     \node [anchor=north west,font=\large,yshift=-29mm] at (model left) {$\vdots$};
     \node [anchor=north west,font=\large\tt,yshift=-37mm] at (model left) {GetState};
     \node [anchor=north west,font=\large\tt,yshift=-44mm] at (model left) {Initialize};
     \node [anchor=north west,font=\large\tt,yshift=-51mm] at (model left) {Forward};
     \node [anchor=north west,font=\large,yshift=-56mm] at (model left) {$\vdots$};

     % Observation class.
     \draw[rounded corners, fill = white!50] (8., 1.)
     -- (8., 10.) node (observation left) {} node [anchor=north west,font=\large\bf] {Observation manager}
     -- (14., 10.) node (observation right) {}
     -- (14., 1.) -- cycle;

     \node [anchor=north west,font=\large,yshift=-8mm] at (observation left) {$\observDof_h$ observation vector};
     \node [anchor=north west,font=\large,yshift=-16mm] at (observation left) {$\obsOpDof_h$ observation operator};
     \node [anchor=north west,font=\large,yshift=-24mm] at (observation left) {$\obsNoiseCovDof_h$ error variance};
     \node [anchor=north west,font=\large,yshift=-29mm] at (observation left) {$\vdots$};
     \node [anchor=north west,font=\large\tt,yshift=-37mm] at (observation left) {GetObservation};
     \node [anchor=north west,font=\large\tt,yshift=-44mm] at (observation left) {ApplyOperator};
     \node [anchor=north west,font=\large\tt,yshift=-51mm] at (observation left) {GetErrorVariance};
     \node [anchor=north west,font=\large,yshift=-56mm] at (observation left) {$\vdots$};

   \end{tikzpicture}

  \caption{In \emph{Verdandi}, the data assimilation algorithm is implemented in a class that encapsulates a model and an observation manager. The model defines the state vector, the dynamics, the associated error statistics, \ldots{} The observation manager provides the observations, the observation operator, the associated error statistics, \ldots{} These variables are accessed through member functions like \texttt{GetState} or \texttt{GetObservation}.}
  \label{fig:verdandi_class}
\end{figure}



\paragraph{Contents of the Library}

This section describes the contents of the library in more detail, as it should be seen from
the user's viewpoint as regards the following components:
\begin{itemize}
	\item \textbf{Assimilation Methods}
	\item \textbf{Models}
	\item \textbf{Observations}
	\item \textbf{Error Statistics}
	\item \textbf{Other Tools}
\end{itemize}

\paragraph{Assimilation Methods}

As previously outlined, the assimilation method merges a numerical model and  observations.
Therefore each class ``\code{AssimilationMethod}'' has the numerical model and the observations as members. Furthermore,
the assimilation method is intrinsically a new numerical model which integrates the observations. Each
class ``\code{AssimilationMethod}'' thus implements the methods of the class \code{Model}, and also of course the methods performing the data assimilation procedure \emph{per se}, also called the analysis for sequential methods.

\paragraph{Numerical Model}

The required interface will greatly vary with the data assimilation
method. The class \code{Model} typically gives access to
\begin{enumerate}
\item the time integration over one time step, say with \code{Forward};
\item the state vector, say with \code{GetState};
\item the date that the model has reached (in its time integration), with
 \code{GetDate} that probably returns an integer;
\item the covariance error ``models'', say \code{GetStateErrorVariance} for
 background and \code{GetModelErrorVariance} for model error, which are
 objects (see section~\ref{sec:error_statistics});
\item the model input data and parameters, so that they could be perturbed;
\item the tangent linear model;
\item the adjoint model, with a backward mode (\code{Backward}) and access to
 adjoint variables;
\item some source term of the underlying equation (for nudging).
\end{enumerate}

\paragraph{Observations}

The observations should be handled by a class called {\it observation
 manager}. The interface of \code{ObservationManager} typically gives access to
\begin{enumerate}
\item a method that tells the manager to load/read the observations at a given
 date (integer \code{Model::GetDate});
\item a method that tells whether observations are available at current date,
 or whether observations have been available between the previous date and
 the current date, say \code{HasObservation};
\item the observations, with \code{GetData};
\item the covariance error ``model'', say \code{GetErrorVariance} for the
 observations;
\item a method to perturb the observations (useful in twin experiments);
\item the tangent linear version;
\item the adjoint version;
\item probably the observation operator.
\end{enumerate}

The observation operator may be implemented in a dedicated class, like the error
statistics. It may or may not be encapsulated in the observation manager. The
observation operator needs access to the model and to the observation
manager, since it maps from model space to observation space. Obviously this
demands some mechanism to specify the position of the observations and the
positions associated with the model state components (note that parts of the
state vector may not be associated with any position).

\paragraph{Error Statistics}
\label{sec:error_statistics}

Many assimilation methods require statistics for observation errors, model
errors and/or background errors. The interface of a class for error statistics
typically includes:
\begin{enumerate}
\item a method to retrieve the covariance matrix--~although note that the method should not be
 called in high-dimension;
\item a method to retrieve a row (or a column) of the covariance matrix;
\item base methods to get the size of the covariance matrix and to access a
 single element of the matrix--~one should be able to use the class as if it
 were a matrix class (hence, consistency with the library for linear algebra
 would be a good idea).
\end{enumerate}

\paragraph{Data Management}

There may be a need for several {\it data containers}. This is probably not
necessary for the state vector or the observations at a given date, since a
vector should be good enough. But if ones manipulates, say, the sequence (in
time) of all observations from a network, the data structure is more
complex. For instance, at many dates, there may be missing observations at a
few locations of the network. In addition, one may need specific methods to
remove a location, to apply some filter, to threshold the data,~\ldots{}

For sequential aggregation (ensemble forecast), one may rely on an {\it
 ensemble container} that stores all simulated values and maybe the
corresponding observed values.

More generally, data processing can be painful. A few dedicated classes would
be welcome.


\subsection{Constraints}

\begin{itemize}
\item \textbf{Contents} -- As mentioned in Section~\ref{sec:objectives}, the library should be designed for
high-dimensional problems first. This does not mean that other problems cannot
be addressed, but if the high dimension demands a specific design in some
respect, there should be no concern about following that design.

\item \textbf{Computer Languages} -- Obviously there must be a low-level language since high performance is
required. This language must be
\begin{enumerate}
\item efficient for computing;
\item with rich features, especially when it comes to genericity;
\item coming along with libraries that cover the needs of the present library
 (primarily linear algebra).
\end{enumerate}
For these reasons we decide to rely on \textbf{C++} which offer object-progamming
capabilities in addition with high performance computing.

But in scientific computing, one always relies at some point on a high-level
language. This language is used at least for visualization. The library should
communicate well with one or more high-level languages. This should permit
direct calls to the library, so that one gets at hand the results of the
assimilation, and maybe the intermediate steps if the interface to the methods
is rich enough. In this context, a high-level language should offer:
\begin{enumerate}
\item the ability to make calls to many methods and functions of the library;
\item the ability to manipulate the library data structures (so as to access
 the library results);
\item the possibility to easily generate the interface to the library (more or
 less automatically so that any change in the library should not result in
 significant workload);
\item no significant loss of performance.
\end{enumerate}
The use of the high-level language should always remain optional. The library
should work without it. And for all these reasons we choose \textbf{Python}. In fact
Python is a very powerful language. It is free, its interpreter is free
software and many libraries (the so-called modules) are free software too. A d
very convenient software is SWIG (\url{http://www.swig.org/}) which can
(almost) automatically build a Python interface to a C/C++ code. The main
limitation with Python is that it may not offer enough (complete) modules to
replace all Matlab toolboxes. In the recent past, Python has been maturing for
scientific computing. It is now pretty well organized around SciPy
(\url{http://scipy.org/}), NumPy (\url{http://numpy.scipy.org/}), Matplotlib
(\url{http://matplotlib.sourceforge.net/}) and MayaVi/PyVTK
(\url{http://mayavi.sourceforge.net/}). Some packages try to provide all
Python facilities in a single consistent package, like SAGE
(\url{http://www.sagemath.org/)}. Many efforts were explicitly undertaken in
order to replace Matlab.

\item \textbf{Portability} -- It is needless to stress the demand for portability since it is a natural
feature of any good software. The library should compile on BSD systems,
Linux, MacOS, Unix and Windows. Beyond the portability itself, this often
ensures that most compilers will accept the library, and this may even
increase the safety of the implementation. An obvious consequence is that all dependencies of the library must be
portable.

\item \textbf{Compatibility with Users' Models and Observations} -- The library should ease plugging a user's model. It is likely that the model
requires adjustments to be compatible with the library, but they should be
minimized. The library should rely on the lightest interface and it should
assume very little about the model structure.These constraints relate to genericity. The library should be able to deal
with many applications, thus many models, observations and error statistics.

\item \textbf{Parallel Computing} -- Because of the high-dimensional problems to be addressed, parallel computing
may be needed. The library should therefore be available for supercomputers
and clusters. Nowadays a lot of parallel computing involves multiple cores and
processors in the same machine: obviously, this must be supported.

\item \textbf{Nesting and Coupling} -- The assimilation is not necessary the last stage in a system. The model with
assimilation may be seen as a new model which is in turn included in
something. For instance, a model with assimilation may be coupled with another model. Hence
assimilation should never be seen as the end of the simulation process.

\item \textbf{License} -- The Library need to be open-source but also need to offer opportunities for business use. Therefore the library should be GNU GPL and rely on dependencies that are LGPL too.


\subsection{Model Development}




\paragraph{Development Model}
The library is freely distributed as opensource software, under the GNU LGPL license. It is made available from a public web site \href{http://verdandi.gforge.inria.fr/}. External contributions will also be possible, under certain specifications.% (see below). Regarding the business community, as the GPL license may be too restrictive for certain uses and partners, individual (partner-wise) BSD or GNU LGPL licenses will be granted upon request for example in the context of euHeart (\url{http://www.euheart.eu/}) that  financially supported the development of Verdandi.


A contribution can be committed to the repository if and only if it is (1)
compliant with the overall design, (2) compliant with the coding standard, (3)
of some interest for the library (i.e., not too specific), (4) documented (or
soon to be documented: stable versions will only include documented code). This
means that a certain quality level must be achieved for a contribution to be
included, but also that, once this quality level is ``cleared'', there are few
constraints. This is made possible thanks to the modularity and the
scalability of the library and thanks to the light maintenance that should be
required.

If possible, the developers should write ready-to-commit code and commit
themselves. In practice, a new developer should be first supervised,
preferably by one of the main \emph{Verdandi} developers who can detect if a contribution is good enough for
inclusion in the library. There should be a learning period during which the
new developer has her/his contributions (commit candidates) checked and maybe
corrected. After the developer has produced several quality contributions
(with no correction needed), say about 4 in a raw, she/he gains commit rights.

There should always be one of the main \emph{Verdandi} developers that quickly reviews
any new code (after it is committed) in order to check its compliance with the
library design and coding standard.


\paragraph{Forge}

There is a need for a common repository for: the code itself, its
documentation and its related documents (like this one or a web page) and
Inria GForge is the adequate choice. In addition to the repository, it
provides mailing lists and trackers (for the bugs and the feature
requests).

\paragraph{Revision Control System}

The \emph{Verdandi} library is maintained under Git (\url{http://git.or.cz/}) which provides
a decentralized revision control system more powerful than Subversion (many open source projects are currently
migrating from Subversion to Git, or to a similar system like Mercurial) and available in Inria GForge.

We identify the need that \emph{the trunk} (or master branch in Git) should always compile and be clean and
bug-free (as far as the developers know). Roughly speaking, one could release
at any time a version (almost stable) with the trunk. Experimental work should
remain in branches. Thanks to this rule, one can always trust the trunk and work with
it.

\paragraph{Dependencies}
A few external libraries (as few as possible!) are needed, at least for compilation, linear
algebra, random numbers, configuration files, optimization and high level interface. A
detailed comparison of the available solutions have been conducted. Each time,
a comparison report has follow to support the final choice. We detail our various choices in the next section.

\hypertarget{installation_dependencies}{}\section{\-Dependencies}\label{installation_dependencies}

A few libraries are needed, for compilation, configuration files and linear algebra. Detailed comparisons of the available solutions were conducted:

\begin{itemize}
\item A thorough study of existing libraries for linear algebra \cite{linear_algebra} has been carried out to choose \href{http://seldon.sourceforge.net/}{\tt \-Seldon}  for providing \emph{Verdandi} with vectors, matrices and related operations.

\item A study of several libraries to manage configuration files \cite{configuration_library} has initially concluded that GetPot should be used to read the configurations.\marginnote{\href{http://www.lua.org}{\tt \-Lua} and Ops are introduced in Section \ref{dependencies_configuration}} Eventually, we switched to Ops: the configuration files are written in \href{http://www.lua.org}{\tt \-Lua}, which makes the configuration files easy to read and write for the beginner, and yet very powerful for advanced users.

\item \emph{Verdandi} provides a high level interface in Python generated via \href{http://www.swig.org/}{\tt \-S\-W\-I\-G}. The tools to build a high level interface on top of the C++ source code have been listed and studied \cite{high_level_interface}.
\end{itemize}
Below is  the list of dependencies required by Verdandi:

\begin{itemize}
\item The software \marginnote{For more information about  \href{http://www.scons.org/}{\tt \-S\-Cons} see Section \ref{dependencies_compilation}.} construction tool \href{http://www.scons.org/}{\tt \-S\-Cons} (version 1.\-0 or higher) for compilation.
\item \-Python for both \-S\-Cons and the optional \-Python interface (see page \hyperlink{python}{\-Python}) to the \-C++ code; the generation of the interface also requires \href{http://www.swig.org/}{\tt \-S\-W\-I\-G}.
\end{itemize}

\-Note that in \-\emph{Verdandi} tarball, you will also find\-:
\begin{itemize}
\item The linear algebra library \href{http://seldon.sourceforge.net/}{\tt \-Seldon}.
\item \href{http://www.lua.org}{\tt \-Lua}, a scripting language.
\item \-Ops, a library for reading \-Lua configuration files.
\end{itemize}

\hypertarget{dependencies_seldon}{}\subsection{Linear Algebra Library}\label{dependencies_seldon}


A thorough study of existing libraries for linear algebra \cite{linear_algebra} has been carried out to choose \href{http://seldon.sourceforge.net/}{\tt \-Seldon}

\paragraph{Seldon main strengths}

\href{http://seldon.sourceforge.net/}{\tt \-Seldon}  is adapted to data assimilation problems in large dimension for its following key features:

\begin{itemize}
\item \textbf{Availability of dense and sparse matrices, vectors}\\
 \href{http://seldon.sourceforge.net/}{\tt \-Seldon} provides many different matrix and vector structures, and many functions for computations (linear algebra).
 Among dense matrices, there are specific structures for rectangular matrices, symmetric matrices, hermitian matrices and triangular matrices. Each type includes several formats. E.g., rectangular dense matrices may be stored by rows or by columns; symmetric dense matrices may be stored as rectangular matrices or only upper part of the matrix is stored (this is the packed form of Blas).
\item \textbf{Interface to BLAS and LAPACK}\\
\href{http://seldon.sourceforge.net/}{\tt \-Seldon} is interfaced with \href{http://www.netlib.org/blas/}{Blas} (levels 1, 2 and 3) and \href{http://www.netlib.org/lapack/}{Lapack}, except for functions involving banded matrices (since this format is not available for the moment). If Blas is not available to the user, a few alternative functions (same functions written in C++) may be used.
\item \textbf{Performance}\\
The performance of  \href{http://seldon.sourceforge.net/}{\tt \-Seldon} was evaluated through the Linear Algebra Libraries study \cite{linear_algebra}. (see benchmark figure \ref{fig:benchmark})


\begin{figure}
  \caption{Benchmark for Dense Matrix from Claire Mouton, Linear Algebra Libraries (2009).}
  \label{fig:benchmark}
  \includegraphics[width=1.1\textwidth]{image/bench1.pdf}
  \includegraphics[width=1.1\textwidth]{image/bench2.pdf}
\end{figure}





\item \textbf{Convenient}\\
\href{http://seldon.sourceforge.net/}{\tt \-Seldon} is designed to be efficient and convenient, which is notably achieved thanks to template classes. Exception handling and several debug levels were define to ease the "coding" development.

\item \textbf{Interface to sparse solver libraries}\\
For sparse matrices, Seldon is interfaced with direct solvers of \href{http://mumps.enseeiht.fr/}{MUMPS}, \href{http://crd-legacy.lbl.gov/~xiaoye/SuperLU/}{SuperLU} and \href{http://www.cise.ufl.edu/research/sparse/umfpack/}{UmfPack}. There is a bunch of iterative solvers available in Seldon such as Gmres, BiCgSTAB, Qmr, etc. Thanks to templates, these solvers can be used for any type of matrix and preconditioning, not only Seldon matrices. This is very useful when the user does not store the matrix, but is able to perform a matrix-vector product.

\item \textbf{Portability}\\
\href{http://seldon.sourceforge.net/}{\tt \-Seldon} is supposed to be fully compliant with the C++ standard. Therefore, it can be compiled by GNU GCC (>=3.0; tested with version 3.2, 3.3, 3.4, 4.0, 4.1, 4.2, 4.3 and 4.4) and by the Intel C++ compiler icc (tested with icc 7.1 and 8.0). No tests were conducted with proprietary compilers under Unix, but the compliance with the C++ standard should ensure portability. Decent versions of Microsoft Visual C++ (i.e., from Visual C++ 2003) compile Seldon.

\item \textbf{Local mastering of developpment (INRIA)}\\

\item \textbf{Compatibility with distributed matrices and vectors}\\
\href{http://seldon.sourceforge.net/}{\tt \-Seldon} was interfaced with \href{http://www.mcs.anl.gov/petsc/}{PETSc} which provides distributed vectors and matrices and many functions for computations. \href{http://www.mcs.anl.gov/petsc/}{PETSc} vectors and matrices can be used through the \href{http://seldon.sourceforge.net/}{\tt \-Seldon} objects.

\end{itemize}

\hypertarget{tips_matrix_vector}{}\paragraph{\-Seldon Matrices and Vectors}\label{tips_matrix_vector}


\-The structures manipulated in \-\emph{Verdandi} are \href{http://seldon.sourceforge.net/}{\tt \-Seldon} vectors and matrices.

\-Vectors are instances of the class {\ttfamily \-Vector}.\\
\-Class {\ttfamily \-Vector} is a template class\-:\\
{\ttfamily \-Vector$<$\-T, Storage, Allocator$>$}.
\begin{itemize}
\item{\ttfamily \-T} is the type of the elements to be stored (e.\-g. {\ttfamily double}).
\item {\ttfamily \-Storage} defines how the vector is stored. {\ttfamily \-Storage} is equal to {\ttfamily \-Vect\-Full} by default for full vectors, you can set it to {\ttfamily \-Vect\-Sparse} for sparse vectors.
\item \-Finally, {\ttfamily \-Allocator} defines the way memory is managed. \-It is close to \-S\-T\-L allocators. \-See the section \char`\"{}\-Allocators\char`\"{} for further details.

\end{itemize}

\-Matrices are instances of the class {\ttfamily \-Matrix}.\\
\-Class {\ttfamily \-Matrix} is a template class\-:\\
 {\ttfamily \-Matrix$<$\-T, \-Prop, \-Storage, \-Allocator$>$}.

 \begin{itemize}
 \item \-As for vectors, {\ttfamily \-T} is the type of the elements to be stored (e.\-g. {\ttfamily double}).

\item {\ttfamily \-Prop} indicates that the matrix has given properties (symmetric, hermitian, positive definite or whatever). \-This template parameter is never used by \-Seldon; so the user may define its own properties. \-Thanks to this template parameter, the user may overload some functions based on the properties of the matrix. \-Seldon defines two properties\-: {\ttfamily \-General} (default) and {\ttfamily \-Symmetric}.

\item {\ttfamily \-Storage} defines how the matrix is stored. \-Matrices may be stored in several ways. {\ttfamily \-Row\-Major} is the default storage.

\item \-Finally, {\ttfamily \-Allocator} defines the way memory is managed. \-It is close to \-S\-T\-L allocators.

\end{itemize}

\hypertarget{dependencies_configuration}{}\subsection{Configuration Files}\label{dependencies_configuration}


\paragraph{Ops in short}

Ops is a C++ library and a Python module for reading configuration files. The files are written in Lua, which makes the configuration files easy to read and write for the beginner, and yet very powerful for advanced users.

Ops supports reading Boolean, integers, floats, doubles and strings, and vectors (of any of the previous types). It is also possible to call functions defined in the configuration files.

The user can define constraints to be satisfied by the entries (e.g., positive integer, list of acceptable values, ...). In case of errors, exceptions are raised.

Ops is capable of saving the Lua definitions of all variables (except functions) that have been read in a configuration file. This may be useful to keep track of configurations.


Ops only depends on \href{http://www.lua.org/}{Lua 5.1}. Both Ops and \href{http://www.lua.org/}{Lua 5.1} are provided in the  \-\emph{Verdandi} tarball.

\hypertarget{configuration_files_basic_use}{}\paragraph{\-Example}\label{configuration_files_basic_use}

The main features of the library are illustrated by the following example. No exception is raised in this example, but Ops raises an exception any time an error is detected (missing file, missing entry, constraint not satisfied, Lua interpretation error, ...) and shows an information message to help the user.

example.lua:
\marginnote{
\-Configuration files must be written in \href{http://www.lua.org/manual/5.1/}{\tt \-Lua 5.\-1} and are read by the library Ops.\\

Lua main strengths:
\begin{itemize}
\item \-Scripting language brings a lot of functionalities.
\item \-The language is well-defined and the syntax errors are detected by the interpreter.
\item \-Easy references and computations on configuration variables. It is possible to call Lua functions from C++ code.
\item \-It is possible to perform tests or system calls in the configuration file. For instance, one can test the existence of a directory.
\item \-A configuration file can be included in an other one, a configuration file can be shared.
\end{itemize}


}


 \begin{frame_lua}
-- Lines starting with "--" are comment lines.

-- This defines an integer.
Nx = 100
-- Calculations are possible.
Ny = 2 * Nx - 10

-- This defines a floating number in double precision.
Delta_t_model = 0.03
-- Another example calculation:
Delta_t_sqrt = math.sqrt(Delta_t_model) * 1.5e-7

-- Here is a string.
output_directory = "result/"
-- Concatenation of strings is carried out by "..".
output_file = output_directory .. "output.bin"


--------------- MODEL ----------------


-- Configuration entries are provided in sections and subsections.
model = {

   definition = {

      -- You can provide a vector.
      initial_state = {0.3, 0.3},
      -- Binary options (Boolean).
      with_linear_term = true,
      with_constant_term = false,
      -- Reference to a previously defined entry.
      Delta_t = Delta_t_model

   }

}

-- Entries can be overwritten:
model.definition.initial_state =  {1., 1.6}
\end{frame_lua}




  \-advanced\_example.lua \-:

\marginnote{

{\ttfamily vector\-\_\-list} represents three vectors defined as\-: \[(u_1, u_2, u_3)^T\] \[(v_1, v_2, v_3)^T\] \[(w_1, w_2, w_3)^T\]

{\ttfamily matrix\-\_\-list} represents two matrices\-: \[\left(\begin{array}{cc} u_{11} & u_{12}\\ u_{21} & u_{22}\\ \end{array} \right)\] \[\left(\begin{array}{cc} v_{11} & v_{12}\\ v_{21} & v_{22}\\ \end{array} \right)\]

}

 \begin{frame_lua}
-- A list of vectors is provided as a single vector (which will be split by
-- Ops).
vector_list = {u_1, u_2, u_3,
               v_1, v_2, v_3,
               w_1, w_2, w_3}

-- Note that the following syntax is absolutely equivalent (Lua does not pay
-- attention to line breaks).
vector_list = {u_1, u_2, u_3, v_1, v_2, v_3, w_1, w_2, w_3}

-- A list of matrices is also provided as a single vector (which will be split
-- by Ops).
matrix_list = {u_11, u_12,
               u_21, u_22,
               v_11, v_12,
               v_21, v_22}
\end{frame_lua}




\hypertarget{dependencies_compilation}{}\subsection{Compilation}\label{dependencies_compilation}


\href{http://scons.org/}{\tt \-S\-Cons} is a software construction tool, used for building every example of \hyperlink{namespace_verdandi}{\-Verdandi}. \-It uses \-Python scripts as configuration files.

\hypertarget{scons_main_strenghts}{}\paragraph{\-SCons main strengths}\label{scons_main_strenghts}

Nowadays, make and the autotools are outdated. The two main replacement tools are CMake (\href{http://www.cmake.org/}{http://www.cmake.org}) and SCons (\href{http://www.scons.org/}{http://www.scons.org/}). With the latter, the SConstruct files (similar to the makefiles) are written in Python. CMake has its own language. Here are some key features of SCons:


\begin{itemize}
\item \-It uses Python scripts as configuration files, so user-written builds have access to a complete general-purpose programming language.
\item \-Automatic dependency analysis built-in.
\item \-Support for many platforms, compilers, and targets built-in.
\item \-Support for parallel builds which maintains a specified number of jobs running simultaneously regardless of directory hierarchy.
\end{itemize}

\hypertarget{scons_using}{}\paragraph{\-Basic Usage}\label{scons_using}

\-In order to start with \-Verdandi, it is sufficient to install \-S\-Cons. \-Make sure that the executable {\ttfamily scons} is available.

\-For example, to compile programs of the Quadratic Model, run {\ttfamily scons} in the directory {\ttfamily example/quadratic\-\_\-model/}\-:


\begin{frame_bash}
host<~/> scons
\end{frame_bash}

If you want to compile only the program {\ttfamily forward.cpp} run:

\begin{frame_bash}
host<~/> scons forward
\end{frame_bash}




\end{itemize}

% ========================================================================
% Chapter Using Verdandi
% ========================================================================
\chapter{Using Verdandi}



\hypertarget{overview}{}\section{Overview}\label{overview}

The \-\emph{Verdandi} directory is made up of the following sub-directories.


\begin{DoxyItemize}
\item {\ttfamily bin/}\-: contains useful scripts.\\

For instance,  \-the script {\ttfamily format} partially formats source files according to \-Verdandi's rules\-: \marginnote{For more information about the conventions applied in \emph{Verdandi} see Appendix Chapter \ref{coding_standards}}
it removes trailing spaces and indents the code; it finally checks that no line goes beyond the 78th column.
\item {\ttfamily error/}\-: contains error variance classes:
	\begin{itemize}
	\item  {\ttfamily \-Diagonal\-Matrix}:

	This class implements a covariance error matrix that is
      diagonal.
	\item  {\ttfamily \-Balgovind\-Matrix}:

	This class defines a covariance matrix in Balgovind form.
      In a covariance matrix in Balgovind form, the covariance between two
      points depends on the distances (in each direction) between the
      points. For example, in the 2D case, if the entry $(i, j)$ of the
      matrix is the covariance between the values at $(x_i, y_i)$ and
      $(x_j, y_j)$, its value will be:

      $[B_{i, j} = v \left(1 + \frac{|x_j - x_i|}{L_x}\right)
      \exp\left(-\frac{|x_j - x_i|}{L_x}\right) \left(1 + \frac{|y_j -
      y_i|}{L_y}\right) \exp\left(-\frac{|y_j - y_i|}{L_y}\right)]$

      where $v$ is a variance, and $L_x$ and $L_y$ are
      decorrelation lengths.
	\item  {\ttfamily \-IsotropicBalgovind\-Matrix}:
	This class defines a covariance matrix in isotropic Balgovind form.
     In a covariance matrix in isotropic Balgovind form, the covariance
      between two points only depends on the Euclidean distances between the
      points. For example, in the 2D case, if the entry $(i, j)$ of the
      matrix is the covariance between the values at $(x_i, y_i)$ and
      $(x_j, y_j)$, its value will be:

     $ [B_{i, j} = v \left(1 + \frac{\sqrt{(x_j - x_i)^2 + (y_j -
      y_i)^2}}{L}\right) \exp\left(-\frac{\sqrt{(x_j - x_i)^2 + (y_j -
      y_i)^2}}{L}\right)]$

      where $v$ is a variance, and $L$ is the decorrelation length.
	\end{itemize}
\item {\ttfamily example/}\-: contains example programs for several models and configurations. \marginnote{All examples programs are described in  Section \ref{example_programs}.}
\item {\ttfamily method/}\-: contains the data assimilation algorithms available in Verdandi: \marginnote{All data assimilation methods available in \emph{Verdandi} are described in Chapter \ref{data_assimilation_algorithms}.}
\begin{DoxyItemize}
\item \hyperlink{optimal_interpolation}{optimal interpolation (\-O\-I)};
\item \hyperlink{extended_kalman_filter}{extended \-Kalman filter (\-E\-K\-F)};
\item \hyperlink{reduced_order_extended_kalman_filter}{reduced order extended \-Kalman filter (\-R\-O\-E\-K\-F)};
\item \hyperlink{unscented_kalman_filter}{unscented \-Kalman filter (\-U\-K\-F)};
\item \hyperlink{reduced_order_unscented_kalman_filter}{reduced order unscented \-Kalman filter (\-R\-O\-U\-K\-F)};
\item \hyperlink{reduced_minimax_filter}{reduced minimax filter (\-R\-M\-F)};
\item \hyperlink{four_dimensional_variational}{four dimensional variational (4\-D\-V\-A\-R)};
\item \hyperlink{ensemble_kalman_filter}{ensemble \-Kalman filter (\-En\-K\-F)}.
\end{DoxyItemize}
\item {\ttfamily model/}\-: contains the following sample models:
\marginnote{The example models are documented in Section \ref{models}.}
\begin{DoxyItemize}
\item \hyperlink{quadratic_model}{\-Quadratic \-Model};
\item \hyperlink{shallow_water_model}{\-Shallow-\/water};
\item \hyperlink{clamped_bar_model}{\-Clamped \-Bar};
\item \hyperlink{lorenz_model}{\-Lorenz \-Model}.
\end{DoxyItemize}
\item {\ttfamily observation\-\_\-manager/}\-: contains example observation managers:\marginnote{The example observation managers available in \emph{Verdandi} are documented in  Section \ref{observations}.}
\begin{DoxyItemize}
\item a  \hyperlink{linear_observation_manager}{Linear Observation Manager} whose observation operator is simply defined with a matrix;
\item a  \hyperlink{grid_to_network_observation_manager}{Grid to Network Observation Manager} with an observation operator that maps from a model grid to an observation network;
\item  \hyperlink{observation_aggregator}{Observation Aggregator}.
\end{DoxyItemize}
\item {\ttfamily output\-\_\-saver/}\-: contains a convenient class to save (on disk) different kinds of output results;
\item {\ttfamily share/}\-: contains functionalities shared between the objects, such as the message handling, the error management and some useful functions.


\end{DoxyItemize}




\hypertarget{installation}{}\section{Installation}\label{installation}


\-\emph{Verdandi} is supposed to be fully compliant with the {\bfseries \-C++ standard}. \-This ensures portability on many platforms. \-It compiles at least on \hyperlink{installation_linux}{\-Linux}, \hyperlink{installation_macos}{\-Mac\-O\-S} and \hyperlink{installation_windows}{\-Windows, 32-\/bit computer}. \-It is compatible with \-I\-D\-Es such as \-Xcode and \-Microsoft \-Visual \-Studio (tested on \-Visual \-C++ 2010).



\hypertarget{installation_linux}{}\subsection{\-Linux}\label{installation_linux}


\warning{Dependencies installations under linux}

\hypertarget{installation_installation_linux}{}\paragraph{\-Installation}\label{installation_installation_linux}


\-Download the source code (\href{http://verdandi.gforge.inria.fr/}{\tt \-\emph{Verdandi} homepage}), usually available in a compressed file, e.\-g., verdandi-\/\mbox{[}version\mbox{]}.tar.\-bz2.
\-Uncompress the file, e.\-g., in command line\-: {\ttfamily tar -\/xvjf verdandi-\/\mbox{[}version\mbox{]}.tar.\-bz2}.
\-This will create the directory {\ttfamily verdandi-\/\mbox{[}version\mbox{]}/} in which you will find \-Verdandi.



\hypertarget{installation_tests_linux}{}\paragraph{\-Testing the installation}\label{installation_tests_linux}


\-In order to start with \-Verdandi, it is sufficient to install \-S\-Cons. \-Make sure that the executable {\ttfamily scons} is available.

\-To compile one of the examples provided with \-Verdandi, run {\ttfamily scons} in the directory {\ttfamily example/quadratic\-\_\-model/}\-:


\begin{frame_bash}
host<~/> scons
\end{frame_bash}


\-Then to run the quadratic model example, execute the following commands\-:
\marginnote{
\begin{enumerate}
\item \-This program generates the observations by running the model with the true initial conditions described in {\ttfamily truth.\-lua}, without any error. \-It performs steps forward with the quadratic model without data assimilation.
\item \-This program applies the optimal interpolation, starting from erroneous initial conditions described in {\ttfamily assimilation.\-lua}. \-The observations are those generated above by {\ttfamily forward}.
\end{enumerate}
}

\begin{frame_bash}
host<~/> forward configuration/truth.lua [1.]
host<~/> optimal_interpolation configuration/assimilation.lua [2.]
\end{frame_bash}

\-This should generate results in the form of .bin files found in the directory {\ttfamily example/quadratic\-\_\-model/result/}.


\hypertarget{installation_macos}{}\subsection{\-Mac\-O\-S}\label{installation_macos}

\hypertarget{installation_installation_macos}{}\paragraph{\-Installation}\label{installation_installation_macos}

\-Installation instructions for \-Mac\-O\-S and \-Linux are nearly identical, except for a slight difference about the location of the directory where you have to put the files.

\hypertarget{installation_Xcodeproject}{}\paragraph{\-Create a \emph{Verdandi} Xcode project}\label{installation_Xcodeproject}

\begin{itemize}
\item \-Download \-\emph{Verdandi} and expand it to the directory of your choice ({\ttfamily \-M\-Y\-\_\-\-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-P\-A\-T\-H}).


\item \-Create a \-\emph{Verdandi} project within \-Xcode (\char`\"{}\-File -\/$>$ New Project\char`\"{}). \-In \char`\"{}\-Xcode/\-New Project\char`\"{}, select \char`\"{}\-Other/\-External Build System\char`\"{}. \-Choose a name ({\ttfamily verdandi}) and select the path to the source directory ({\ttfamily \-M\-Y\-\_\-\-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-P\-A\-T\-H}). \-In \char`\"{}\-Groups \& Files\char`\"{}, right click project name ({\ttfamily verdandi}), then choose \char`\"{}\-Add -\/$>$ Existing Files...\char`\"{} and add recursively the \-\emph{Verdandi} project directories.
\item {\bfseries \-Compiling under \-Xcode}\-: \par


1. \-In \char`\"{}\-Groups and Files -\/$>$ Targets\char`\"{}, right click \char`\"{}\-Targets\char`\"{} then select \char`\"{}\-Add -\/$>$ New Target...\char`\"{}, choose \char`\"{}other/\-External Target\char`\"{} and choose a name (for instance, {\ttfamily forward}).

2. \-In \char`\"{}\-Groups and Files -\/$>$ Targets\char`\"{}, double click the target that was created ({\ttfamily forward}).

3. \-In the \char`\"{}\-Build Tool\char`\"{} field, put the full path to scons (for example, \char`\"{}/usr/local/bin/scons\char`\"{}).

4. \-Set the \char`\"{}\-Directory\char`\"{} field to the directory that contains the \-S\-Construct file (for example, {\ttfamily \-M\-Y\-\_\-\-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-P\-A\-T\-H/example/clamped\-\_\-bar/}).

5. \-In \char`\"{}\-Build Settings\char`\"{}, specify the architectures to which the binary is targeted (for instance, \char`\"{}\-A\-R\-C\-H\-S = x86\-\_\-64\char`\"{}).

6. \-You should now be able to build using the \char`\"{}\-Build\char`\"{} command from \-Xcode.

7. \-Right click \char`\"{}\-Executables\char`\"{}, choose \char`\"{}\-Add new custom executable...\char`\"{}, make it point to the executable you are building, define the arguments (\char`\"{}configuration/truth.\-lua\char`\"{}) and then you can debug using \-Xcode.

\end{itemize}

\hypertarget{installation_windows}{}\subsection{\-Windows, 32-\/bit computer}\label{installation_windows}

\hypertarget{installation_windows_dependencies}{}\paragraph{\-Dependencies}\label{installation_windows_dependencies}

\begin{itemize}
\item {\bfseries \-S\-Cons} \par
 \-First install a 2.\-x version of \href{http://www.python.org/download/}{\tt \-Python} (preferably the latest 2.\-x version, but any version from 2.\-4 should be fine). \-Then install \href{http://www.scons.org/}{\tt \-S\-Cons}. \-Add the path of the \-S\-Cons program to the environment variable {\ttfamily \-P\-A\-T\-H} (right-\/click on \-My \-Computer -\/$>$ \-Properties -\/$>$ \-Advanced -\/$>$ \-Environment \-Variables).


\item {\bfseries \-Download precompiled libraries} \par


\-Not all the libraries are needed for all the methods, select and install the ones you will want to use in your assimilation.


\begin{itemize}
\item \-Lua (always required). \-On \href{http://luabinaries.sourceforge.net/download.html}{\tt the \-Lua \-Binaries webpage}, download the archive containing the \-Windows x86 \-D\-L\-L and \-Includes (at the time this page is written\-: {\ttfamily lua5\-\_\-1\-\_\-4\-\_\-\-Win32\-\_\-dll8\-\_\-lib.\-zip}). \-Extract the archive and put the extracted directory in your \-P\-A\-T\-H environment variable. \-In this directory, rename {\ttfamily lua51.\-lib} in {\ttfamily lua.\-lib}.
\end{itemize}


\begin{itemize}
\item \-Blas and \-Lapack (highly recommended). \-Download on \href{http://www.fi.muni.cz/~xsvobod2/misc/lapack/}{\tt this webpage} the archive for the shared version, statically-\/linked. \-Extract the archive to some directory. \-Add this directory to your {\ttfamily \-P\-A\-T\-H} environment variable. \-Inside the directory, rename {\ttfamily blas\-\_\-win32\-\_\-\-M\-T.\-lib} in {\ttfamily blas.\-lib} and {\ttfamily lapack\-\_\-win32\-\_\-\-M\-T.\-lib} in {\ttfamily lapack.\-lib}. \par

\end{itemize}


\begin{itemize}
\item \-Atlas (highly recommended). \-Download on \href{http://www.netlib.org/atlas/archives/windows/}{\tt this webpage} the file {\ttfamily atlas330\-\_\-\-Win\-N\-T\-\_\-\-P4\-S\-S\-E2.\-zip}. \-Extract the archive and put the extracted directory {\ttfamily \-Win\-N\-T\-\_\-\-P4\-S\-S\-E2} in your {\ttfamily \-P\-A\-T\-H} environment variable. \-Inside this directory, rename the {\ttfamily libcblas.\-a} in {\ttfamily cblas.\-lib} and {\ttfamily libatlas.\-a} in {\ttfamily atlas.\-lib}. \par

\end{itemize}




\begin{itemize}
\item \-If you need \-Super\-L\-U (needed only if one uses sparse matrices) see next paragraph.
\end{itemize}

\item {\bfseries \-Create SuperLU library} (optional)\par

Download the \-Super\-L\-U archive at \href{http://crd.lbl.gov/~xiaoye/SuperLU/}{\tt \-Super\-L\-U}. \-Take the sequential version 4.\-1 and expand it. \par


\-Within \-Microsoft \-Visual \-Studio, create a new \-Win32 \-Console \-Application. \-Start with an empty project. \-Then add to the project all the {\ttfamily .c} and {\ttfamily .h} files from {\ttfamily \-Super\-L\-U\-\_\-4.\-1$\backslash$\-S\-R\-C} directory (\-Project -\/$>$ \-Add existing item). \-Change the configuration to build a release version (\-Build -\/$>$ \-Configuration \-Manager -\/$>$ \-Configuration -\/$>$ \-Release). \par


\-Specify the {\ttfamily \-Super\-L\-U$\backslash$\-S\-R\-C} location in {\ttfamily \-Additional \-Include \-Directories} (\-Project -\/$>$ \-Properties -\/$>$ \-Configuration \-Properties -\/$>$ \-C/\-C++ -\/$>$ \-General). \-Change the property of the project to make the output as \-Library file {\ttfamily .lib} (neither {\ttfamily .exe} nor {\ttfamily .dll} file), in \-Project -\/$>$ \-Properties -\/$>$ \-Configuration \-Properties -\/$>$ \-General -\/$>$ \-Configuration \-Type. \par


\-Compile the project to produce the library file {\ttfamily superlu.\-lib} (\-Build -\/$>$ \-Build \-Solution).


\end{itemize}\hypertarget{installation_project}{}\paragraph{\-Create a \emph{Verdandi} project}\label{installation_project}


\begin{itemize}
\item \-Download \-\emph{Verdandi} and expand it to the directory of your choice.


\item \-Create a \char`\"{}\-New project from existing code file\char`\"{} in \-Visual. \-Select \-Visual \-C++ for the entry \char`\"{}\-Type of project\char`\"{}. \-Specify then the location of an example model directory in your version of \hyperlink{namespace_verdandi}{\-Verdandi}, e.\-g., {\ttfamily \-Verdandi-\/\mbox{[}version\mbox{]}$\backslash$example$\backslash$quadratic\-\_\-model}, and give a name to the project. \-On the \char`\"{}\-Project Settings\char`\"{} page, select \char`\"{}\-Use external build system\char`\"{}. \-Then put {\ttfamily scons} as the generic build command line and {\ttfamily scons -\/c} as the clean command line. \-Click on \-O\-K.
\end{itemize}


\hypertarget{installation_test}{}\paragraph{\-Run a test}\label{installation_test}


\begin{itemize}
\item \-You now have to configure the dependencies to the different libraries. \-In \char`\"{}\-Project -\/$>$ Properties -\/$>$ Configuration Properties -\/$>$ V\-C++ Directories\char`\"{}, add in the \char`\"{}\-Library Directories\char`\"{} the path to the different directories where your \char`\"{}.\-lib\char`\"{} files are. \-For example, if your \-Lua library is stored in the directory {\ttfamily \-C\-:$\backslash$\-Program \-Files$\backslash$\-Lua$\backslash$5.\-1$\backslash$lib}, add a new line with this path.

\-If you want to run the quadratic model, you have to link to the \-Lua, \-Blas, \-Lapack and \-Cblas libraries. \-Other models can require other libraries.




\item \-In \char`\"{}\-Project -\/$>$ Properties -\/$>$ Configuration Properties -\/$>$ N\-Make\char`\"{}, set the build command line to {\ttfamily scons forward.\-exe} and the rebuild command line to {\ttfamily scons -\/c \&\& scons forward.\-exe}. \-Set the output to {\ttfamily forward.\-exe}.


\item \-Compile with \char`\"{}\-Build -\/$>$ Build solution\char`\"{}. \-Specify the argument for {\ttfamily forward.\-exe}; i.\-e., put {\ttfamily configuration$\backslash$truth.\-lua} in \char`\"{}\-Configuration Properties -\/$>$ Debugging -\/$>$ Command Arguments\char`\"{}. \-To run the example, launch \char`\"{}\-Debug -\/$>$ Start Without Debugging\char`\"{}. \-If you are told that the executable is out of date, check the box so that you will not be asked again and click on {\ttfamily \-No} (do not rebuild the project).
\end{itemize}


\hypertarget{installation_alternative}{}\paragraph{\-Alternative method to run the tests}\label{installation_alternative}


\-Note that you can use the command prompt with the \-Visual command-\/line tools, in order to obtain the same results with an approach similar to that of \-Linux.

\begin{itemize}
\item \-Open the command prompt, either in \-Visual (in \char`\"{}\-Tools -\/$>$ Command prompt\char`\"{}), or from your computer \char`\"{}\-Start menu\char`\"{}\-: \char`\"{}\-All Programs -\/$>$ Microsoft Visual Studio -\/$>$ Visual Studio Command Prompt\char`\"{}. \-Then set the current directory to the example directory of \hyperlink{namespace_verdandi}{\-Verdandi} with the {\ttfamily cd} command. \-For instance, {\ttfamily cd \-C\-:$\backslash$\-Verdandi-\/\mbox{[}version\mbox{]}$\backslash$example$\backslash$quadratic\-\_\-model}.

\-You will then have to edit the {\ttfamily \-S\-Construct} file to \char`\"{}manually\char`\"{} add the links to the libraries needed to compile. \-Edit the {\ttfamily \-S\-Construct} file from the current directory, so that it looks like this\-:

 \begin{frame_python}
import os

# Put the path to Verdandi.
# Also editable from command line with option "verdandi".
verdandi_path = "C:\\verdandi-[version]"

flag_cpp = "/nologo /EHsc /MD"
linker = "LINK"
# Put here the list of directories containing the library files to be included.
include_path = [""]
# Put here the list of directories containing the .lib files.
library_path = ["C:\\Program Files\\Lua\\5.1\\lib", "C:\\Program Files\\Blas_Lapack","C:\\Program Files\\WinNT_P4SSE2"]

execfile(os.path.join(verdandi_path, "share\\SConstruct"))
\end{frame_python}



\item \-If you want to run the quadratic model, you have to add the \-Lua, \-Blas, \-Lapack and \-Cblas directories (containing lua.\-lib, blas.\-lib, lapack.\-lib and cblas.\-lib) in the \char`\"{}library\-\_\-path\char`\"{} variable. \-Other models can require other libraries to be added in this variable.

\-Then type {\ttfamily scons} in the command prompt. \-It should create all the executables for the quadratic model. \-To launch them, type the name of the executable followed by the appropriated configuration file. \-For example, {\ttfamily forward.\-exe configuration$\backslash$truth.\-lua} will apply the forward method using the configuration file \char`\"{}truth.\-lua\char`\"{}, and generate some result files in the {\ttfamily result} directory.
\end{itemize}

\hypertarget{installation_windows64}{}\subsection{\-Windows, 64-\/bit computer}\label{installation_windows64}

\hypertarget{installation_compiler}{}\paragraph{64-\/bit compiler for Visual Studio}\label{installation_compiler}

\-Depending on your version of \-Visual, a 64-\/bit compiler may or may not be available by default. \-Refer to \href{http://msdn.microsoft.com/en-us/library/hs24szh9.aspx}{\tt this table.} \-If not available, you can add one by installing the latest version of the \-Windows \-S\-D\-K, which contains 64-\/bit compilers for \-Visual \-Studio. \-At this time, the latest version is the 7.\-1, \href{http://www.microsoft.com/downloads/en/details.aspx?FamilyID=6b6c21d2-2006-4afa-9702-529fa782d63b&displaylang=en}{\tt available here}.

\hypertarget{installation_windows64_dependencies}{}\paragraph{\-Dependencies}\label{installation_windows64_dependencies}

\begin{itemize}
\item {\bfseries \-S\-Cons} \par
 \-First install a 2.\-x version of \href{http://www.python.org/download/}{\tt \-Python} (preferably the latest 2.\-x version, but any version from 2.\-4 should be fine). \-Then install \href{http://www.scons.org/}{\tt \-S\-Cons}. \-Add the path of the \-S\-Cons program to the environment variable {\ttfamily \-P\-A\-T\-H} (right-\/click on \-My \-Computer -\/$>$ \-Properties -\/$>$ \-Advanced -\/$>$ \-Environment \-Variables).


\item {\bfseries \-Download precompiled libraries} \par


\-Not all the libraries are needed for all the methods, select and install the ones you will want to use in your assimilation.


\begin{itemize}
\item \-Lua (always required). \-On \href{http://luabinaries.sourceforge.net/download.html}{\tt the \-Lua \-Binaries webpage}, download the archive containing the \-Windows x64 \-D\-L\-L and \-Includes (at the time this page is written\-: {\ttfamily lua5\-\_\-1\-\_\-4\-\_\-\-Win64\-\_\-dll8\-\_\-lib.\-zip}). \-Extract the archive and put the extracted directory in your \-P\-A\-T\-H environment variable. \-In this directory, rename {\ttfamily lua51.\-lib} in {\ttfamily lua.\-lib}.
\end{itemize}


\begin{itemize}
\item \-Atlas (highly recommended). \-Download on \href{http://www.netlib.org/atlas/archives/windows/}{\tt this webpage} the file {\ttfamily atlas330\-\_\-\-Win\-N\-T\-\_\-\-P4\-S\-S\-E2.\-zip}. \-Extract the archive and put the extracted directory {\ttfamily \-Win\-N\-T\-\_\-\-P4\-S\-S\-E2} in your {\ttfamily \-P\-A\-T\-H} environment variable. \-Inside this directory, rename the {\ttfamily libatlas.\-a} file in {\ttfamily atlas.\-lib}. \par

\end{itemize}


\item {\bfseries \-Create \-Blas and \-Lapack} (highly recommended) \par


\-You will have to build a 64-\/bit version of these two libraries with \-Visual \-C++. \-Follow the instructions given in section \char`\"{}\-Easy Windows Build\char`\"{} on the \href{http://icl.cs.utk.edu/lapack-for-windows/clapack/#build}{\tt \-C\-L\-A\-P\-A\-C\-K for \-Windows} page.

\-Open the \-A\-L\-L\-\_\-\-B\-U\-I\-L\-D \-Visual project in the new directory you created with \-C\-Make. \-Then in \-Visual, change the solution configuration from the default \-Debug to \-Release, and build the solution. \-This will create the three libraries we need \-: {\ttfamily blas.\-lib} (by default in the sub-\/directory {\ttfamily \-B\-L\-A\-S$\backslash$\-S\-R\-C$\backslash$\-Release$\backslash$}), {\ttfamily lapack.\-lib} (in {\ttfamily \-S\-R\-C$\backslash$\-Release$\backslash$}) and {\ttfamily libf2c.\-lib} (in {\ttfamily \-F2\-C\-L\-I\-B\-S$\backslash$libf2c$\backslash$\-Release$\backslash$}. \-For convenience, take these three files and put them in the same directory of your choice, for instance {\ttfamily \-C\-:$\backslash$\-Program \-Files$\backslash$\-Blas\-\_\-\-Lapack}.

\-At last, you will need the \-G\-N\-U \-Scientific \-Library. \-The latest version is at this time the \-G\-S\-L-\/1.\-14 \href{http://www.gnu.org/software/gsl/}{\tt available here}. \-Extract it to the directory of your choice, for example {\ttfamily \-C\-:$\backslash$gsl$\backslash$}. \-Then move the files {\ttfamily \-C\-:$\backslash$gsl$\backslash$gsl$\backslash$blas$\backslash$gsl\-\_\-cblas.\-h} and {\ttfamily \-C\-:$\backslash$gsl$\backslash$gsl$\backslash$sys$\backslash$gsl\-\_\-sys.\-h} to {\ttfamily \-C\-:$\backslash$gsl$\backslash$gsl$\backslash$}. \-Finally, rename the file {\ttfamily \-C\-:$\backslash$gsl$\backslash$gsl$\backslash$config.\-h.\-in} to {\ttfamily \-C\-:$\backslash$gsl$\backslash$gsl$\backslash$config.\-h}.





\item {\bfseries \-Create \-Super\-L\-U library} (optional) \par


\-Download the \-Super\-L\-U archive at \href{http://crd.lbl.gov/~xiaoye/SuperLU/}{\tt \-Super\-L\-U}. \-Take the sequential version 4.\-1 and expand it. \par


\-Within \-Microsoft \-Visual \-Studio, create a new \-Win32 \-Console \-Application. \-Start with an empty project. \-Then add to the project all the {\ttfamily .c} and {\ttfamily .h} files from {\ttfamily \-Super\-L\-U\-\_\-4.\-1$\backslash$\-S\-R\-C} directory (\-Project -\/$>$ \-Add existing item). \-Change the configuration to build a release version (\-Build -\/$>$ \-Configuration \-Manager -\/$>$ \-Configuration -\/$>$ \-Release). \par


\-Specify the {\ttfamily \-Super\-L\-U$\backslash$\-S\-R\-C} location in {\ttfamily \-Additional \-Include \-Directories} (\-Project -\/$>$ \-Properties -\/$>$ \-Configuration \-Properties -\/$>$ \-C/\-C++ -\/$>$ \-General). \-Change the property of the project to make the output as \-Library file {\ttfamily .lib} (neither {\ttfamily .exe} nor {\ttfamily .dll} file), in \-Project -\/$>$ \-Properties -\/$>$ \-Configuration \-Properties -\/$>$ \-General -\/$>$ \-Configuration \-Type. \par


\-Compile the project to produce the library file {\ttfamily superlu.\-lib} (\-Build -\/$>$ \-Build \-Solution).


\end{itemize}\hypertarget{installation_project}{}\paragraph{\-Create a \emph{Verdandi} project}\label{installation_project}

\begin{itemize}
\item \-Download \-\emph{Verdandi} and expand it to the directory of your choice.


\item \-Create a \char`\"{}\-New project from existing code file\char`\"{} in \-Visual. \-Select \-Visual \-C++ for the entry \char`\"{}\-Type of project\char`\"{}. \-Specify then the location of an example model directory in your version of \hyperlink{namespace_verdandi}{\-Verdandi}, e.\-g., {\ttfamily \-Verdandi-\/\mbox{[}version\mbox{]}$\backslash$example$\backslash$quadratic\-\_\-model}, and give a name to the project. \-On the \char`\"{}\-Project Settings\char`\"{} page, select \char`\"{}\-Use external build system\char`\"{}. \-Then put {\ttfamily scons} as the generic build command line and {\ttfamily scons -\/c} as the clean command line. \-Click on \-O\-K.
\end{itemize}

\hypertarget{installation_test}{}\paragraph{\-Run a test}\label{installation_test}

\begin{itemize}
\item \-Edit {\ttfamily \-S\-Construct} file from the current project directory so that it looks like this\-:



 \begin{frame_python}
import os

# Put the path to Verdandi.
# Also editable from command line with option "verdandi".
verdandi_path = "C:\\verdandi-[version]"

flag_cpp = "/nologo /EHsc /MD"
linker = "LINK"
# Put here the list of directories containing the GSL headers.
# One must include the top GSL directory and its subdirectory "gsl".
include_path = ["C:\\gsl", "C:\\gsl\\gsl"]
# Put here the list of directories containing lua.lib, blas.lib, lapack.lib and libf2c.lib.
library_path = ["C:\\Program Files\\lua64", "C:\\Program Files\\Blas_Lapack"]

import glob

# Replace also here "C:\\gsl\\" with the path to your GSL top directory.
dependency_list = [x for x in glob.glob('C:\\gsl\\gsl\\cblas\\*.c') if "test" not in x];

library_list = ["libf2c.lib"]

execfile(os.path.join(verdandi_path, "share\\SConstruct"))
\end{frame_python}


\-The quadratic model has dependencies to the \-Lua, \-Blas, \-Lapack and \-Cblas libraries, but other models can require to add some more paths to the {\ttfamily include\-\_\-path} and {\ttfamily library\-\_\-path} variables. \-As in 32-\/bit, you can add the library and include paths directly in the \-Visual configuration instead of adding them to the \char`\"{}include\-\_\-path\char`\"{} and \char`\"{}library\-\_\-path\char`\"{} variables in {\ttfamily \-S\-Construct}. \-To do this, go to \char`\"{}\-Project -\/$>$ Properties -\/$>$ Configuration Properties -\/$>$ V\-C++ Directories\char`\"{}, and add your include paths in the \char`\"{}\-Include Directories\char`\"{} entry, and add your library paths in the \char`\"{}\-Library Directories\char`\"{} entry.


\item \-Edit the \-Project -\/$>$ \-Properties. \-In \-Configuration \-Properties -\/$>$ \-N\-Make, set the build command line to {\ttfamily scons forward.\-exe} and the rebuild command line to {\ttfamily scons -\/c \&\& scons forward.\-exe}. \-Set the output to {\ttfamily forward.\-exe}. \-In \-Configuration \-Properties, set \char`\"{}\-Platform Tools\char`\"{} to the appropriate 64-\/bit kit (\char`\"{}\-Windows 7.\-1 S\-D\-K\char`\"{}, for example if you are using \-Visual \-C++ \-Express). \-If \char`\"{}\-Platform Tools\char`\"{} is not a visible entry, you may need to temporarily set the \char`\"{}\-Configuration type\char`\"{} to another type than \-Makefile (\char`\"{}\-Application (.\-exe)\char`\"{}, for example). \-Be sure to switch back the \char`\"{}\-Configuration type\char`\"{} to \-Makefile, right after selecting the platform tool.


\item \-Compile with \-Build -\/$>$ \-Build solution. \-Specify the argument for {\ttfamily forward.\-exe}; i.\-e., put {\ttfamily configuration$\backslash$truth.\-lua} in \-Configuration \-Properties -\/$>$ \-Debugging -\/$>$ \-Command \-Arguments. \-To run the example, launch \-Debug -\/$>$ \-Start \-Without \-Debugging. \-If you are told that the executable is out of date, check the box so that you will not be asked again and click on {\ttfamily \-No} (do not rebuild the project).
\end{itemize}

\hypertarget{installation_alternative}{}\paragraph{\-Alternative method to run the tests}\label{installation_alternative}


\-Note that you can use the command prompt with the \-Visual command-\/line tools, in order to obtain the same results with an approach similar to that of \-Linux.
\begin{itemize}
\item \-Open the command prompt, either in \-Visual (in \char`\"{}\-Tools -\/$>$ Command prompt\char`\"{}), or from your computer \char`\"{}\-Start menu\char`\"{}\-: \char`\"{}\-All Programs -\/$>$ Microsoft Visual Studio -\/$>$ Visual Studio Command Prompt\char`\"{}. \-Then set the current directory to the example directory of \hyperlink{namespace_verdandi}{\-Verdandi} with the {\ttfamily cd} command. \-For instance, {\ttfamily cd \-C\-:$\backslash$\-Verdandi-\/\mbox{[}version\mbox{]}$\backslash$example$\backslash$quadratic\-\_\-model}.

\-You will then have to edit the {\ttfamily \-S\-Construct} file to \char`\"{}manually\char`\"{} add the links to the libraries needed to compile. \-Edit the {\ttfamily \-S\-Construct} file from the current directory, so that it looks like this\-:

\begin{frame_python}
import os

# Put the path to Verdandi.
# Also editable from command line with option "verdandi".
verdandi_path = "C:\\verdandi-[version]"

flag_cpp = "/nologo /EHsc /MD"
linker = "LINK"
# Put here the list of directories containing the GSL headers.
# One must include the top GSL directory and its subdirectory "gsl".
include_path = ["C:\\gsl", "C:\\gsl\\gsl"]
# Put here the list of directories containing lua.lib, blas.lib, lapack.lib and libf2c.lib.
library_path = ["C:\\Program Files\\lua64", "C:\\Program Files\\Blas_Lapack"]

import glob

# Replace also here "C:\\gsl\\" with the path to your GSL top directory.
dependency_list = [x for x in glob.glob('C:\\gsl\\gsl\\cblas\\*.c') if "test" not in x];

library_list = ["libf2c.lib"]

execfile(os.path.join(verdandi_path, "share\\SConstruct"))
\end{frame_python}



\item \-If you want to run the quadratic model, you have to add the \-Lua, \-Blas, \-Lapack and \-Cblas directories (containing lua.\-lib, blas.\-lib, lapack.\-lib and cblas.\-lib) in the \char`\"{}library\-\_\-path\char`\"{} variable. \-Other models can require other libraries to be added in this variable.

\-Then type {\ttfamily scons} in the command prompt. \-It should create all the executables for the quadratic model. \-To launch them, type the name of the executable followed by the appropriated configuration file. \-For example, {\ttfamily forward.\-exe configuration$\backslash$truth.\-lua} will apply the forward method using the configuration file \char`\"{}truth.\-lua\char`\"{}, and generate some result files in the {\ttfamily result} directory.
\end{itemize}






\hypertarget{example_programs}{}\section{Example Programs}\label{example_programs}

\-All examples are located in the {\ttfamily example} directory.\marginnote{To have a summary of \emph{Verdandi} contents see Section \ref{overview}.}

\hypertarget{example_programs_shallow_water}{}\subsection{\-Shallow Water}\label{example_programs_shallow_water}

\-The \hyperlink{shallow_water}{\-Shallow \-Water model} describes the flow below a pressure surface in a fluid. \-The different boundary and initial conditions are described in the configuration files in {\ttfamily example/shallow\-\_\-water/configuration}.

\-First compile the examples with
\begin{frame_bash}
host<~/> scons
\end{frame_bash}
  in the directory {\ttfamily example/shallow\-\_\-water}. \-This will compile an example with {\ttfamily  \hyperlink{class_verdandi_1_1_forward_driver}{\-Forward\-Driver}} and an example with {\ttfamily  \hyperlink{class_verdandi_1_1_optimal_interpolation}{\-Optimal\-Interpolation}} (see the documentation of \hyperlink{optimal_interpolation}{optimal interpolation}).

\hypertarget{notation_observations}{}\paragraph{\-Observations}\label{notation_observations}

\-Since no observations are given yet, we have to generate some. \-Execute the following command\-:
\begin{frame_bash}
host<~/> forward configuration/truth.lua
\end{frame_bash}
  to run the model with the initial conditions described in {\ttfamily truth.\-lua}, without data assimilation. \-This should generate a few result files in the directory {\ttfamily example/shallow\-\_\-water/result/}. \-The water height is stored in the file {\ttfamily truth-\/state\-\_\-forecast.\-bin}, and the horizontal velocity along x and y in respectively {\ttfamily u.\-bin} and {\ttfamily v.\-bin}. \-These files store time trajectories.

\-The generated state (water height) will serve as observations for the assimilation. \-To plot it, you can use \href{http://ipython.scipy.org/}{\tt \-I\-Python} with the module pylab. \-Refer to the \hyperlink{python}{\-Python} section to make sure you can use the \-Python interface of \hyperlink{namespace_verdandi}{\-Verdandi}.

\-The following code will plot the water height at time t=0 and t=10.

\begin{frame_python}
>> ipython -pylab

In  [1]: from verdandi import *
In  [2]: truth = load_vector_list("result/truth-state_forecast.bin")
In  [3]: plot(truth[0], label = "time t=0")
In  [4]: plot(truth[10], label = "time t=10")
In  [5]: legend()

\end{frame_python}


\-This should be the output\-:

\includegraphics{image/shallow_water_truth_t0_10.png}

\-The initial condition is a rectangular function in the center and the boundary condition is a flow from the left side. \-These conditions are described in {\ttfamily example/shallow\-\_\-water/configuration/shallow\-\_\-water.\-lua}.

\hypertarget{example_programs_assimilation}{}\paragraph{\-Data assimilation with optimal interpolation}\label{example_programs_assimilation}

\-The observations are here managed by the \hyperlink{linear_observation_manager}{Linear Observation Manager}. \-The parameters for the observations are stored in {\ttfamily example/shallow\-\_\-water/configuration/observation.\-lua}. \-By default, the observation operator is a scaled identity matrix with diagonal values of 1, which means that the whole state is observed. \-For a more illustrative example, we can choose to restrain the observations to specific components of the state.

\-In the file {\ttfamily example/shallow\-\_\-water/configuration/observation.\-lua}, change the parameter {\ttfamily observation.\-operator.\-scaled\-\_\-identity} from {\ttfamily true} to {\ttfamily false} and put the following code at the end of the file \-:
\begin{frame_lua}
for i = 1, 100 do
   for j = 1, 3 do
      observation.operator.value[(i-1)*3 + j] = 0.
   end
end

observation.operator.value[80] = 1.
observation.operator.value[100 + 81] = 1.
observation.operator.value[200 + 82] = 1.
\end{frame_lua}
  \-This will restrict the observations to three components of the water height vector with indexes 79, 80 and 81. \-See the \hyperlink{linear_observation_manager}{\-Linear \-Observation \-Manager} linear documentation about \-Linear\-Observation\-Manager for further details. \-Note that the indexes in \-Lua structures start at 1 while the indexes in the rest of \hyperlink{namespace_verdandi}{\-Verdandi} (\-Python, \-C++, documentation, integers given in the configuration) start at 0.

\-To use the \hyperlink{optimal_interpolation}{\-Optimal \-Interpolation} method, execute the following command.

\begin{frame_bash}
host<~/> optimal_interpolation configuration/assimilation.lua
\end{frame_bash}

  \-This runs the model with the initial conditions described in {\ttfamily example/shallow\-\_\-water/configuration/assimilation.\-lua}. \-This should generate several files in the directory {\ttfamily result/}. \-The analysis states $x^a_h$ are stored in the file {\ttfamily result/oi-\/state\-\_\-analysis.\-bin}, the forecasted state $x^f_h$ in {\ttfamily oi-\/state\-\_\-forecast.\-bin} and the horizontal velocity along x and y in respectively {\ttfamily result/u.\-bin} and {\ttfamily result/v.\-bin}.

\-We can now observe the results of data assimilation.
\begin{frame_python}
>> ipython -pylab

In  [1]: from verdandi import *
In  [2]: truth = load_vector_list("result/truth-state_forecast.bin")
In  [3]: oi_state_forecast = load_vector_list("result/oi-state_forecast.bin")
In  [4]: oi_state_analysis = load_vector_list("result/oi-state_analysis.bin")
In  [5]: x=10; plot(truth[x]); plot(oi_state_forecast[x]); plot(oi_state_analysis[x])
\end{frame_python}


\-The previous script should give the following result\-:

\includegraphics{image/shallow_water_t10.png}


\-Since we have restricted the observations to the points x = 79, 80 and 81, and since the observations have the same values as the forecast at these locations (that is, 1), the increment $y_h - H_h x_h$ is zero and the assimilation has no impact.

\-Let us take a look at a later time step. \-In the same ipython console, type\-:

 \begin{frame_python}
In  [6]: clf()
In  [7]: x=20; plot(truth[x]); plot(oi_state_forecast[x]); plot(oi_state_analysis[x])
\end{frame_python}


for the following result\-:

\includegraphics{image/shallow_water_t20.png}

 \-Here, the observed wave originating from the rectangular initial condition has reached the observed locations. \-This produces an analysis which corrects the forecasted state $x_h^f$ (in green) according to the observations. \-This analysis $x^a_h$ is then reinjected in the model for the next time step $h+1$.

The correction is \-more pronounced at t=30\-:

 \begin{frame_python}
In  [8]: clf()
In  [9]: x=30; plot(truth[x]); plot(oi_state_forecast[x]); plot(oi_state_analysis[x])
\end{frame_python}


\includegraphics{image/shallow_water_t30.png}




\-Let us change the parameters in the configuration files and see the effects. \-For example, in {\ttfamily example/shallow\-\_\-water/configuration/shallow\-\_\-water.\-lua}, change the value of {\ttfamily shallow\-\_\-water.\-state\-\_\-error.\-variance} from {\ttfamily 100.} to {\ttfamily 25.}.

\-Execute optimal\-\_\-interpolation once again and visualize the results\-:

\begin{frame_python}
>> optimal_interpolation configuration/assimilation.lua

>> ipython -pylab

In  [1]: from verdandi import *
In  [2]: truth = load_vector_list("result/truth-state_forecast.bin")
In  [3]: oi_state_forecast = load_vector_list("result/oi-state_forecast.bin")
In  [4]: oi_state_analysis = load_vector_list("result/oi-state_analysis.bin")
In  [5]: x=30; plot(truth[x]); plot(oi_state_forecast[x]); plot(oi_state_analysis[x])
\end{frame_python}

\includegraphics{image/shallow_water_t30_2.png}


\-Since we lowered the variance of the state error (diagonal of $B_h$), the analysis stays closer to the forecast.

\hypertarget{example_programs_clamped_bar}{}\subsection{\-Clamped Bar}\label{example_programs_clamped_bar}

\-The \hyperlink{clamped_bar}{\-Clamped \-Bar model} describes the vibration of a bar clamped at one end. \-The boundary and initial conditions are described in the configuration files found in {\ttfamily example/clamped\-\_\-bar/configuration}.

\-First compile the examples with
\begin{frame_bash}
host<~/> scons
\end{frame_bash}
  in the directory {\ttfamily example/clamped\-\_\-bar}. \-This will compile an example with each of the {\bfseries data assimilation methods} {\ttfamily  \hyperlink{class_verdandi_1_1_forward_driver}{\-Forward\-Driver}}, {\ttfamily  \hyperlink{class_verdandi_1_1_optimal_interpolation}{\-Optimal\-Interpolation}} (\hyperlink{optimal_interpolation}{optimal interpolation}), {\ttfamily  \hyperlink{class_verdandi_1_1_extended_kalman_filter}{\-Extended\-Kalman\-Filter}} (\hyperlink{extended_kalman_filter}{extended \-Kalman filter}), {\ttfamily  \hyperlink{class_verdandi_1_1_unscented_kalman_filter}{\-Unscented\-Kalman\-Filter}} (\hyperlink{unscented_kalman_filter}{unscented \-Kalman filter}), {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_extended_kalman_filter}{\-Reduced\-Order\-Extended\-Kalman\-Filter}} (\hyperlink{reduced_order_extended_kalman_filter}{reduced order extended \-Kalman filter}), {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_unscented_kalman_filter}{\-Reduced\-Order\-Unscented\-Kalman\-Filter}} (\hyperlink{reduced_order_unscented_kalman_filter}{reduced order unscented \-Kalman filter}), and {\ttfamily  \hyperlink{class_verdandi_1_1_four_dimensional_variational}{\-Four\-Dimensional\-Variational}} (\hyperlink{four_dimensional_variational}{four dimensional variational}).

  \hypertarget{notation_observations}{}\paragraph{\-Observations}\label{notation_observations}

\-Since no observations are given yet, we have to generate some. \-Execute the following command\-:
\begin{frame_bash}
host<~/> forward configuration/truth.lua
\end{frame_bash}
  to run the model with the initial conditions described in {\ttfamily truth.\-lua}, without data assimilation. \-This should generate a result file ({\ttfamily truth-\/state\-\_\-forecast.\-bin}) in the directory {\ttfamily example/clamped\-\_\-bar/result/}. \-This file store the state (displacement, velocity, $ \theta_{f} $) trajectory.

\-The generated state (displacement, velocity, $ \theta_{f} $) will serve as observations for the assimilation. \-To plot it, you can use \href{http://ipython.scipy.org/}{\tt \-I\-Python} with the module pylab. \-Refer to the \hyperlink{python}{\-Python} section to make sure you can use the \-Python interface of \hyperlink{namespace_verdandi}{\-Verdandi}.

\-The following code will plot the displacement at time t=0 and t=10.

\begin{frame_python}
>> ipython -pylab

In  [1]: from verdandi import *
In  [2]: truth = load_vector_list("result/truth-state_forecast.bin")
In  [3]: N = 10
In  [4]: v = truth[0]
In  [5]: v.Resize(N)
In  [6]: w = truth[1000]
In  [7]: w.Resize(N)
In  [8]: plot(v); plot(w);legend(("time=0", "time=10"), "upper left");

\end{frame_python}


\-The output should look something like this\-:

\includegraphics{image/clamped_bar_truth_t0_10.png}

\-At the initial time, the bar is fixed and horizontal.

\-During the simulation, a force $F(\theta_f) = \sin(\frac{\pi t}{t_f}) M_{\theta_f} (1 ... 1)^T$ is applied to the bar at each point. \-For the parameter $ \theta_f $, we supposed that the bar is divided into two regions of the same length. \-In the first region (\mbox{[}0, 4\mbox{]}), we have $ \theta_f = 1.5 $ while, in the second region (\mbox{[}5, 9\mbox{]}), we have $ \theta_f = 1.7$. \-These conditions are described in {\ttfamily example/clamped\-\_\-bar/configuration/clamped\-\_\-bar.\-lua}.

\hypertarget{example_programs_assimilation2}{}\paragraph{\-Data assimilation with R\-O\-E\-K\-F and R\-O\-U\-K\-F.}\label{example_programs_assimilation2}

\-The observations are managed by the \hyperlink{linear_observation_manager}{linear observation manager}. \-The parameters for the observations are stored in {\ttfamily example/clamped\-\_\-bar/configuration/observation.\-lua}. \-By default, the observation operator is a scaled identity matrix with diagonal values of 1, which means that the whole state is observed. \-For a more illustrative example, we can choose to restrain the observations to specific components of the state.

\-In the file {\ttfamily example/clamped\-\_\-bar/configuration/observation.\-lua}, change the parameter {\ttfamily observation.\-operator.\-scaled\-\_\-identity} from {\ttfamily true} to {\ttfamily false} and put the following code at the end of the file \-:
\begin{frame_lua}
Nstate = 22
Nobservation = 10
for i = 1, Nobservation * Nstate do
    observation.operator.value[i] = 0.
end
for i = 1, Nobservation do
    for j = 1, Nobservation do
        if i == j then
            observation.operator.value[Nstate * (i - 1) + j] = 1.0
        end
    end
end
\end{frame_lua}
  \-This will restrict the observations to the displacements. \-See the \hyperlink{linear_observation_manager}{\-Linear \-Observation \-Manager} documentation for further details. \-Note that the indexes in \-Lua structures start at 1 while the indexes in the rest of \hyperlink{namespace_verdandi}{\-Verdandi} (\-Python, \-C++, documentation, integers given in the configuration) start at 0.

\-To use the \hyperlink{reduced_order_extended_kalman_filter}{\-Reduced \-Order \-Extended \-Kalman \-Filter} and the \hyperlink{reduced_order_unscented_kalman_filter}{\-Reduced \-Order \-Unscented \-Kalman \-Filter} methods, execute the following commands.
\begin{frame_bash}
host<~/> reduced_order_extended_kalman_filter configuration/assimilation.lua
host<~/> reduced_order_unscented_kalman_filter configuration/assimilation.lua
\end{frame_bash}
  \-This runs the model with the initial conditions described in {\ttfamily example/clamped\-\_\-bar/configuration/assimilation.\-lua}. \-The simulation begins with erroneous values for the parameter $ \theta_f $. \-This should generate several files in the directory {\ttfamily result/}. \-The analysis states $x^a_h$ are stored in the files {\ttfamily result/roekf-\/state\-\_\-analysis.\-bin} and {\ttfamily result/roukf-\/state\-\_\-analysis.\-bin}, the forecasted state $x^f_h$ in {\ttfamily roekf-\/state\-\_\-forecast.\-bin} and {\ttfamily roukf-\/state\-\_\-forecast.\-bin}.

\-We can now observe the results of data assimilation.

\begin{frame_python}
>> ipython -pylab

In  [1]: from verdandi import *
In  [2]: N = 22
In  [3]: roekf = loadtxt("result/roekf-state_analysis.dat", usecols = range(0, N))
In  [4]: roukf = loadtxt("result/roukf-state_analysis.dat", usecols = range(0, N))
In  [5]: x = 20; plot(roekf[:, x]); plot(roukf[:, x]);legend(("roekf", "roukf"), "lower right");
In  [6]: clf()
In  [7]: x = 21; plot(roekf[:, x]); plot(roukf[:, x]);legend(("roekf", "roukf"), "lower right");
\end{frame_python}


\-This should plot\-:

\includegraphics{image/clamped_bar_1.png}

\includegraphics{image/clamped_bar_2.png}


\-Since the \hyperlink{clamped_bar}{\-Clamped \-Bar model} is linear with respect to the parameter $ \theta_f $, the \hyperlink{reduced_order_extended_kalman_filter}{\-Reduced \-Order \-Extended \-Kalman \-Filter} and the \hyperlink{reduced_order_unscented_kalman_filter}{\-Reduced \-Order \-Unscented \-Kalman \-Filter} methods give the same results. \-In this simulation, we start from erroneous values of the parameter $ \theta_f = (1.0, 1.0)$ and the methods converge to the correct values $ (1.5, 1.7)$.






\hypertarget{models}{}\section{Example Models}\label{models}

\-Several {\bfseries models} have been implemented in \-Verdandi.

\-Follow the links below for a description of four available {\bfseries models}\-:


\begin{itemize}
\item \hyperlink{quadratic_model}{\-Quadratic \-Model};
\item \hyperlink{shallow_water}{\-Shallow-\/water};
\item \hyperlink{clamped_bar}{\-Clamped \-Bar};
\item \hyperlink{lorenz}{\-Lorenz \-Model}.
\end{itemize}

\-For details about how to apply {\bfseries data assimilation methods} on these models see \hyperlink{example_programs}{\-Example \-Programs}.

\hypertarget{quadratic_model}{}\subsection{Quadratic Model}\label{quadratic_model}

\-In order to define the quadratic model, we introduce\-:
\begin{itemize}
\item $n$ matrices $ S_i \in \mathbb{R}^{n \times n} $ for the quadratic part of the model,
\item one matrix $ L \in \mathbb{R}^{n \times n} $ for the linear part of the model, and
\item a vector $b \in \mathbb{R}^n $ for the constant part of the model.
\end{itemize}

\-The equation of the $i$th state component of the quadratic model ( $ i \in \{1,\ldots,n\}$) is \[ \frac{\mathrm{d} x_i}{\mathrm{d} t} = x^T S_i x + L_i x + b_i, \] where $L_i$ is the $i$th line of $L$.

\-In case the model has no quadratic part, the state equation is simply \[ \frac{\mathrm{d} x}{\mathrm{d} t} = L x + b. \]


\hypertarget{shallow_water}{}\subsection{Shallow Water}\label{shallow_water}

The shallow-\/water equations (also called Saint Venant equations) are a set of hyperbolic partial differential equations that describe the flow below a pressure surface in a fluid. It is suitable for flows with a free surface and small depth. For instance, these equations can be applied to model the behavior of a lake or a river. The model describes the evolution of the water height $h(x,y)$ and the horizontal velocity $(u(x,y),v(x,y))$. A simplified expression of the model is


\begin{center} $\partial_th + \partial_x(hu) + \partial_y(hv) = 0$ \par
 $\partial_t(hu) + \partial_x(huu) + \partial_y(huv) +\frac{1}2g\partial_xh^2 = 0$ \par
 $\partial_t(hv) + \partial_x(huv) + \partial_y(hvv) +\frac{1}2g\partial_yh^2 = 0$ \par
 \end{center}

One can define several boundary conditions:
\begin{enumerate}
\item an incoming flow rate $q_b = h_bu_b$ (or $q_b = h_bv_b$ along $y$), with the sign of $u_b$ (or $v_b$) being determined by the considered boundary (for instance, $u \le 0$ on the right boundary);
\item a homogeneous Neumann condition for $(h, u, v)$;
\item an impermeability condition: the flow rate is zero at the boundary;
\item a fixed height $h_b$.
\end{enumerate}

The shallow-\/water model is implemented in {\ttfamily \hyperlink{_shallow_water_8hxx_source}{ShallowWater.hxx}} and {\ttfamily \hyperlink{_shallow_water_8cxx_source}{ShallowWater.cxx}}. The class {\ttfamily  \hyperlink{class_verdandi_1_1_shallow_water}{ShallowWater}} is a template class: {\ttfamily ShallowWater$<$T$>$}. {\ttfamily T} is the numerical type of the variables (e.g., {\ttfamily double}).

The state contains:
\begin{itemize}
\item the water height (stored in the matrix {\ttfamily h\_\-});
\item the horizontal velocity along x (stored in matrix {\ttfamily u\_\-});
\item the horizontal velocity along y (stored in matrix {\ttfamily v\_\-}).
\end{itemize}


\hypertarget{clamped_bar}{}\subsection{Clamped Bar}\label{clamped_bar}

The clamped bar model describes the vibration of a still bar clamped at one end. The bar is discretized with {\ttfamily Nx} finite elements of the same length. With the hypothesis of \char`\"{}small displacements\char`\"{}, it follows the set of linear equations:

\begin{center} $ M_{\theta_m} \ddot Y + C_{\theta_c} \dot Y + K_{\theta_k} Y = F_{\theta_f}$ \par
 \end{center}

where $M_{\theta_m}$ is the mass matrix, $K_{\theta_k}$ is the stiffness matrix, $C_{\theta_c} = \alpha M_{\theta_c} + \beta M_{\theta_c} $ is the damp matrix and $F(\theta_f) = \sin(\frac{\pi t}{t_f}) M_{\theta_f} (1 ... 1)^T$ is the effort vector.

The clamped bar model is solved numerically using a Newmark scheme (middle point) for integration in time:

$ \ddot Y_{h + \frac{1}{2}} = \frac{\ddot Y_{h+1} + \ddot Y_{h} }2 = \frac{\dot Y_{h+1} - \dot Y_{h} } {\Delta t} $ \par
 $ \dot Y_{h + \frac{1}{2}} = \frac{\dot Y_{h+1} + \dot Y_{h} }2 = \frac{Y_{h+1} - Y_{h} } {\Delta t} $ \par



\hypertarget{lorentz}{}\subsection{Lorentz}\label{lorentz}

\-The \-Lorenz model is a 3-\/dimensional chaotic system. \-The equations of the model are\-:

\begin{center} $\partial_tx = Pr (y - x)$\par
 $\partial_ty = x (Ra - z) -y$ \par
 $\partial_tz = xy - b z$ \par
 \end{center}

where $Pr$ is the \-Prandtl number, $Ra$ the \-Rayleigh number, and $b$ is positive number.

\-The \-Lorenz model is implemented in {\ttfamily \hyperlink{_lorenz_8hxx_source}{\-Lorenz.\-hxx}} and {\ttfamily \hyperlink{_lorenz_8cxx_source}{\-Lorenz.\-cxx}}. \-The class {\ttfamily  \hyperlink{class_verdandi_1_1_lorenz}{\-Lorenz}} is a template class\-: {\ttfamily \-Lorenz$<$\-T$>$}. {\ttfamily \-T} is the numerical type of the variables (e.\-g., {\ttfamily double}).

\-The state vector is $(x, y, z)$.


\hypertarget{observations}{}\section{Example Observation Managers}\label{observations}


\-Two example {\bfseries observation managers} have been implemented in \hyperlink{namespace_verdandi}{\-Verdandi}\-:\marginnote{To have an overview of \emph{Verdandi} contents see Section \ref{overview}.}


\begin{DoxyItemize}
\item \hyperlink{linear_observation_manager}{linear observation manager};
\item \hyperlink{grid_to_network_observation_manager}{grid to network observation manager}.
\end{DoxyItemize}

\-An {\bfseries observation aggregator} which allows to compute aggregated (in time) and flattened observations is also available\-:
\begin{DoxyItemize}
\item \hyperlink{observation_aggregator}{observation aggregator}.
\end{DoxyItemize}

\-The \hyperlink{observation_aggregator}{observation aggregator} is coupled with the \hyperlink{linear_observation_manager}{linear observation manager}. \-One can use the \hyperlink{observation_aggregator}{observation aggregator} in his own {\bfseries observation manager}. \-For more detail about how to write a new {\bfseries observation manager} see \hyperlink{plugging_observation}{this page}.

\hypertarget{linear_observation_manager}{}\subsection{Linear Observation Manager}\label{linear_observation_manager}

\-This observation manager defines a linear observation operator $\mathcal{H}_h = H$, where $H$ is a time-\/independent matrix.

\-The class {\ttfamily  \hyperlink{class_verdandi_1_1_linear_observation_manager}{\-Linear\-Observation\-Manager}} is implemented in {\ttfamily \hyperlink{_linear_observation_manager_8hxx_source}{\-Linear\-Observation\-Manager.\-hxx}} and {\ttfamily \hyperlink{_linear_observation_manager_8cxx_source}{\-Linear\-Observation\-Manager.\-cxx}}. \-It is a template class\-: {\ttfamily \-Linear\-Observation\-Manager$<$\-T$>$}. {\ttfamily \-T} is the numerical type (e.\-g., {\ttfamily double}).

\hypertarget{linear_observation_manager_observation1}{}\paragraph{\-Management of the observations}\label{linear_observation_manager_observation1}

\-The observations should be available in binary format. \-One should define the path to the file storing the observations in the configuration file \-:

 \begin{frame_lua}
observation = {

   file = observation_file,
    ...
   }
\end{frame_lua}


\-One should also define the period with which observations are available.

\-At each time $t_h$, the provided observations can be an approximation of either the whole model state $x^t_{h}$ or the observations $\mathcal{H}_h(x^t_h)$ only.\hypertarget{linear_observation_manager_sub12}{}\paragraph{\-Observation contributions}\label{linear_observation_manager_sub12}
\-When a {\bfseries data assimilation method} requests for observations to the {\ttfamily  \hyperlink{class_verdandi_1_1_linear_observation_manager}{\-Linear\-Observation\-Manager}} at a given time $t_h$, it is possible that no observation is available at this time.\-The {\ttfamily  \hyperlink{class_verdandi_1_1_linear_observation_manager}{\-Linear\-Observation\-Manager}} associates to each available observation $y_i$ a contribution $ \alpha_i$. \-The \hyperlink{observation_aggregator}{observation aggregator} enables to compute, at each time $t_h$, the contribution $\alpha_i$ according to several rules\-: 'step', 'interpolation', 'triangle'.\hypertarget{linear_observation_manager_observation2}{}\paragraph{\-Observation operator}\label{linear_observation_manager_observation2}
\-There are two ways to define the observation operator.

\-One can use a \-Lua table to define the observation operator\-:

 \begin{frame_lua}
observation = {

    ...
   operator = {

        ...
      value = {1, 0, 0, 0
               0, 0, 1, 0}

   },
    ...

\end{frame_lua}


\-It is also possible to define the observation operator in binary format. \-One should define the path to the file storing the observation operator.\hypertarget{linear_observation_manager_observation3}{}\paragraph{\-Observation error variance}\label{linear_observation_manager_observation3}



\hypertarget{grid_to_network_observation_manager}{}\subsection{Grid to Network Observation Manager}\label{grid_to_network_observation_manager}

\-This observation manager defines a grid-\/to-\/network observation operator $\mathcal{H}_h = H$, where $H$ is a time-\/independent matrix.

\-It is implemented in {\ttfamily \hyperlink{_grid_to_network_observation_manager_8hxx_source}{\-Grid\-To\-Network\-Observation\-Manager.\-hxx}} and {\ttfamily \hyperlink{_grid_to_network_observation_manager_8cxx_source}{\-Grid\-To\-Network\-Observation\-Manager.\-cxx}}. \-The class {\ttfamily  \hyperlink{class_verdandi_1_1_grid_to_network_observation_manager}{\-Grid\-To\-Network\-Observation\-Manager}} is a template class\-: {\ttfamily \-Grid\-To\-Network\-Observation\-Manager$<$\-T$>$}. {\ttfamily \-T} is the numerical type (e.\-g., {\ttfamily double}).



\hypertarget{observation_aggregator}{}\subsection{Observation Aggregator}\label{observation_aggregator}


\-The \hyperlink{observation_aggregator}{\-Observation \-Aggregator} allows to compute aggregated and flattened observations. \-The class {\ttfamily  \hyperlink{class_verdandi_1_1_observation_aggregator}{\-Observation\-Aggregator}} is implemented in {\ttfamily \hyperlink{_observation_aggregator_8hxx_source}{\-Observation\-Aggregator.\-hxx}} and {\ttfamily \hyperlink{_observation_aggregator_8cxx_source}{\-Observation\-Aggregator.\-cxx}}. \-It is a template class\-: {\ttfamily \-Observation\-Aggregator$<$\-T$>$}. {\ttfamily \-T} is the numerical type (e.\-g., {\ttfamily double}).

\hypertarget{observation_aggregator_step}{}\paragraph{\-Step interpolation}\label{observation_aggregator_step}
\-In this mode, any observation is selected if its date belongs to a left-\/closed and right-\/open interval centered on $t_h$.

 \begin{frame_lua}
aggregator = {

   type = "step",
   width_left = 0.05,
   width_right = 0.07,
    ...
\end{frame_lua}
 \hypertarget{observation_aggregator_interpolation}{}\paragraph{\-Interpolation}\label{observation_aggregator_interpolation}
\-In this mode, the closest left observation from $t_h$ and the closest right observation are selected. \-The two observations are then interpolated. \-One should define an observation interval. \-It is assumed that the observations outside this interval have no contribution.

 \begin{frame_lua}
aggregator = {

   type = "interpolation",
   -- Observation interval.
   width_left_upper_bound = 1.,
   width_right_upper_bound = 1.,
    ...
\end{frame_lua}
 \hypertarget{observation_aggregator_triangle}{}\paragraph{\-Triangle interpolation}\label{observation_aggregator_triangle}
\-In this mode, one should define an observation interval (left-\/closed and right-\/open). \-All observations available in this interval are considered. \-The observations outside this interval have no contribution. \-They are interpolated by a triangle centered on $t_h$. \-The widths of the triangles may not be constant.

 \begin{frame_lua}
observation = {
    ...

   width_file = "configuration/width.bin",

   aggregator = {

      type = "triangle",
      width_property = "per-observation",
      -- Observation interval.
      width_left_upper_bound = 1.,
      width_right_upper_bound = 1.,
       ...
\end{frame_lua}





\section{Python Interface}


\-\emph{Verdandi} comes with a \-Python interface generated by \href{http://www.swig.org/}{\tt \-Swig}.

\-This page only addresses the compilation and the use of the interface under \-Linux, \-Mac\-O\-S and \-Windows. \-The generation of the interface was not tested on another platform yet. \-No known issue should prevent the interface from running successfully on another platform.

\hypertarget{python_ipython}{}\subsection{\-I\-Python and Matplotlib (not tested under Windows)}\label{python_ipython}

\-It is recommended to use \href{http://ipython.scipy.org/}{\tt \-I\-Python} (enhanced \-Python shell) instead of the regular \-Python shell, with \href{http://matplotlib.sourceforge.net/}{\tt \-Matplotlib}, a 2\-D plotting library which produces high quality figures. \-Once installed, launch \-I\-Python's pylab mode with {\ttfamily ipython -\/pylab}. \-You should get the prompt

 \begin{frame_python}
In [1]:
\end{frame_python}


\-If no error occurs, you have successfully installed \-Matplotlib. \-You can try to draw some curves with the command plot.

 \begin{frame_python}
In [1]: plot([0,1])
\end{frame_python}


\-This should open a new window with the figure of a line from (0,0) to (1,1). \-The prompt should still be available, so you can plot other figures.

 \begin{frame_python}
In [2]: plot([4,-1])
\end{frame_python}


\-Another curve has been added, a line from (0,4) to (1,-\/1).\hypertarget{python_compilation}{}\subsection{\-Compiling the Interface under Linux and Mac\-O\-S}\label{python_compilation}
\-In addition to a \-C++ compiler, one needs \-Swig 1.\-3.\-x. \-Swig 1.\-1 cannot generate the interface. \-You will also need \-Python (say, 2.\-5 or 2.\-6, but previous versions should work too) and its headers.

\-In {\ttfamily python/} directory, you may simply launch {\ttfamily scons swig} if you have \href{http://www.scons.org/}{\tt \-S\-Cons} installed (version $>$=1.\-0).

\-This should generate the \-Python module {\ttfamily verdandi.\-py} and the shared library {\ttfamily \-\_\-verdandi.\-so}. \-You may want to place these two files in a directory of your {\ttfamily \$\-P\-Y\-T\-H\-O\-N\-P\-A\-T\-H}, where \-Python searches for modules.\hypertarget{python_compilationw}{}\subsection{\-Compiling the Interface under Windows}\label{python_compilationw}
\href{http://www.swig.org/}{\tt \-Swig} is available for \-Windows. \-Download the prebuild executable, and add the path to \-S\-W\-I\-G to your environment variable. \-Create a \char`\"{}\-New project from existing code file\char`\"{} in \-Visual. \-Select \-Visual \-C++ for the entry \char`\"{}\-Type of project\char`\"{}. \-Specify then the location of the \char`\"{}python\char`\"{} directory in your version of \hyperlink{namespace_verdandi}{\-Verdandi}\-: {\ttfamily \-Verdandi-\/\mbox{[}version\mbox{]}$\backslash$python}, and give a name to the project. \-On the \char`\"{}\-Project Settings\char`\"{} page, select \char`\"{}\-Use external build system\char`\"{}. \-Then put {\ttfamily scons} on the generic build command line and {\ttfamily scons -\/c} on the clean command line. \-Click on \-O\-K.

\-Then add the different library paths needed, in the entry \char`\"{}\-Library Directories\char`\"{} (in \char`\"{}\-Project -\/$>$ Properties -\/$>$ Configuration Properties -\/$>$ V\-C++ Directories\char`\"{}). \-The default \-S\-W\-I\-G interface of \hyperlink{namespace_verdandi}{\-Verdandi} has dependencies to \-Python, \-Lua, \-Blas, \-Lapack and \-Cblas.

\-Build the solution, which will generate the \-Python module {\ttfamily verdandi.\-py} and the shared library {\ttfamily \-\_\-verdandi.\-pyd}. \-You may want to place these two files in the directory of your {\ttfamily \-D\-L\-Ls} in \-Python (by default\-: {\ttfamily \-C\-:$\backslash$\-Python$\backslash$\-D\-L\-Ls}), where \-Python searches for modules.\hypertarget{python_seldon}{}\subsection{\-Seldon Module under Linux and Mac\-O\-S}\label{python_seldon}
\-To manipulate vectors from the \-Python interface, you need \-Seldon module. \-To build this module, run {\ttfamily scons} from {\ttfamily seldon/src} directory. \-This will build the {\ttfamily \-Swig} interface to \-Python\-:

\begin{frame_bash}
host<~/> scons
\end{frame_bash}


{\ttfamily seldon.\-py} and {\ttfamily \-\_\-seldon.\-so} have been generated. \-Make sure these files are in a directory of {\ttfamily \$\-P\-Y\-T\-H\-O\-N\-P\-A\-T\-H} to be able to launch {\ttfamily \-Seldon} \-Python module.\hypertarget{python_seldon2}{}\subsection{\-Seldon Module under Windows}\label{python_seldon2}
\-Create a \char`\"{}\-New project from existing code file\char`\"{} in \-Visual. \-Select \-Visual \-C++ for the entry \char`\"{}\-Type of project\char`\"{}. \-Specify then the location of the \-Seldon directory in your version of \hyperlink{namespace_verdandi}{\-Verdandi}\-: {\ttfamily \-Verdandi-\/\mbox{[}version\mbox{]}$\backslash$include$\backslash$seldon}, and give a name to the project. \-On the \char`\"{}\-Project Settings\char`\"{} page, select \char`\"{}\-Use external build system\char`\"{}. \-Then put {\ttfamily scons} on the generic build command line and {\ttfamily scons -\/c} on the clean command line. \-Click on \-O\-K.

\-Then add the different library paths needed, in the entry \char`\"{}\-Library Directories\char`\"{} (in \char`\"{}\-Project -\/$>$ Properties -\/$>$ Configuration Properties -\/$>$ V\-C++ Directories\char`\"{}). \-Seldon only needs a link to the \-Python library, so put the path to the {\ttfamily libs} directory of your \-Python installation.

\-Build the solution, which will generate in the \-Seldon directory the \-Python module {\ttfamily seldon.\-py} and the shared library {\ttfamily \-\_\-seldon.\-pyd}. \-You may want to place these two files in the directory of your {\ttfamily \-D\-L\-Ls} in \-Python (by default\-: {\ttfamily \-C\-:$\backslash$\-Python$\backslash$\-D\-L\-Ls}), where \-Python searches for modules.\hypertarget{python_using_interface}{}\subsection{\-Using the Interface}\label{python_using_interface}
\-From {\ttfamily python/} directory, or from any place if {\ttfamily verdandi.\-py} and {\ttfamily \-\_\-verdandi.\-so} (or {\ttfamily \-\_\-verdandi.\-pyd}) are in a directory of {\ttfamily \$\-P\-Y\-T\-H\-O\-N\-P\-A\-T\-H} under \-Linux and \-Mac\-O\-S or in \-Python {\ttfamily \-D\-L\-Ls} directory under \-Windows, you may launch \-Python and load the module.

 \begin{frame_python}
>> ipython -pylab

In  [1]: import seldon
In  [2]: import verdandi

In  [3]: method = verdandi.Method()
In  [4]: method.Initialize("configuration_file.lua")

In  [5]: model = method.GetModel()
In  [6]: model.GetTime()
Out [6]: 0
\end{frame_python}


{\ttfamily \-Forward()} can be processed either by calling the driver method or directly by calling the model method\-:

 \begin{frame_python}
In  [7]: method.Forward()
In  [8]: model.GetTime()
Out [9]: 0.0015
In [10]: model.Forward()
In [11]: model.GetTime()
Out[12]: 0.0030

In [13]: for i in range(1008):
   ....:      model.Forward()
In [14]: model.GetTime()
Out[14]: 1.515
\end{frame_python}


\-Here is an example of the computation of an analysis. \-You may want to check its effect by printing the state vector before and after the analysis\-:

 \begin{frame_python}
In [15]: state_vector = seldon.VectorDouble()

In [16]: model.GetState(state_vector)
In [17]: state_vector.Print()
0   0

In [18]: method.Analyze()
In [19]: model.GetState(state_vector)
In [20]: state_vector.Print()
0.0272727   0.0272727
\end{frame_python}


\-Here is an example of the interactivity of the high-\/level interface\-: the first element of the state vector is set to an arbitrary value\-:  \begin{frame_python}
In [21]: state_vector[0] = 0
In [22]: model.SetState(state_vector)
In [23]: model.GetState(state_vector)
In [24]: state_vector.Print()
0  0.0272727
\end{frame_python}

% ========================================================================
% Chapter Data Assimilation Algorithms
% ========================================================================
\hypertarget{data_assimilation_algorithms}{}\chapter{Data Assimilation Algorithms}\label{data_assimilation_algorithms}

\-Below are the {\bfseries data assimilation methods} available in \hyperlink{namespace_verdandi}{\-Verdandi}\-:


\begin{itemize}
\item \hyperlink{optimal_interpolation}{optimal interpolation (\-O\-I)};
\item \hyperlink{extended_kalman_filter}{extended \-Kalman filter (\-E\-K\-F)};
\item \hyperlink{reduced_order_extended_kalman_filter}{reduced order extended \-Kalman filter (\-R\-O\-E\-K\-F)};
\item \hyperlink{unscented_kalman_filter}{unscented \-Kalman filter (\-U\-K\-F)};
\item \hyperlink{reduced_order_unscented_kalman_filter}{reduced order unscented \-Kalman filter (\-R\-O\-U\-K\-F)};
\item \hyperlink{reduced_minimax_filter}{reduced minimax filter (\-R\-M\-F)};
\item \hyperlink{four_dimensional_variational}{four dimensional variational (4\-D\-V\-A\-R)};
\item \hyperlink{ensemble_kalman_filter}{ensemble \-Kalman filter (\-En\-K\-F)}.
\end{itemize}

\-Not all assimilation \marginnote{The complete interface of the model class is described in Section \ref{model_template}} methods are compatible with all example models, because the latter may not have a interface complete enough. \-The following table indicates which methods can be applied to which example models.

\begin{tabular}{|l|l|l|l|l|l|}
\hline
&\hyperlink{models}{\-Clamped \-Bar~~~} &\hyperlink{models}{\-Shallow \-Water~~~} &\hyperlink{models}{\-Lorenz~~~} &\hyperlink{models}{\-Quadratic \-Model}  \\
\hline
\hyperlink{optimal_interpolation}{\-Optimal interpolation}  &{\ttfamily yes} &{\ttfamily yes} &{\ttfamily no} &{\ttfamily yes}  \\
\hyperlink{extended_kalman_filter}{\-Extended \-Kalman filter}  &{\ttfamily yes} &{\ttfamily no} &{\ttfamily no} &{\ttfamily yes}  \\
\hyperlink{reduced_order_extended_kalman_filter}{\-Reduced order extended \-Kalman filter}  &{\ttfamily yes} &{\ttfamily no} &{\ttfamily no} &{\ttfamily no}  \\
\hyperlink{unscented_kalman_filter}{\-Unscented \-Kalman filter}  &{\ttfamily yes} &{\ttfamily no} &{\ttfamily no} &{\ttfamily yes}  \\
\hyperlink{reduced_order_unscented_kalman_filter}{\-Reduced order unscented \-Kalman filter~~~}  &{\ttfamily yes} &{\ttfamily no} &{\ttfamily no} &{\ttfamily no}  \\
\hyperlink{reduced_minimax_filter}{\-Reduced minimax filter}  &{\ttfamily no} &{\ttfamily no} &{\ttfamily no} &{\ttfamily no}  \\
\hyperlink{four_dimensional_variational}{\-Four dimensional variational}  &{\ttfamily yes} &{\ttfamily no} &{\ttfamily no} &{\ttfamily no}  \\
\hyperlink{ensemble_kalman_filter}{\-Ensemble \-Kalman filter}  &{\ttfamily no} &{\ttfamily yes} &{\ttfamily no} &{\ttfamily yes}  \\
\hline
\end{tabular}


\hypertarget{optimal_interpolation}{}\section{\-Optimal Interpolation}\label{optimal_interpolation}


\hypertarget{optimal_interpolation_oi_algorithm}{}\subsection{\-Algorithm}\label{optimal_interpolation_oi_algorithm}


\-The optimal interpolation method is a sequential data assimilation method implementing the \-B\-L\-U\-E (\-Best \-Linear \-Unbiased \-Estimator) analysis. \-The \-B\-L\-U\-E is so-\/called since (1) it is linearly deduced from the state vector and the observation vector, (2) its error is unbiased and (3) it is optimal in the sense that it has the lowest total variance. \-Each time observations are available, \-B\-L\-U\-E is computed, with prescribed state error variance $B$ and observational error variance $R$. \-Here is the algorithm\-: \par



\begin{DoxyEnumerate}
\item \-At time $t_0$, the initial condition $x^{f}_{0}$ is available.
\item \-For every time $t_h, h \ge 0$,
\begin{DoxyItemize}
\item if observations $y_h$ are available, \par
 the analysis takes the \-B\-L\-U\-E value \par
 $x_h^a = x_h^f + K_h(y_h - H_h(x_h^f))$, \par
 with \par
 $K_h = B_hH_h^{T}(H_hB_hH_h^{T} + R_h)^{-1}$, \par
 and the forecast is \par
 $x_{h+1}^f = \mathcal{M}_h(x_h^a)$;
\item if there are no observations, \par
 the forecast is \par
 $x_{h+1}^f = \mathcal{M}_h(x_h^f)$.
\end{DoxyItemize}
\end{DoxyEnumerate}\-With\-: \par
 $x_h^f$ background state vector; \par
 $x_h^a$ analysis state vector; \par
 $y_h$ observation vector; \par
 $H_h$ linear observation operator that maps the state space to the observation space; \par
 $H_h$ observation operator linearized at $x^f_h$; \par
 $B_h$ background error covariance matrix (error variance of $x_h^f$); \par
 $R_h$ observational error covariance matrix; \par
 $K_h$ analysis gain matrix; \par
 $\mathcal{M}_h$ model.

 \hypertarget{optimal_interpolation_implementation}{}\subsection{\-Implementation}\label{optimal_interpolation_implementation}

 \hyperlink{namespace_verdandi}{\-Verdandi} provides a \-C++ implementation of the optimal interpolation.

\-The optimal interpolation is a sequential data assimilation method. \-It is implemented in {\ttfamily \hyperlink{_optimal_interpolation_8hxx_source}{\-Optimal\-Interpolation.\-hxx}} and {\ttfamily \-Optimal\-Interpolation.\-cxx}. \\
\-The class {\ttfamily  \hyperlink{class_verdandi_1_1_optimal_interpolation}{\-Optimal\-Interpolation}} is a template class\-:\\
 {\ttfamily \-Optimal\-Interpolation$<$\-T, Class\-Model, Class\-Observation\-Manager$>$}.
 \begin{itemize}
 \item {\ttfamily \-T} is the type of the elements to be stored (e.\-g. {\ttfamily double}).
 \item {\ttfamily \-Class\-Model} is the type of the model (e.\-g. {\ttfamily \-Shallow\-Water$<$double$>$}).
 \item {\ttfamily \-Class\-Observation\-Manager} is the type of the observation manager (e.\-g. {\ttfamily \-Grid\-To\-Network\-Observation\-Manager$<$double$>$}).
\end{itemize}
\-A simulation with the optimal interpolation may be carried out with the following \-C++ lines\-:

 \begin{frame_cpp}
OptimalInterpolation<double,  ShallowWater<double>,
         GridToNetworkObservationManager<double> > driver; [1]

driver.Initialize(argv[1]); [2]

while (!driver.HasFinished()) [6]
{
    driver.InitializeStep(); [3]
    driver.Forward(); [4]
    driver.Analyze(); [5]
}
\end{frame_cpp}



\begin{DoxyEnumerate}
\item \-First build the {\ttfamily  \hyperlink{class_verdandi_1_1_optimal_interpolation}{\-Optimal\-Interpolation}} driver with the construction {\ttfamily  \hyperlink{class_verdandi_1_1_optimal_interpolation_a1cc8e69bfd77788c3601487e0b270bb4}{\-Optimal\-Interpolation}}.


\item \-Then initialize the driver, the model and the observation manager, and read the option keys in the configuration file with the method {\ttfamily  \hyperlink{class_verdandi_1_1_optimal_interpolation_a0007eb5163d6b5b38c85ac40dce0f6ce}{\-Initialize(configuration\-\_\-file)}}. \-This optionally computes an analysis (\-B\-L\-U\-E) with the model initial condition.


\item \-Optionally intialize a step for the optimal interpolation with the method {\ttfamily  \hyperlink{class_verdandi_1_1_optimal_interpolation_a69867908e79e4eb34d092b1a9a49ed1a}{\-Initialize\-Step()}}. \-This initializes a step for the model.


\item \-Perform a step forward without optimal interpolation with the method {\ttfamily  \hyperlink{class_verdandi_1_1_optimal_interpolation_a4c7807e4a2e9b91d4c254e330feb0b72}{\-Forward()}}.


\item \-Compute the analysis with the method {\ttfamily  \hyperlink{class_verdandi_1_1_optimal_interpolation_a77df6f22721e423eb605056b700611fe}{\-Analyze()}}. \-Whenever observations are available, it assimilates them through the computation of \-B\-L\-U\-E.


\item \-Compute the data assimilation until the model has finished\-: the method {\ttfamily  \hyperlink{class_verdandi_1_1_optimal_interpolation_a073bc3510ad2e0a7fe3dc022650bada2}{\-Has\-Finished()}} returns true if the simulation is done, false otherwise.
\end{DoxyEnumerate}


\hypertarget{optimal_interpolation_configuration}{}\subsection{\-Configuration}\label{optimal_interpolation_configuration}

 An example of the {\ttfamily  \hyperlink{class_verdandi_1_1_optimal_interpolation}{\-Optimal\-Interpolation}} configuration file can be found in  {\ttfamily verdandi/example/quadratic\_model/assimilation.lua}.

 \paragraph{assimilation.lua}
 \begin{frame_lua}
 -- Simulation with assimilation using optimal interpolation.
optimal_interpolation = {

   -- Computation mode for BLUE: "vector" or "matrix".
   BLUE_computation = "vector", [1]
   -- Should the diagonal of the analysis variance be computed?
   with_analysis_variance_diagonal = false, [2]

   data_assimilation = {

      analyze_first_step = true,

   },

   display = {

      show_iteration = false,
      show_time = true
   },

   output_saver = {

      variable_list = {"state_forecast", "state_analysis"},
      file = output_directory .. "oi-%{name}.%{extension}",
      time = "step " .. Delta_t_clamped_bar * Nskip_save .. " 1.e-6",
      mode = output_mode,
      mode_scalar = output_mode_scalar

   },

   output = {

      configuration = output_directory .. "oi.lua",
      log = output_directory .. "oi.log"

   }

}
 \end{frame_lua}

 \begin{enumerate}

\item The BLUE (Best Linear Unbiased Estimator) computation can be performed using operations on vectors or matrices.
 The matrix mode is mainly intended for cases where the covariance matrices
      are sparse matrices. Otherwise, the manipulation of the matrices may
      lead to unreasonable memory requirements and to high computational
      costs.

 \item This field enables to indicate if the diagonal of the BLUE variance has to be computed or not.

 \end{enumerate}

 \hypertarget{extended_kalman_filter}{}\section{\-Extended Kalman Filter}\label{extended_kalman_filter}


\hypertarget{extended_kalman_filter_algorithm2}{}\subsection{\-Algorithm}\label{extended_kalman_filter_algorithm2}

\begin{DoxyEnumerate}
\item \-Prediction\-:
\begin{DoxyItemize}
\item $x_{h+1}^f = \mathcal{M}_{h}(x_{h}^a)$\par

\item $P_{h+1}^f = M_{h} P_{h}^a M_{h}^T $
\end{DoxyItemize}
\item \-Update\-:
\begin{DoxyItemize}
\item $K_{h+1} = P_{h+1}^fH_{h+1}^{T}(H_{h+1}P_{h+1}^fH_{h+1}^{T} + R_{h+1})^{-1}$\par

\item $x_{h+1}^a = x_{h+1}^f + K_{h+1}(y_{h+1} - \mathcal{H}_{h+1}(x_{h+1}^f))$\par

\item $P_h^a = (I - K_{h+1}H_{h+1})P_{h+1}^f$
\end{DoxyItemize}
\end{DoxyEnumerate}\-With\-: \par
 $x_h^f$ forecast state vector; \par
 $x_h^a$ analysis state vector; \par
 $y_h$ observation vector; \par
 $\mathcal{H}_h$ observation operator that maps the state space to the observation space; \par
 $H_h$ observation operator linearized at $x^f_h$; \par
 $P^f_h$ error covariance matrix of $x_h^f$; \par
 $P^a_h$ error covariance matrix of $x_h^a$; \par
 $R_h$ observational error covariance matrix; \par
 $K_h$ analysis gain matrix; \par
 $\mathcal{M}_h$ model; \par
 $M_h$ model linearized at $x^f_h$.

 \hypertarget{extended_kalman_filter_implementation}{}\subsection{\-Implementation}\label{extended_kalman_filter_implementation}

  \hyperlink{namespace_verdandi}{\-Verdandi} provides a \-C++ implementation of the extended \-Kalman filter (\-E\-K\-F).

\-The extended \-Kalman filter (\-E\-K\-F) is implemented in {\ttfamily \hyperlink{_extended_kalman_filter_8hxx_source}{\-Extended\-Kalman\-Filter.\-hxx}} and {\ttfamily \hyperlink{_extended_kalman_filter_8cxx_source}{\-Extended\-Kalman\-Filter.\-cxx}}.\\
 \-The class {\ttfamily  \hyperlink{class_verdandi_1_1_extended_kalman_filter}{\-Extended\-Kalman\-Filter}} is a template class\-:\\
  {\ttfamily \-Extended\-Kalman\-Filter$<$\-T, Class\-Model, Class\-Observation\-Manager$>$}.
  \begin{itemize}
  \item {\ttfamily \-T} is the type of the elements to be stored (e.\-g. {\ttfamily double}).
  \item {\ttfamily \-Class\-Model} is the type of the model (e.\-g. {\ttfamily \-Clamped\-Bar$<$double$>$}).
  \item {\ttfamily \-Class\-Observation\-Manager} is the type of the observation manager (e.\-g. {\ttfamily \-Linear\-Observation\-Manager$<$double$>$}).
  \end{itemize}

\-A simulation with the \-Extended \-Kalman \-Filter (\-E\-K\-F) may be carried out with the following \-C++ lines\-:

 \begin{frame_cpp}
ExtendedKalmanFilter<real, ClampedBar<real>,
        LinearObservationManager<real> > driver; [1]

driver.Initialize(argv[1]); [2]

while (!driver.HasFinished()) [6]
{
    driver.InitializeStep(); [3]

    driver.Forward(); [4]

    driver.Analyze(); [5]
}
\end{frame_cpp}


\begin{DoxyEnumerate}
\item \-First build the {\ttfamily  \hyperlink{class_verdandi_1_1_extended_kalman_filter}{\-Extended\-Kalman\-Filter}} driver with the construction {\ttfamily  \hyperlink{class_verdandi_1_1_extended_kalman_filter_aec315cc36c89d5f01114636c8fc8d701}{\-Extended\-Kalman\-Filter}}.


\item \-Then initialize the driver, the model and the observation manager, and read option keys in the configuration file with {\ttfamily  \hyperlink{class_verdandi_1_1_extended_kalman_filter_a74653334f0753417237742f88bdc6a08}{\-Initialize(configuration\-\_\-file)}}. \-This optionally computes an analysis (\-B\-L\-U\-E) with the model initial condition.


\item \-Optionally intialize a step with {\ttfamily  \hyperlink{class_verdandi_1_1_extended_kalman_filter_a2a95feb5808c086a01dbb34ecb171e70}{\-Initialize\-Step()}}. \-This initializes a step for the model.


\item \-Perform a step forward and propagate the state error variance with {\ttfamily  \hyperlink{class_verdandi_1_1_extended_kalman_filter_a00e1741e3ddb28ba7d8e8f2e4f2068e6}{\-Forward()}}.


\item \-Compute the analysis with {\ttfamily  \hyperlink{class_verdandi_1_1_extended_kalman_filter_a49ea2f90bf6ecb16e37e5c0a3c275f40}{\-Analyze()}}, whenever observations are available.


\item \-Compute the data assimilation until the model has finished\-: {\ttfamily  \hyperlink{class_verdandi_1_1_extended_kalman_filter_a13923684be25c10b04b164fc8d185df1}{\-Has\-Finished()}} returns true if the simulation is done, false otherwise.
\end{DoxyEnumerate}




\hypertarget{ekf_configuration}{}\subsection{\-Configuration}\label{ekf_configuration}

 An example of the {\ttfamily  \hyperlink{class_verdandi_1_1_extended_kalman_filter}{\-Extended\-Kalman\-Filter}} configuration file can be found in  {\ttfamily verdandi/example/quadratic\_model/assimilation.lua}.

 \paragraph{assimilation.lua}
 \begin{frame_lua}
-- Simulation with assimilation using EKF.
extended_kalman_filter = {

   -- Computation mode for BLUE: "vector" or "matrix".
   BLUE_computation = "matrix", [1]
   -- Computation mode for covariance: "vector" or "matrix".
   covariance_computation = "vector", [2]

   data_assimilation = {

      analyze_first_step = false,

   },

   display = {

      show_iteration = false,
      show_time = true
   },

   output_saver = {

      variable_list = {"state_forecast", "state_analysis"},
      file = output_directory .. "ekf-%{name}.%{extension}",
      time = "step " .. Delta_t_clamped_bar * Nskip_save .. " 1.e-6",
      mode = output_mode,
      mode_scalar = output_mode_scalar

   },

   output = {

     configuration = output_directory .. "ekf.lua",
     log = output_directory .. "ekf.log"

  }

}

 \end{frame_lua}

 \begin{enumerate}

\item The BLUE (Best Linear Unbiased Estimator) computation can be performed using operations on vectors or matrices.
 The matrix mode is mainly intended for cases where the covariance matrices
      are sparse matrices. Otherwise, the manipulation of the matrices may
      lead to unreasonable memory requirements and to high computational
      costs.

 \item The propagation of the state error variance ($P_{h+1}^f = M_{h} P_{h}^a M_{h}^T $)  can be performed using operations on vectors or matrices.
 The matrix mode is mainly intended for the case where the tangent linear model can be provided as matrix.
 \end{enumerate}




 \hypertarget{reduced_order_extended_kalman_filter}{}\section{\-Reduced Order Extended Kalman Filter}\label{reduced_order_extended_kalman_filter}


\hypertarget{reduced_order_extended_kalman_filter_algorithm16}{}\subsection{\-Algorithm}\label{reduced_order_extended_kalman_filter_algorithm16}


\-Assuming that \-P is of reduced rank p - typically much smaller than the dimension of the space n - the basic idea in reduced-\/order filtering is, in essence, to be able to manipulate covariance matrices in the factorized form \[ P = LU^{-1}L^{T}, \]

where \-U - in the group of invertible matrices $\mathcal{GL}_{p}$ - is of much smaller size than \-P $\in \mathcal{M}_{h}$ and represents the main uncertainties in the system. \-What is crucial here is to be able to perform all computations on \-L and \-U without needing to compute \-P.


\begin{DoxyEnumerate}
\item \-Prediction\-:
\begin{DoxyItemize}
\item $ x_{h+1}^f = \mathcal{M}_{h}(x_{h}^{a}) + Q_{h+1}$\par

\end{DoxyItemize}
\item \-Update\-:
\begin{DoxyItemize}
\item $ L_{h+1} = M_{h}L_h$\par

\item $ U_{h+1} = U_h + (H_{h+1}L_{h+1})^T R_{h+1}^{-1} H_{h+1}L_{h+1}$\par

\item $ x_{h+1}^a = x_{h+1}^f + L_{h+1}U_{h+1}^{-1}(H_{h+1}L_{h+1})^T R_{h+1}^{-1} (y_{h+1}-H_{h+1}x_{h+1}^f)$\par

\end{DoxyItemize}
\end{DoxyEnumerate}\-With\-: \par
 $x_h^f$ forecast state vector; \par
 $x_h^a$ analysis state vector; \par
 $y_h$ observation vector; \par
 $\mathcal{H}_h$ observation operator that maps the state space to the observation space; \par
 $H_h$ observation operator linearized at $x^f_h$; \par
 $Q_h$ model error covariance matrix; \par
 $R_h$ observational error covariance matrix; \par
 $\mathcal{M}_h$ model.

 \hypertarget{reduced_order_extended_kalman_filter_implementation}{}\subsection{\-Implementation}\label{reduced_order_extended_kalman_filter_implementation}


 \hyperlink{namespace_verdandi}{\-Verdandi} provides a \-C++ implementation of the reduced order extended \-Kalman filter (\-R\-O\-E\-K\-F) also known as singular evolutive extended \-Kalman filter (\-S\-E\-E\-K).

\-The reduced order extended \-Kalman filter (\-R\-O\-E\-K\-F) is implemented in {\ttfamily \hyperlink{_reduced_order_extended_kalman_filter_8hxx_source}{\-Reduced\-Order\-Extended\-Kalman\-Filter.\-hxx}} and {\ttfamily \hyperlink{_reduced_order_extended_kalman_filter_8cxx_source}{\-Reduced\-Order\-Extended\-Kalman\-Filter.\-cxx}}.\\
 \-The class {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_extended_kalman_filter}{\-Reduced\-Order\-Extended\-Kalman\-Filter}} is a template class\-: \\
 {\ttfamily \-Reduced\-Order\-Extended\-Kalman\-Filter$<$\-T, Class\-Model, Class\-Observation\-Manager$>$}.
 \begin{itemize}
  \item {\ttfamily \-T} is the type of the elements to be stored (e.\-g. {\ttfamily double}).
  \item {\ttfamily \-Class\-Model} is the type of the model (e.\-g. {\ttfamily \-Clamped\-Bar$<$double$>$}).
  \item {\ttfamily \-Class\-Observation\-Manager} is the type of the observation manager (e.\-g. {\ttfamily \-Linear\-Observation\-Manager$<$double$>$}).
  \end{itemize}

\-A simulation with the reduced order extended \-Kalman filter (\-R\-O\-E\-K\-F) may be carried out with the following \-C++ lines\-:

 \begin{frame_cpp}
ReducedOrderExtendedKalmanFilter<real, ClampedBar<real>,
        LinearObservationManager<real> > driver; [1]

driver.Initialize(argv[1]); [2]

while (!driver.HasFinished()) [6]
{
    driver.InitializeStep(); [3]

    driver.Forward(); [4]

    driver.Analyze(); [5]
}
\end{frame_cpp}


\begin{DoxyEnumerate}
\item \-First build the {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_extended_kalman_filter}{\-Reduced\-Order\-Extended\-Kalman\-Filter}} driver with the construction {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_extended_kalman_filter_a547ead3b7adf64bad4068d3ed576ac34}{\-Reduced\-Order\-Extended\-Kalman\-Filter}}.


\item \-Then initialize the driver, the model and the observation manager, and read option keys in the configuration file with {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_extended_kalman_filter_a9018b22e4b303d8b0b379c992987f9d3}{\-Initialize(configuration\-\_\-file)}}. \-This optionally computes an analysis with the model initial condition.


\item \-Optionally intialize a step with {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_extended_kalman_filter_ad6fa4758f55f12b43d1fa03c169f9fe6}{\-Initialize\-Step()}}. \-This initializes a step for the model.


\item \-Perform a step forward and propagate the state error variance with {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_extended_kalman_filter_a672093ae1fb9e3353d706ed47cc3a869}{\-Forward()}}.


\item \-Compute the analysis with {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_extended_kalman_filter_ad0db0f2ba0f3ba0fa32e9c0bd106865d}{\-Analyze()}}, whenever observations are available.


\item \-Compute the data assimilation until the model has finished\-: {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_extended_kalman_filter_aec124f083945014ce06bf6c342c530e4}{\-Has\-Finished()}} returns true if the simulation is done, false otherwise.
\end{DoxyEnumerate}


\hypertarget{roekf_configuration}{}\subsection{\-Configuration}\label{roekf_configuration}

 An example of the {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_extended_kalman_filter}{\-Reduced\-Order\-Extended\-Kalman\-Filter}} configuration file can be found in  {\ttfamily verdandi/example/quadratic\_model/assimilation.lua}.

 \paragraph{assimilation.lua}
 \begin{frame_lua}
-- Simulation with assimilation using ROEKF.
reduced_order_extended_kalman_filter = {

   data_assimilation = {

      analyze_first_step = false,

   },

   display = {

      show_iteration = false,
      show_time = true

   },

   output_saver = {

      variable_list = {"state_forecast", "state_analysis"},
      file = output_directory .. "roekf-%{name}.%{extension}",
      time = "step " .. Delta_t_clamped_bar * Nskip_save .. " 1.e-6",
      mode = output_mode,
      mode_scalar = output_mode_scalar

   },

   output = {

     configuration = output_directory .. "roekf.lua",
     log = output_directory .. "roekf_%{rank}.log"

   },

}
 \end{frame_lua}



\hypertarget{unscented_kalman_filter}{}\section{\-Unscented Kalman Filter}\label{unscented_kalman_filter}



\hypertarget{unscented_kalman_filter_algorithm3}{}\subsection{\-Algorithm}\label{unscented_kalman_filter_algorithm3}


\-The unscented \-Kalman filter (\-U\-K\-F) is based on using well-\/chosen \char`\"{}interpolation points\char`\"{} (sigma-\/points) in order to propagate the mean and covariance of a random variable with improved accuracy with respect to standard extended \-Kalman filtering (\-E\-K\-F). \-Different choices of sigma-\/points are implemented in \-Verdandi\-:
\begin{DoxyEnumerate}
\item canonical sigma-\/points\-: aligned with the canonical $(e_i)$ of the space with associated coefficient $\alpha_i = \frac{1}{2n}$
\begin{DoxyItemize}
\item $I^{(i)} = \sqrt n e_i $, for $1 \le i \le n$ \par

\item $I^{(i)} = - \sqrt n e_i $, for $n + 1 \le i \le 2n $ ;
\end{DoxyItemize}
\item star sigma-\/points\-: the origin is added to the previous canonical points;
\item simplex sigma-\/points\-: this represents the smallest number of necessary sigma-\/points $ r = n + 1 $, which are located on a regular polyhedron of radius $ \sqrt n $.
\end{DoxyEnumerate}

\-The principle of the \-U\-K\-F filter is to replace the means and covariances of the \-Kalman filter by the empirical means and covariances propagated by the dynamical operator $\mathcal{M}$ during the prediction, and by the observation operator $\mathcal{H}$ during the correction. \-This lead the following algorithm\-:
\begin{DoxyEnumerate}
\item \-Prediction\-:
\begin{DoxyItemize}
\item $x_{h}^{(i)a} = x_h^a + \sqrt{P_h^a} I^{(i)} $\par

\item $x_{h+1}^f = E_{\alpha}(\mathcal{M}_{h}(x_h^{(*)a}))$\par

\item $P_{h+1}^f = Cov_{\alpha}(\mathcal{M}_{h}(x_h^{(*)a}))$
\end{DoxyItemize}
\item \-Update\-:
\begin{DoxyItemize}
\item $x_{h+1}^{(i)f} = x_{h+1}^f + \sqrt{P_{h+1}^f} I^{(i)} $\par

\item $y_{h+1}^{(i)} = \mathcal{H}_{h+1}(x_{h+1}^{(i)f})$\par

\item $P_{\alpha}^{xy} = Cov_{\alpha}(x_{h+1}^{(*)f}, y_{h+1}^{(*)})$\par

\item $P_{\alpha}^{y} = R_{h+1} + Cov_{\alpha}(y_{h+1}^{(*)}, y_{h+1}^{(*)})$\par

\item $K_{h+1} = P_{\alpha}^{xy}(P_{\alpha}^{y})^{-1}$ \par

\item $x_{h+1}^a = x_{h+1}^f + K_{h+1}(y_{h+1} - E_{\alpha}(y_{h+1}^{(*)}))$\par

\item $P_{h+1}^a = P_{h+1}^f - P_{\alpha}^{xy}(P_{\alpha}^{y})^{-1}(P_{\alpha}^{xy})^T$
\end{DoxyItemize}


\end{DoxyEnumerate}\-With\-: \par
 $x_h^f$ forecast state vector; \par
 $x_h^a$ analysis state vector; \par
 $y_h$ observation vector; \par
 $\mathcal{H}_h$ observation operator that maps the state space to the observation space; \par
 $H_h$ observation operator linearized at $x^f_h$; \par
 $P^f_h$ error covariance matrix of $x_h^f$; \par
 $P^a_h$ error covariance matrix of $x_h^a$; \par
 $R_h$ observational error covariance matrix; \par
 $K_h$ analysis gain matrix; \par
 $\mathcal{M}_h$ model.

 \hypertarget{unscented_kalman_filter_ukf_ref}{}\subsection{\-Reference}\label{unscented_kalman_filter_ukf_ref}
\-For more detail about the unscented \-Kalman filtering see\par
 \href{http://dx.doi.org/10.1051/cocv/2010006}{\tt \-Reduced-\/order \-Unscented \-Kalman \-Filtering with application to parameter identification in large-\/dimensional systems (\-P. \-Moireau, \-D. \-Chapelle)}.


 \hypertarget{unscented_kalman_filter_ukf_implementation}{}\subsection{\-Implementation}\label{unscented_kalman_filter_ukf_implementation}


 \hyperlink{namespace_verdandi}{\-Verdandi} provides a \-C++ implementation of the unscented \-Kalman filter (\-U\-K\-F).

\-The unscented \-Kalman filter (\-U\-K\-F) is implemented in {\ttfamily \hyperlink{_unscented_kalman_filter_8hxx_source}{\-Unscented\-Kalman\-Filter.\-hxx}} and {\ttfamily \hyperlink{_unscented_kalman_filter_8cxx_source}{\-Unscented\-Kalman\-Filter.\-cxx}}.\\
 \-The class {\ttfamily  \hyperlink{class_verdandi_1_1_unscented_kalman_filter}{\-Unscented\-Kalman\-Filter}} is a template class\-:\\
  {\ttfamily \-Unscented\-Kalman\-Filter$<$\-T, Class\-Model, Class\-Observation\-Manager$>$}.
  \begin{itemize}
  \item {\ttfamily \-T} is the type of the elements to be stored (e.\-g. {\ttfamily double}).
  \item {\ttfamily \-Class\-Model} is the type of the model (e.\-g. {\ttfamily \-Clamped\-Bar$<$double$>$}).
  \item {\ttfamily \-Class\-Observation\-Manager} is the type of the observation manager (e.\-g. {\ttfamily \-Linear\-Observation\-Manager$<$double$>$}).
\end{itemize}


\-A simulation with the unscented \-Kalman filter (\-U\-K\-F) may be carried out with the following \-C++ lines\-:

 \begin{frame_cpp}
UnscentedKalmanFilter<real, ClampedBar<real>,
        LinearObservationManager<real> > driver; [1]

driver.Initialize(argv[1]); [2]

while (!driver.HasFinished()) [6]
{
    driver.InitializeStep(); [3]

    driver.Forward(); [4]

    driver.Analyze(); [5]
}
\end{frame_cpp}





\begin{DoxyEnumerate}
\item \-First build the {\ttfamily  \hyperlink{class_verdandi_1_1_unscented_kalman_filter}{\-Unscented\-Kalman\-Filter}} driver with the construction {\ttfamily  \hyperlink{class_verdandi_1_1_unscented_kalman_filter_ab48260d24d6656b0b8b9b408c226e09d}{\-Unscented\-Kalman\-Filter}}.


\item \-Then initialize the driver, the model and the observation manager, and read option keys in the configuration file with {\ttfamily  \hyperlink{class_verdandi_1_1_unscented_kalman_filter_a75803b63310250aa37b54128b714c810}{\-Initialize(configuration\-\_\-file)}}. \-This optionally computes an analysis with the model initial condition.


\item \-Optionally intialize a step with {\ttfamily  \hyperlink{class_verdandi_1_1_unscented_kalman_filter_a150b6e3f2d8fe7627ecd47047dd05c61}{\-Initialize\-Step()}}. \-This initializes a step for the model.


\item \-Perform a step forward and propagate the state error variance with {\ttfamily  \hyperlink{class_verdandi_1_1_unscented_kalman_filter_a7dfa54bcedf8d0ea26c93ad0bb2d6293}{\-Forward()}}.


\item \-Compute the analysis with {\ttfamily  \hyperlink{class_verdandi_1_1_unscented_kalman_filter_a0f87ca7e67c3165f040b97dbbd87bb45}{\-Analyze()}}, whenever observations are available.


\item \-Compute the data assimilation until the model has finished\-: {\ttfamily  \hyperlink{class_verdandi_1_1_unscented_kalman_filter_a024094116ae425381344e129208c3e74}{\-Has\-Finished()}} returns true if the simulation is done, false otherwise.
\end{DoxyEnumerate}



 \hypertarget{ukf_configuration}{}\subsection{\-Configuration}\label{ukf_configuration}

 An example of the {\ttfamily  \hyperlink{class_verdandi_1_1_unscented_kalman_filter}{\-Unscented\-Kalman\-Filter}} configuration file can be found in  {\ttfamily verdandi/example/quadratic\_model/assimilation.lua}.

 \paragraph{assimilation.lua}
 \begin{frame_lua}
-- Simulation with assimilation using UKF.
unscented_kalman_filter = {

   data_assimilation = {

      analyze_first_step = false

   },

   sigma_point = {

      -- Choice of sigma-points: "canonical", "star" or "simplex".
      type = "simplex" [1]

   },

   display = {

      show_iteration = false,
      show_time = true

   },

   output_saver = {

      variable_list = {"state_forecast", "state_analysis"},
      file = output_directory .. "ukf-%{name}.%{extension}",
      time = "step " .. Delta_t_clamped_bar * Nskip_save .. " 1.e-6",
      mode = output_mode,
      mode_scalar = output_mode_scalar

   },

   output = {

     configuration = output_directory .. "ukf.lua",
     log = output_directory .. "ukf.log"

  }

}

 \end{frame_lua}

 \begin{enumerate}

\item Several sigma-point distributions have been implemented: simplex, canonical, star. The simplex distribution represents the smallest number of necessary sigma-points ($p + 1$).

 \end{enumerate}

 \hypertarget{reduced_order_unscented_kalman_filter}{}\section{\-Reduced Order Unscented Kalman Filter}\label{reduced_order_unscented_kalman_filter}


\hypertarget{reduced_order_unscented_kalman_filter_algorithm5}{}\subsection{\-Algorithm}\label{reduced_order_unscented_kalman_filter_algorithm5}


\-Assuming that \-P is of reduced rank p - typically much smaller than the dimension of the space n - the basic idea in reduced-\/order filtering is, in essence, to be able to manipulate covariance matrices in the factorized form \[ P = LU^{-1}L^{T}, \]

where \-U - in the group of invertible matrices $\mathcal{GL}_{p}$ - is of much smaller size than \-P $\in \mathcal{M}_{n}$ and represents the main uncertainties in the system. \-What is crucial here is to be able to perform all computations on \-L and \-U without needing to compute \-P.

\hypertarget{reduced_order_unscented_kalman_filter_algorithm6}{}\paragraph{\-Simplex case}\label{reduced_order_unscented_kalman_filter_algorithm6}

\-In this section, we focus on the simplex distribution. \-Consider some simplex sigma-\/points $ (V^{(i)})_{1\leq i \leq r} \in \mathbb{R}^p $ associated with some coefficients $ (\alpha) = ( \alpha_1 ... \alpha_r )^T $. \-Then, we define the matrix of these sigma-\/points denoted by $ [V^{*}] \in \mathcal{M}_{r,p}$ and the matrix $ D_{\alpha} = diag( \alpha_1 ... \alpha_r ) \in \mathcal{M}_{r}$.


\begin{DoxyEnumerate}
\item \-Sampling\-:
\begin{DoxyItemize}
\item $ C_{h} = \sqrt{U_h^{-1}} $,\par

\item $ x_{h}^{(i)a} = x_h^a + L_hC_hI^{(i)} \textrm{, } \quad 1\leq i \leq p+1 $\par

\end{DoxyItemize}
\item \-Prediction\-:

\begin{DoxyItemize}
\item $ x_{h+1}^f = E_\alpha(\mathcal{M}_{h}(x_{h+1}^{(*)a})) $\par

\item $ x_{h+1}^{(i)f} = x_{h+1}^f + [M_{h}(x_{h}^{*a})]D_\alpha [V^*]^T ([V^*] D_\alpha [V^*]^T)^{-1/2}I^{(i)} $\par

or without resampling:

\item $  x_{h+1}^{(i)f} = M_{h}(x_{h}^{(i)a} $\par



\item $ L_{h+1} = [x_{h+1}^{(*)f}]D_\alpha [V^*]^T \in \mathcal{M}_{n,p} $\par

\item $ P_{h+1}^f = L_{h+1} (P_{\alpha}^V)^{-1} L_{h+1}^T $


\end{DoxyItemize}
\item \-Update\-:
\begin{DoxyItemize}

\item $ y_{h+1}^{(i)} = \mathcal{H}_{h+1}(x_{h+1}^{(i)f})$\par

\item $ \{HL\}_{h+1} = [y_{h+1}^{*}]D_\alpha [V^*]^T$,\par

\item $ U_{h+1} = P_{\alpha}^V + \{HL\}_{h+1}^T R_{h+1}^{-1} \{HL\}_{h+1} \in \mathcal{M}_{p}$\par

\item $ x_{h+1}^a = x_{h+1}^f + L_{h+1}U_{h+1}^{-1}\{HL\}_{h+1}^T R_{h+1}^{-1} (y_{h+1}-E_\alpha(y_{h+1}^{(*)}))$\par

\item $ P_{h+1}^a = L_{h+1} U_{h+1}^{-1} L_{h+1}^T$
\end{DoxyItemize}
\end{DoxyEnumerate}\-With\-: \par
 $x_h^f$ forecast state vector; \par
 $x_h^a$ analysis state vector; \par
 $y_h$ observation vector; \par
 $\mathcal{H}_h$ observation operator that maps the state space to the observation space; \par
 $H_h$ observation operator linearized at $x^f_h$; \par
 $P^f_h$ error covariance matrix of $x_h^f$; \par
 $P^a_h$ error covariance matrix of $x_h^a$; \par
 $R_h$ observational error covariance matrix; \par
 $\mathcal{M}_h$ model.

\-It is worthwhile noting that the \-S\-E\-I\-K filter is equivalent to this reduced \-U\-K\-F algorithm. \-In fact, the \-S\-E\-I\-K procedure uses in the resampling and covariance factorization a matrix which is nothing but the transposed of $[V^*]$ with this particular choice of sigma-\/points.

\hypertarget{reduced_order_unscented_kalman_filter_algorithm7}{}\paragraph{\-Generalized case}\label{reduced_order_unscented_kalman_filter_algorithm7}

\-Given adequate sampling rules, precompute the corresponding $[V^*]$, $P_{\alpha}^V = [V^*] D_\alpha [V^*]^T $, $[I^*] = ([V^*] D_\alpha [V^*]^T)^{-\frac{1}{2}} [V^*]$, and $D_V = D_\alpha [V^*]^T (P_{\alpha}^V))^{-1} [V^*] D_\alpha $.


\begin{DoxyEnumerate}
\item \-Sampling\-:
\begin{DoxyItemize}
\item $ C_{h} = \sqrt{U_h^{-1}} $\par

\item $ x_{h}^{(i)a} = x_h^a + L_hC_hI^{(i)} \textrm{, } \quad 1\leq i \leq p+1 $\par

\end{DoxyItemize}
\item \-Prediction\-:
\begin{DoxyItemize}
\item $ x_{h+1}^f = E_\alpha(\mathcal{M}_{h}(x_{h+1}^{(*)a})) $\par

\item $ x_{h+1}^{(i)f} = x_{h+1}^f + [\mathcal{M}_{h}(x_{h}^{*a}) - x_{h+1}^f]D_{\alpha}^{1/2} \Upsilon_p I^(i), \textrm{ resampling with SVD} $\par

\item $ L_{h+1} = [x_{h+1}^{(*)f}]D_\alpha [V^*]^T \in \mathcal{M}_{n,p} $\par

\item $ P_{h+1}^f = L_{h+1} (P_{\alpha}^V)^{-1} L_{h+1}^T $
\end{DoxyItemize}
\item \-Update\-:
\begin{DoxyItemize}
\item $ [\tilde{y}] = [\mathcal{H}_{h+1}(x_{h+1}^{(*)f}) - E_\alpha(\mathcal{H}_{h+1}(x_{h+1}^{(*)f})) ]$\par

\item $ D_m = [\tilde{y}]^T R_{h+1}^{-1}[\tilde{y}] \in \mathcal{M}_r $\par

\item $ U_{h+1} = P_{\alpha}^V + [V^*] D_\alpha \bigl(1 + D_m(D_\alpha - D_V)\bigr)^{-1} D_m D_\alpha [V^*]^T \in \mathcal{M}_{p} $\par

\item $ \{HL\}_{h+1} = [\tilde{y}]( 1 + D_\alpha D_m)^{-1}\Bigl(1 + D_V \bigl( 1+D_m (D_\alpha-D_V) \bigr)^{-1} D_m \Bigr) D_\alpha[V^*]^T $\par

\item $ x_{h+1}^a = x_{h+1}^f + L_{h+1}U_{h+1}^{-1}\{HL\}_{h+1}^T R_{h+1}^{-1} (y_{h+1}-E_\alpha(y_{h+1}^{(*)}))$\par

\item $ P_{h+1}^a = L_{h+1} U_{h+1}^{-1} L_{h+1}^T$
\end{DoxyItemize}
\end{DoxyEnumerate}\-With\-: \par
 $x_h^f$ forecast state vector; \par
 $x_h^a$ analysis state vector; \par
 $y_h$ observation vector; \par
 $\mathcal{H}_h$ observation operator that maps the state space to the observation space; \par
 $H_h$ observation operator linearized at $x^f_h$; \par
 $P^f_h$ error covariance matrix of $x_h^f$; \par
 $P^a_h$ error covariance matrix of $x_h^a$; \par
 $R_h$ observational error covariance matrix; \par
 $\mathcal{M}_h$ model.

 \hypertarget{unscented_kalman_filter_ukf_ref}{}\subsection{\-Reference}\label{unscented_kalman_filter_ukf_ref}
\-For more detail about the reduced order unscented \-Kalman filtering see\par
 \href{http://dx.doi.org/10.1051/cocv/2010006}{\tt \-Reduced-\/order \-Unscented \-Kalman \-Filtering with application to parameter identification in large-\/dimensional systems (\-P. \-Moireau, \-D. \-Chapelle)}.


 \hypertarget{unscented_kalman_filter_ukf_implementation}{}\subsection{\-Implementation}\label{unscented_kalman_filter_ukf_implementation}

 \hyperlink{namespace_verdandi}{\-Verdandi} provides a \-C++ implementation of the reduced order unscented \-Kalman filter (\-R\-O\-U\-K\-F), which is the generalized formulation of the singular evolutive interpolated \-Kalman filter (\-S\-E\-I\-K).

\-The reduced order unscented \-Kalman filter (\-R\-O\-U\-K\-F) is implemented in {\ttfamily \hyperlink{_reduced_order_unscented_kalman_filter_8hxx_source}{\-Reduced\-Order\-Unscented\-Kalman\-Filter.\-hxx}} and {\ttfamily \hyperlink{_reduced_order_unscented_kalman_filter_8cxx_source}{\-Reduced\-Order\-Unscented\-Kalman\-Filter.\-cxx}}.\\
 \-The class {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_unscented_kalman_filter}{\-Reduced\-Order\-Unscented\-Kalman\-Filter}} is a template class\-: \\
 {\ttfamily \-Reduced\-Order\-Unscented\-Kalman\-Filter$<$\-T, Class\-Model, Class\-Observation\-Manager$>$}.
  \begin{itemize}
  \item {\ttfamily \-T} is the type of the elements to be stored (e.\-g. {\ttfamily double}).
  \item {\ttfamily \-Class\-Model} is the type of the model (e.\-g. {\ttfamily \-Clamped\-Bar$<$double$>$}).
  \item {\ttfamily \-Class\-Observation\-Manager} is the type of the observation manager (e.\-g. {\ttfamily \-Linear\-Observation\-Manager$<$double$>$}).
  \end{itemize}
\-A simulation with the reduced order unscented \-Kalman filter (\-R\-O\-U\-K\-F) may be carried out with the following \-C++ lines\-:

 \begin{frame_cpp}
ReducedOrderUnscentedKalmanFilter<real, ClampedBar<real>,
        LinearObservationManager<real> > driver; [1]

driver.Initialize(argv[1]); [2]

while (!driver.HasFinished()) [6]
{
    driver.InitializeStep(); [3]

    driver.Forward(); [4]

    driver.Analyze(); [5]
}
\end{frame_cpp}





\begin{DoxyEnumerate}
\item \-First build the {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_unscented_kalman_filter}{\-Reduced\-Order\-Unscented\-Kalman\-Filter}} driver with the construction {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_unscented_kalman_filter_a129b504d575fffcb3c8bb24485838e16}{\-Reduced\-Order\-Unscented\-Kalman\-Filter}}.


\item \-Then initialize the driver, the model and the observation manager, and read option keys in the configuration file with {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_unscented_kalman_filter_aa482de38f62f8c9e6e270fa2ce20e49b}{\-Initialize(configuration\-\_\-file)}}. \-This optionally computes an analysis with the model initial condition.


\item \-Optionally intialize a step with {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_unscented_kalman_filter_a528987dfbba5343306aa83f055ba1aa5}{\-Initialize\-Step()}}. \-This initializes a step for the model.


\item \-Perform a step forward and propagate the state error variance with {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_unscented_kalman_filter_a79767d20f8601c31877c3b457d08ce32}{\-Forward()}}.


\item \-Compute the analysis with {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_unscented_kalman_filter_a10d2c0b27b731bfcb28210e0128368fe}{\-Analyze()}}, whenever observations are available.


\item \-Compute the data assimilation until the model has finished\-: {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_unscented_kalman_filter_a35178086b2ceab0231a912b7208c4e67}{\-Has\-Finished()}} returns true if the simulation is done, false otherwise.
\end{DoxyEnumerate}





  \hypertarget{roukf_configuration}{}\subsection{\-Configuration}\label{roukf_configuration}

 An example of the  {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_order_unscented_kalman_filter}{\-Reduced\-Order\-Unscented\-Kalman\-Filter}} configuration file can be found in  {\ttfamily verdandi/example/quadratic\_model/assimilation.lua}.

 \paragraph{assimilation.lua}
 \begin{frame_lua}
-- Simulation with assimilation using ROUKF.
reduced_order_unscented_kalman_filter = {

   data_assimilation = {

      analyze_first_step = false,
      with_resampling = false,
      -- Indicates how R is stored: "matrix", "matrix_inverse".
      observation_error_variance = "matrix_inverse", [1]

   },

   sigma_point = {

      -- Choice of sigma-points: "canonical", "star" or "simplex".
      type = "simplex" [2]

   },

   display = {

      show_iteration = false,
      show_time = true

   },

   output_saver = {

      variable_list = {"state_forecast", "state_analysis"},
      file = output_directory .. "roukf-%{name}.%{extension}",
      time = "step " .. Delta_t_clamped_bar * Nskip_save .. " 1.e-6",
      mode = output_mode,
      mode_scalar = output_mode_scalar

   },

   output = {

     configuration = output_directory .. "roukf.lua",
     log = output_directory .. "roukf_%{rank}.log"

   },

   mpi = {

        algorithm = 0,
        master_process_contribution = 1.0
    }

}

 \end{frame_lua}

 \begin{enumerate}

 \item The observation manager can provide the observation error variance or its inverse (more efficient).

\item Several sigma-point distributions have been implemented: simplex, canonical, star. The simplex distribution represents the smallest number of necessary sigma-points ($p + 1$).

 \end{enumerate}





\hypertarget{reduced_minimax_filter}{}\section{\-Reduced Minimax Filter}\label{reduced_minimax_filter}


\hypertarget{reduced_minimax_filter_algorithm_minimax_2}{}\subsection{\-Algorithm}\label{reduced_minimax_filter_algorithm_minimax_2}

\begin{DoxyEnumerate}
\item \-Initialization\-:
\begin{DoxyItemize}
\item $\hat x_0 = G^{-1}_0 \left(F_0^T S_0^{-1} \overline e + H_0^T R_0^{-1} (y_0- \overline \eta_0)\right)$\par

\item $G_0 = F_0^TS_0^{-1}F_0 + H_0^T R_0^{-1} H_0$\par

\item $\beta_0=< R_0^{-1} (y_0-\overline \eta_0),y_0-\overline \eta_0>$\par

\end{DoxyItemize}


\item \-Update\-:
\begin{DoxyItemize}
\item $ x_{h+1}^f={\mathcal M}_h(F_h\hat x_h) $\par

\item $\hat x_{h+1} = F_{h+1}^Tx_{h+1}^f + G^{-1}_{h+1}H^T_{t +1}R^{-1}_{h+1}[(y_{h+1}-\overline \eta_{h+1})-H_{h+1}F_{h+1}^T x_{h+1}^f] + c_{h+1}, $,\par

\item $c_{h+1} = G^{-1}_{h+1}F_{h+1}^T(Q_h+{\mathcal M}_hG_h^{-1}{\mathcal M}^T_h)^{-1}((I-F_hF_h^T)x_{h+1}^f+\overline w_h) $
\item $G_{h+1} = F_{h+1}^T \left[ Q_h^{-1} - Q_h^{-1} M_h B_h M_h^T Q^{-1}_h \right] F_{h+1} + H_{h+1}^T R_{h+1}^{-1} H_{h+1} $\par

\item $B_h = \left(G_h + M_h^T Q_h^{-1} M_h\right)^+ $\par

\item $\beta_{h+1} = \beta_h - < B^+_h G_h^{-1}\hat x_h,\hat x_h> + < F_h M^T_h Q_h M_h F_h^T \overline w_h, \overline w_h> + \gamma_{h+1}$\par

\item $\gamma_{h+1} = < R_h^{-1} (y_h-\overline \eta_h),y_h-\overline \eta_h> $\par

\end{DoxyItemize}


\item \-Reachability set\-:
\begin{DoxyItemize}
\item $ \mathcal R(h) = \widehat x_h + \sqrt{1-\beta_h+<G_h\hat x_h,\hat x_h>}\mathcal X(t)$\par

\item $\mathcal X(h) = \{z: <G_h z, z>\le 1\} $\par

\end{DoxyItemize}
\end{DoxyEnumerate}\-With\-: \par
 $x^f_h$ forecast state vector; \par
 $\hat x_h$ analysis state vector; \par
 $y_h$ observation vector; \par
 $\mathcal{H}_h$ observation operator that maps the state space to the observation space; \par
 $H_h$ tangent linear observation operator linearized at $x^f_h$; \par
 $G_h$ minimax gain matrix; \par
 $\mathcal R(h)$ the reachability set that is the set of all model states compatible with observations and uncertainty description; \par
 $R_h$ observational error covariance matrix, possibly scaled; \par
 $Q_h$ state error covariance matrix, possibly scaled; \par
 $\mathcal X(h)$ a set describing how the model propagates uncertain initial condition, observation error and model error; \par
 $\beta_h$ observation-\/dependent scaling factor; \par
 $\mathcal{M}_h$ model; \par
 $\overline e$ systematic error in the initial condition; \par
 $\overline e_h$ systematic model error; \par
 $\overline \eta_h$ systematic observation error; \par
 $M_h$ tangent linear model linearized at $\hat x_h$; \par
 $F^T_h$ is a reduction matrix mapping the state space into the reduced-\/state space.\par


 \hypertarget{reduced_minimax_filter_algorithm_implementation}{}\subsection{\-Implementation}\label{reduced_minimax_filter_algorithm_implementation}


 \hyperlink{namespace_verdandi}{\-Verdandi} provides a \-C++ implementation of the \-Reduced \-Minimax \-Filter (\-R\-M\-F).

\-The \-Reduced \-Minimax \-Filter (\-R\-M\-F) is implemented in {\ttfamily \hyperlink{_reduced_minimax_8hxx_source}{\-Reduced\-Minimax.\-hxx}} and {\ttfamily \hyperlink{_reduced_minimax_8cxx_source}{\-Reduced\-Minimax.\-cxx}}.\\
 \-The class {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_minimax}{\-Reduced\-Minimax}} is a template class\-:\\
  {\ttfamily \-Reduced\-Minimax$<$\-T, \-Class\-Model, \-Class\-Observation\-Manager$>$}.
   \begin{itemize}
  \item {\ttfamily \-T} is the type of the elements to be stored (e.\-g. {\ttfamily double}).
  \item {\ttfamily \-Class\-Model} is the type of the model (e.\-g. {\ttfamily \-Clamped\-Bar$<$double$>$}).
  \item {\ttfamily \-Class\-Observation\-Manager} is the type of the observation manager (e.\-g. {\ttfamily \-Linear\-Observation\-Manager$<$double$>$}).
  \end{itemize}

\-A simulation with the \-Reduced \-Minimax \-Filter (\-R\-M\-F) may be carried out with the following \-C++ lines\-:

 \begin{frame_cpp}
ReducedMinimax<real, ClampedBar<real>,
        LinearObservationManager<real> > driver; [1]

driver.Initialize(argv[1]); [2]

while (!driver.HasFinished()) [5]
{
    driver.InitializeStep(); [3]

    driver.Forward(); [4]
}
\end{frame_cpp}



\begin{DoxyEnumerate}
\item \-First build the {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_minimax}{\-Reduced\-Minimax}} driver with the construction {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_minimax_a3348af891e4af2d37f6ffb44ae513210}{\-Reduced\-Minimax}}.


\item \-Then initialize the driver, the model and the observation manager, and read option keys in the configuration file with {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_minimax_a36393b2be9a1c0abf3d005b84ee8bd3e}{\-Initialize(configuration\-\_\-file)}}.


\item \-Initialize a step with {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_minimax_af7af2afae2e9698bfaae48d71b9ae571}{\-Initialize\-Step()}}. \-This initializes a step for the model.


\item \-Perform a step forward, with assimilation of the observation, and propagate the minimax gain with {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_minimax_a769b32003ad3a1886ee50bb1c07888fb}{\-Forward()}}.


\item \-Iterate until the model has finished\-: {\ttfamily  \hyperlink{class_verdandi_1_1_reduced_minimax_adc80ca802a589f2ab15f65010b4842e6}{\-Has\-Finished()}} returns true if the simulation is done, false otherwise.
\end{DoxyEnumerate}




 \hypertarget{monte_carlo_mc}{}\section{\-Monte Carlo}\label{monte_carlo}


\hypertarget{monte_carlo_mc_algorithm}{}\subsection{\-Algorithm}\label{monte_carlo_mc_algorithm}

\-The \-Monte \-Carlo method consists in perturbing selected parameters from the model. \-The perturbation is generated randomly and can be applied either at each step or only at the initial time. \par



\begin{DoxyEnumerate}
\item \-At time $t_0$, the parameters (or some parameters) $p_0$ of the model are perturbed and denoted $\widetilde p_0$. \-The initial condition $x^f_0$ can also be perturbed.
\item \-For every time $t_h, h \ge 0$,
\begin{DoxyItemize}
\item $x_{h+1}^f = \mathcal{M}_h(x_h^f, \widetilde p_h)$, \par

\item the parameters $p_{h+1}$ are pertubed and denoted $\widetilde p_{h+1}$.
\end{DoxyItemize}
\end{DoxyEnumerate}\-With\-: \par
 $x_h^f$ state vector; \par
 $\mathcal{M}_h$ model; \par
 $p_h$ model parameters; \par
 $\widetilde p_h$ perturbed model parameters.



\hypertarget{monte_carlo_mc_implementation}{}\subsection{\-Implementation}\label{monte_carlo_mc_implementation}


\hyperlink{namespace_verdandi}{\-Verdandi} provides a \-C++ implementation of the \-Monte \-Carlo method.

\-The \-Monte \-Carlo method is implemented in {\ttfamily \hyperlink{_monte_carlo_8hxx_source}{\-Monte\-Carlo.\-hxx}} and {\ttfamily \hyperlink{_monte_carlo_8cxx_source}{\-Monte\-Carlo.\-cxx}}.\\
 \-The class {\ttfamily  \hyperlink{class_verdandi_1_1_monte_carlo}{\-Monte\-Carlo}} is a template class\-:\\
  {\ttfamily \-Monte\-Carlo$<$\-T, Class\-Model$>$}.
  \begin{itemize}
   \item {\ttfamily \-T} is the type of the elements to be stored (e.\-g., {\ttfamily double}).
   \item {\ttfamily \-Class\-Model} is the type of the model (e.\-g., {\ttfamily \-Quadratic\-Model$<$double$>$}).
   \end{itemize}

\-A simulation with the \-Monte \-Carlo method may be carried out with the following \-C++ lines\-:

\begin{frame_cpp}
MonteCarlo<real,  QuadraticModel<real> > driver; [1]

driver.Initialize(argv[1]); [2]

while (!driver.HasFinished()) [5]
{
    driver.InitializeStep(); [3]
    driver.Forward(); [4]
}
\end{frame_cpp}





\begin{DoxyEnumerate}
\item \-First build the {\ttfamily  \hyperlink{class_verdandi_1_1_monte_carlo}{\-Monte\-Carlo}} driver with the construction {\ttfamily  \hyperlink{class_verdandi_1_1_monte_carlo_a2cbaff4f3f90c79c7ccfcb9193699b60}{\-Monte\-Carlo}}.


\item \-Then initialize the driver, the model and the perturbation manager,and read option keys in the configuration file with the method {\ttfamily  \hyperlink{}{\-Initialize(configuration\-\_\-file)}}. \-Model parameters are perturbed at that stage.


\item \-Optionally initialize the model before a time step with the method {\ttfamily  \hyperlink{class_verdandi_1_1_monte_carlo_a0a89636757301c4d54d7d9d5adb979a2}{\-Monte\-Carlo()}}. \-Pertubations are applied to model parameters.


\item \-Perform a step forward with the method {\ttfamily  \hyperlink{class_verdandi_1_1_monte_carlo_a6f86578e17d6cc780238beb665033fa5}{\-Forward()}}.


\item \-Compute until the model has finished\-: the method {\ttfamily  \hyperlink{class_verdandi_1_1_monte_carlo_a2b111f15a0b75f1b9496d113c246f20f}{\-Has\-Finished()}} returns true if the simulation is done, false otherwise.
\end{DoxyEnumerate}



\-Note that one call to the \-Monte \-Carlo driver will only run a single simulation. \-In order to compute a full \-Monte \-Carlo simulation, the program above should be called as many times as needed.









 \hypertarget{perturbation_manager}{}\subsection{\-Perturbation Manager}\label{perturbation_manager}

 \-A perturbation manager in \-\emph{Verdandi} is a tool to generate pseudo-\/random numbers. \-Two random numbers generator libraries are at this time interfaced \-: \href{http://www.robertnz.net/nr03doc.htm}{\tt \-Newran} and \href{http://trng.berlios.de/}{\tt \-T\-R\-N\-G}. \\
 \-One may find the implementations in the base class {\ttfamily \hyperlink{_base_perturbation_manager_8hxx_source}{\-Base\-Perturbation\-Manager.\-hxx}} and {\ttfamily \hyperlink{_base_perturbation_manager_8cxx_source}{\-Base\-Perturbation\-Manager.\-cxx}} and the derived classes for each library \-: {\ttfamily \hyperlink{_newran_perturbation_manager_8hxx_source}{\-Newran\-Perturbation\-Manager.\-hxx}} and {\ttfamily \hyperlink{_newran_perturbation_manager_8cxx_source}{\-Newran\-Perturbation\-Manager.\-cxx}} for \-Newran, {\ttfamily \hyperlink{_t_r_n_g_perturbation_manager_8hxx_source}{\-T\-R\-N\-G\-Perturbation\-Manager.\-hxx}} and {\ttfamily \hyperlink{_t_r_n_g_perturbation_manager_8cxx_source}{\-T\-R\-N\-G\-Perturbation\-Manager.\-cxx}} for \-T\-R\-N\-G.\hypertarget{perturbation_manager_configuration}{}\paragraph{\-Configuration options}\label{perturbation_manager_configuration}
\-In models, the perturbation manager can be used to perturb a variable with randomly generated numbers. \-Here are the main parameters.


\begin{DoxyEnumerate}
\item {\ttfamily distribution}\-: the type of the distribution for the random vector;
\item {\ttfamily mean}\-: mean of the distribution
\item {\ttfamily variance}\-: covariance matrix of the distribution;
\item {\ttfamily parameter}\-: vector either empty or that contains two values for clipping the distribution;
\item {\ttfamily correlation}\-: vector that contains the correlation between sub-\/vectors;
\item {\ttfamily option}\-: defines when the perturbations are to be applied (at the first step only or at every step).
\end{DoxyEnumerate}

\-Here is one example derived from the \hyperlink{quadratic_model}{\-Quadratic \-Model} configuration file. \-We want to apply a perturbation on the constant term.
\begin{frame_lua}
quadratic_model = {

   definition = {

      constant = {1.,
                  -1.}
  },


  uncertainty = {

      constant = {

         distribution = "Normal",
         mean = {0.5,
                 0.5},
         variance = {1., 0.,
                     0., 1.},
         parameter = {-1., 1.},
	 correlation = {},
         option = "init_step"

      }

   }
\end{frame_lua}


\-Keep in mind that the {\ttfamily mean} parameter is the mean of the perturbation, so that the mean of the perturbed variable will be {\ttfamily constant + mean}. \-Here, the perturbed vector will the sum of \[\left(\begin{array}{cc} -1.\\ 1.\\ \end{array} \right) + \left(\begin{array}{cc} 0.5.\\ 0.5\\ \end{array} \right) \] and a random vector generated with a centered normal distribution of variance \[\left(\begin{array}{cc} 1. & 0.\\ 0. & 1.\\ \end{array} \right) .\] \-The {\ttfamily parameter} vector ensures that the all random numbers will be between -\/1. and 1. \-The {\ttfamily correlation} parameter correlates the first sub-\/vector with each of the following. \-Since here we have only one vector to perturb, there is no correlation to apply.





 \hypertarget{ensemble_kalman_filter}{}\section{\-Ensemble Kalman Filter}\label{ensemble_kalman_filter}


\hypertarget{ensemble_kalman_filter_algorithm_enkf}{}\subsection{\-Algorithm}\label{ensemble_kalman_filter_algorithm_enkf}
\-In the ensemble \-Kalman filter, the forecast error covariance matrix is estimated with an ensemble of simulations. \-Each member of the ensemble is defined with perturbations in the initial condition and in several uncertain input parameters. \-The filter estimator is given by the ensemble mean.


\begin{DoxyEnumerate}
\item \-At time $t_0$, an ensemble $(x^{f, \{i\} }_{0})_i$ of initial conditions is generated. \-The uncertain parameters $p_0$ of the model are perturbed in each member, and denoted $\widetilde p_0^{\{i\}}$.
\item \-For every time $t_h, h \ge 0$,
\begin{DoxyItemize}
\item the forecast is the ensemble mean \par
 $x_{h}^f = \frac{1}{N} \displaystyle\sum\limits_{i=1}^{N} x^{f, \{i\} }_{h}$
\item if observations $y_h$ are available, the forecast error covariance matrix is approximated by, \par
 $P_h^{f} = \frac{1}{N-1} \displaystyle\sum\limits_{i=1}^{N} (x_{h}^{f, \{i\}} - x_{h}^f)(x_{h}^{f, \{i\}} - x_{h}^f)^T\;.$ \par
 \-The analysis is computed for each member of the ensemble\-: \par
 $x_h^{a, \{i\}} = x_h^{f, \{i\}} + K_h(y_h - \mathcal{H}_h(x_h^{f, \{i\}}))$, \par
 with \par
 $K_h = P_h^{f}H_h^{T}(H_hP_h^{f}H_h^{T} + R_h)^{-1}\;.$ \par
 \-The subsequent forecast is \par
 $x_{h+1}^{f,\{i\}} = \mathcal{M}_h(x_h^{a ,\{i\}}, \widetilde p_h^{\{i\}})\;.$ \par
 \-The parameters $p_{h+1}$ are then perturbed and denoted $\widetilde p_{h+1}$.
\item if there are no observations, the forecast is \par
 $x_{h+1}^{f,\{i\}} = \mathcal{M}_h(x_h^{f ,\{i\}}, \widetilde p_h^{\{i\}})\;.$ \par
 \-The parameters $p_{h+1}$ are then perturbed and denoted $\widetilde p_{h+1}$.
\end{DoxyItemize}
\end{DoxyEnumerate}\-With\-: \par
 $x_h^f$ forecast state vector (ensemble mean); \par
 $x_h^a$ analysis state vector (ensemble mean); \par
 $x_h^{f, \{i\}}$ forecast state vector of member $i$ of the ensemble; \par
 $x_h^{a, \{i\}}$ analysis state vector of member $i$ of the ensemble; \par
 $y_h$ observation vector; \par
 $\mathcal{H}_h$ observation operator that maps the state space to the observation space; \par
 $H^{\{i\}}_h$ observation operator linearized at $x^f_h$; \par
 $P_h^{f}$ error covariance matrix of $x_h^f$; \par
 $R_h$ observational error covariance matrix; \par
 $K_h$ analysis gain matrix; \par
 $p_h$ model parameters; \par
 $\widetilde p_h$ perturbed model parameters; \par
 $\mathcal{M}_h$ model.


 \hypertarget{ensemble_kalman_filter_implementation}{}\subsection{\-Implementation}\label{ensemble_kalman_filter_implementation}

 \hyperlink{namespace_verdandi}{\-Verdandi} provides a \-C++ implementation of the \-Ensemble \-Kalman \-Filter (\-En\-K\-F).

 \-The \-Ensemble \-Kalman \-Filter (\-En\-K\-F) is implemented in {\ttfamily \hyperlink{_ensemble_kalman_filter_8hxx_source}{\-Ensemble\-Kalman\-Filter.\-hxx}} and {\ttfamily \hyperlink{_ensemble_kalman_filter_8cxx_source}{\-Ensemble\-Kalman\-Filter.\-cxx}}. \\
 \-The class {\ttfamily  \hyperlink{class_verdandi_1_1_ensemble_kalman_filter}{\-Ensemble\-Kalman\-Filter}} is a template class\-:\\
  {\ttfamily \-Ensemble\-Kalman\-Filter$<$\-T, Class\-Model, Class\-Observation\-Manager, Class\-Perturbation\-Manager$>$}.
  \begin{itemize}
  \item {\ttfamily \-T} is the type of the elements to be stored (e.\-g., {\ttfamily double}).
  \item {\ttfamily \-Class\-Model} is the type of the model (e.\-g., {\ttfamily \-Shallow\-Water$<$double$>$}).
  \item {\ttfamily \-Class\-Observation\-Manager} is the type of the observation manager (e.\-g. {\ttfamily \-Linear\-Observation\-Manager$<$double$>$}).
  \item {\ttfamily \-Class\-Perturbation\-Manager} is the type of the perturbation manager (e.\-g. {\ttfamily \-Newran\-Perturbation\-Manager}).
  \end{itemize}

\-A simulation with \-Ensemble \-Kalman filter (\-En\-K\-F) may be carried out with the following \-C++ lines\-:

 \begin{frame_cpp}
EnsembleKalmanFilter<real, ShallowWater<real>,
        LinearObservationManager<real>, NewranPerturbationManager> driver; [1]

driver.Initialize(argv[1]); [2]

while (!driver.HasFinished()) [6]
{
    driver.InitializeStep(); [3]
    driver.Forward(); [4]
    driver.Analyze(); [5]
}
\end{frame_cpp}





\begin{DoxyEnumerate}
\item \-First build the {\ttfamily  \hyperlink{class_verdandi_1_1_ensemble_kalman_filter}{\-Ensemble\-Kalman\-Filter}} driver with the construction {\ttfamily  \hyperlink{class_verdandi_1_1_ensemble_kalman_filter_abb2d27f6bef00753e9998b84fa434903}{\-Ensemble\-Kalman\-Filter}}.


\item \-Then initialize the driver, the model, the observation manager, the perturbation manager and read option keys in the configuration file with {\ttfamily  \hyperlink{}{\-Initialize(configuration\-\_\-file)}}. \-Model parameters or initial conditions are perturbed differently for each member of the ensemble at that stage.


\item \-Optionally initialize the model before a time step with {\ttfamily  \hyperlink{class_verdandi_1_1_ensemble_kalman_filter_ad83360d77648baa50cb701361a8c9261}{\-Initialize\-Step()}}. \-Perturbations can be applied again.


\item \-Perform a step forward with {\ttfamily  \hyperlink{class_verdandi_1_1_ensemble_kalman_filter_aff9ba74ef1ca5d33409a0d1358449093}{\-Forward()}} for all members of the ensemble.


\item \-Compute the analysis with {\ttfamily  \hyperlink{class_verdandi_1_1_ensemble_kalman_filter_ab5ac8954477fd12eb49acf81793d76b6}{\-Analyze()}} whenever observations are available.


\item \-Iterate until the model has finished\-: {\ttfamily  \hyperlink{class_verdandi_1_1_ensemble_kalman_filter_a9eda1d9299a0677c40c39491fea855a8}{\-Has\-Finished()}} returns true if the simulation is done, false otherwise.
\end{DoxyEnumerate}



\hypertarget{four_dimensional_variational}{}\section{\-Four Dimensional Variational}\label{four_dimensional_variational}


\hypertarget{four_dimensional_variational_algorithm4dv}{}\subsection{\-Algorithm}\label{four_dimensional_variational_algorithm4dv}

\-Let consider $ (x_h(\xi))_h $ such that $ x_{h=0}(\xi) = x_0 + \xi $.

\-Given the observations $ y_h $ and the a priori on the initial condition $ x_0 $, we want to find the parameter $ \xi $ optimal for the quadratic criterion \begin{center} $ \displaystyle \mathcal{J}(\xi) = \frac{1}{2} \| \xi \|^2_{P_0^{-1}} + \frac{1}{2} \displaystyle\sum\limits_{h=0}^{N_t} \|y_h - H_h x_h(\xi) \|^2_{R_h^{-1}} $. \end{center}

\-The \-Four \-Dimensional \-Variational assimilation method (4\-D\-V\-A\-R) carries out the minimization of the previous cost function.

\hypertarget{four_dimensional_variational_algorithm4dv0}{}\paragraph{\-Gradient-\/based optimization}\label{four_dimensional_variational_algorithm4dv0}

\-Gradient descent algorithms are usually used in the minimization of the cost function. \-We therefore need to compute the gradient of the cost function $ \mathcal{J}$.

$ \mathcal{J}$ admits a minimum at a point where $ \mathrm{d}_\xi \mathcal{J} = 0 $. \-Yet, \begin{center} $ \mathrm{d}_\xi \mathcal{J} \cdot \delta \xi = \xi^T P_0^{-1} \delta \xi - \displaystyle\sum\limits_{h=0}^{N_t} (y_h - H_h x_h)^T R_h^{-1} H_h \mathrm{d}_\xi x_h \cdot \delta \xi $, \end{center}  with \begin{center} $ \mathrm{d}_\xi x_{h+1} = M_{h+1} \mathrm{d}_\xi x_h $, $ \mathrm{d}_\xi x_0 = 1 $ \end{center}

\-Then, we introduce $ (p_h)_{1 \le h \le N_t}$ fulfilling the adjoint dynamic of $ x_h $,

\begin{center} $ p_h - M_{h+1}^T p_{h+1} = H_h^T R_h^{-1} (y_h - H_h x_h)$\end{center}
\begin{center} $ p_{N_t} = 0 $ \end{center}

\-And we can prove that \begin{center} $ \mathrm{d} \mathcal{J}\cdot\delta \xi = \xi^T P_0^{-1} \delta \xi - p_0^T \delta \xi $. \end{center}

 \hypertarget{four_dimensional_variational_algorithm4dv1}{}\paragraph{\-Derivative-\/free optimization}\label{four_dimensional_variational_algorithm4dv1}

\-One can also try derivative-\/free algorithms such as \-C\-O\-B\-Y\-L\-A (\-Constrained \-Optimization \-B\-Y \-Linear \-Approximations) or \-P\-R\-A\-X\-I\-S (optimization via the \char`\"{}principal-\/axis method\char`\"{}).


\hypertarget{four_dimensional_variational_algorithm4dvnotation}{}\paragraph{\-Notation}\label{four_dimensional_variational_algorithm4dvnotation}

 $x_h$ state vector; \par
 $y_h$ observation vector; \par
 $\mathcal{H}_h$ observation operator that maps the state space to the observation space; \par
 $H_h$ observation operator linearized at $x_h$; \par
 $P_h$ error covariance matrix of $x_h$; \par
 $R_h$ observational error covariance matrix; \par
 $\mathcal{M}_h$ model.


\hypertarget{four_dimensional_variational_implementation}{}\subsection{\-Implementation}\label{four_dimensional_variational_implementation}

\hyperlink{namespace_verdandi}{\-Verdandi} provides a \-C++ implementation of the \-Four \-Dimensional \-Variational assimilation method (4\-D\-V\-A\-R).

\-The \-Four \-Dimensional \-Variational assimilation method (4\-D\-V\-A\-R) is implemented in {\ttfamily \hyperlink{_four_dimensional_variational_8hxx_source}{\-Four\-Dimensional\-Variational.\-hxx}} and {\ttfamily \hyperlink{_four_dimensional_variational_8cxx_source}{\-Four\-Dimensional\-Variational.\-cxx}}.\\
 \-The class {\ttfamily  \hyperlink{class_verdandi_1_1_four_dimensional_variational}{\-Four\-Dimensional\-Variational}} is a template class\-: \\
 {\ttfamily \-Four\-Dimensional\-Variational$<$\-T, \-Class\-Model, \-Class\-Observation\-Manager, \-Class\-Optimization$>$}.
 \begin{itemize}
 \item {\ttfamily \-T} is the type of the elements to be stored (e.\-g. {\ttfamily double}).
 \item {\ttfamily \-Class\-Model} is the type of the model (e.\-g. {\ttfamily \-Clamped\-Bar$<$double$>$}).
 \item {\ttfamily \-Class\-Observation\-Manager} is the type of the observation manager (e.\-g. {\ttfamily \-Linear\-Observation\-Manager$<$double$>$}).
 \item {\ttfamily \-Class\-Optimization} is the type of the optimization algorithm (e.\-g. {\ttfamily \-Seldon\-::\-N\-Lopt\-Solver}).
 \end{itemize}
\-The implementation of the \-Four \-Dimensional \-Variational assimilation method (4\-D\-V\-A\-R) relies on the \href{http://www.seldon.sourceforge.net}{\tt \-Seldon} \hyperlink{optimization_solver}{\-Optimization \-Solver}, to carry out nonlinear optimization. \-One optimization library is at this time interfaced\-: \href{http://ab-initio.mit.edu/wiki/index.php/NLopt}{\tt \-N\-Lopt}. \-The installation procedure of the \-N\-Lopt \-Solver is detailed in the section \hyperlink{optimization_solver_nlopt_installation}{\-N\-Lopt \-Installation}.

\-A simulation with the \-Four \-Dimensional \-Variational assimilation method (4\-D\-V\-A\-R) may be carried out with the following \-C++ lines\-:

 \begin{frame_cpp}
FourDimensionalVariational<real, ClampedBar<real>,
        LinearObservationManager<real>, Seldon::NLoptSolver> driver; [1]

driver.Initialize(argv[1]); [2]

driver.Analyze(); [3]

while (!driver.HasFinished()) [6]
{
    driver.InitializeStep(); [4]

    driver.Forward(); [5]
}
\end{frame_cpp}



\begin{DoxyEnumerate}
\item \-First build the {\ttfamily  \hyperlink{class_verdandi_1_1_four_dimensional_variational}{\-Four\-Dimensional\-Variational}} driver with the construction {\ttfamily  \hyperlink{class_verdandi_1_1_four_dimensional_variational_ae14f6f280b12bb02e4440e5b08513ab7}{\-Four\-Dimensional\-Variational}}.


\item \-Then initialize the driver, the model and the observation manager, and read option keys in the configuration file with {\ttfamily  \hyperlink{class_verdandi_1_1_four_dimensional_variational_ae957a078f20e349479b7c823850e975b}{\-Initialize(configuration\-\_\-file)}}.


\item \-Compute the initial condition with {\ttfamily  \hyperlink{class_verdandi_1_1_four_dimensional_variational_a746e6da7fbc0cb815ef10a790c87e42b}{\-Analyze()}}, whenever observations are available.


\item \-Optionally intialize a step with {\ttfamily  \hyperlink{class_verdandi_1_1_four_dimensional_variational_a8171f91eeb3ff4ed62c37d92d285148d}{\-Initialize\-Step()}}. \-This initializes a step for the model.


\item \-Perform a step forward and propagate the state error variance with {\ttfamily  \hyperlink{class_verdandi_1_1_four_dimensional_variational_a562aa63b8f14856831f0a39e573c10ad}{\-Forward()}}.


\item \-Compute the data assimilation until the model has finished\-: {\ttfamily  \hyperlink{class_verdandi_1_1_four_dimensional_variational_ae1c4dd6b21f14e5ad157f9ce6699069c}{\-Has\-Finished()}} returns true if the simulation is done, false otherwise.
\end{DoxyEnumerate}


\hypertarget{optimization_solver_nlopt}{}\subsection{\-N\-Lopt Solver}\label{optimization_solver_nlopt}

\-An optimization solver in \-\emph{Verdandi} is a tool to carry out nonlinear optimization. \-One optimization library is at this time interfaced\-: \href{http://ab-initio.mit.edu/wiki/index.php/NLopt}{\tt \-N\-Lopt}.
\hypertarget{optimization_solver_nlopt_installation}{}\paragraph{\-N\-Lopt Installation}\label{optimization_solver_nlopt_installation}
\-Download the latest version available from the \href{http://ab-initio.mit.edu/wiki/index.php/NLopt#Download_and_installation}{\tt \-N\-Lopt web site } and follow the \href{http://ab-initio.mit.edu/wiki/index.php/NLopt_Installation}{\tt \-N\-Lopt \-Installation } instructions.

\hypertarget{optimization_solver_using_nlopt}{}\paragraph{\-Using N\-Lopt Solver}\label{optimization_solver_using_nlopt}

\href{http://ab-initio.mit.edu/wiki/index.php/NLopt}{\tt \-N\-Lopt} provides algorithms to solve optimization problems. \-N\-Lopt \-Solver is a \href{http://www.seldon.sourceforge.net}{\tt \-Seldon} interface to \href{http://ab-initio.mit.edu/wiki/index.php/NLopt}{\tt \-N\-Lopt}. \-It can be used in a \-\emph{Verdandi} data assimilation method.

\-An example of its use in a method can be found in the \hyperlink{four_dimensional_variational}{\-Four \-Dimensional \-Variational (4\-D\-Var) method}.

\hypertarget{optimization_solver_nlopt_configuration}{}\paragraph{\-Configuration}\label{optimization_solver_nlopt_configuration}

\-The main \-N\-Lopt \-Solver configuration options are described below.


\begin{DoxyItemize}
\item {\ttfamily algorithm}\-: the optimization algorithm. \href{http://ab-initio.mit.edu/wiki/index.php/NLopt}{\tt \-N\-Lopt} provides \href{http://ab-initio.mit.edu/wiki/index.php/NLopt_Algorithms#Local_gradient-based_optimization}{\tt gradient-\/based optimization algorithms } and \href{http://ab-initio.mit.edu/wiki/index.php/NLopt_Algorithms#Local_derivative-free_optimization}{\tt derivative-\/free optimization algorithms }.

\-The name of the optimization algorithm has to be one of\-:

\begin{TabularC}{2}
\hline
\href{http://ab-initio.mit.edu/wiki/index.php/NLopt_Algorithms#Local_gradient-based_optimization}{\tt gradient-\/based optimization algorithms}  &\href{http://ab-initio.mit.edu/wiki/index.php/NLopt_Algorithms#Local_derivative-free_optimization}{\tt derivative-\/free optimization algorithms }  \\\cline{1-2}
{\ttfamily \-L\-D\-\_\-\-L\-B\-F\-G\-S } &{\ttfamily \-L\-N\-\_\-\-P\-R\-A\-X\-I\-S}  \\\cline{1-2}
{\ttfamily \-L\-D\-\_\-\-L\-B\-F\-G\-S\-\_\-\-N\-O\-C\-E\-D\-A\-L } &{\ttfamily \-L\-N\-\_\-\-C\-O\-B\-Y\-L\-A}  \\\cline{1-2}
{\ttfamily \-L\-D\-\_\-\-V\-A\-R1 } &{\ttfamily \-L\-N\-\_\-\-B\-O\-B\-Y\-Q\-A}  \\\cline{1-2}
{\ttfamily \-L\-D\-\_\-\-V\-A\-R2 } &{\ttfamily \-L\-N\-\_\-\-N\-E\-W\-U\-O\-A}  \\\cline{1-2}
{\ttfamily \-L\-D\-\_\-\-T\-N\-E\-W\-T\-O\-N } &{\ttfamily \-L\-N\-\_\-\-N\-E\-W\-U\-O\-A\-\_\-\-B\-O\-U\-N\-D}  \\\cline{1-2}
{\ttfamily \-L\-D\-\_\-\-T\-N\-E\-W\-T\-O\-N\-\_\-\-R\-E\-S\-T\-A\-R\-T } &{\ttfamily \-L\-N\-\_\-\-N\-E\-L\-D\-E\-R\-M\-E\-A\-D}  \\\cline{1-2}
{\ttfamily \-L\-D\-\_\-\-T\-N\-E\-W\-T\-O\-N\-\_\-\-P\-R\-E\-C\-O\-N\-D } &{\ttfamily \-L\-N\-\_\-\-S\-B\-P\-L\-X}  \\\cline{1-2}
{\ttfamily \-L\-D\-\_\-\-T\-N\-E\-W\-T\-O\-N\-\_\-\-P\-R\-E\-C\-O\-N\-D\-\_\-\-R\-E\-S\-T\-A\-R\-T } &{\ttfamily \-L\-N\-\_\-\-A\-U\-G\-L\-A\-G}  \\\cline{1-2}
{\ttfamily \-L\-D\-\_\-\-M\-M\-A } &{\ttfamily \-L\-N\-\_\-\-A\-U\-G\-L\-A\-G\-\_\-\-E\-Q}  \\\cline{1-2}
{\ttfamily \-L\-D\-\_\-\-A\-U\-G\-L\-A\-G\-\_\-\-E\-Q } &\\\cline{1-2}
{\ttfamily \-L\-D\-\_\-\-S\-L\-S\-Q\-P } &\\\cline{1-2}
\end{TabularC}



\item {\ttfamily parameter\-\_\-tolerance}\-: the relative tolerance on the parameters. \-When the variation of the parameters, after one step of the algorithm, has changed by less than {\ttfamily parameter\-\_\-tolerance} multiplied by the value of the parameters, the optimization is stopped. \-If you do not want to use a particular tolerance termination, you can just set that tolerance to zero and it will be ignored.


\item {\ttfamily cost\-\_\-function\-\_\-tolerance}\-: the relative tolerance on the cost function. \-When the variation of the cost function, after one step of the algorithm, has changed by less than {\ttfamily cost\-\_\-function\-\_\-tolerance} multiplied by the value of the cost function, the optimization is stopped. \-If you do not want to use a particular tolerance termination, you can just set that tolerance to zero and it will be ignored.


\item {\ttfamily \-Niteration\-\_\-max}\-: the maximum number of cost function evaluations. \-It is ignored if it is non-\/positive.


\end{DoxyItemize}

\-Here is an example derived from the \hyperlink{four_dimensional_variational}{\-Four \-Dimensional \-Variational (4\-D\-Var)} configuration file.

 \begin{frame_lua}
-- Simulation with assimilation using 4D-VAR.
four_dimensional_variational = {

   nlopt = {

      -- Optimization algorithm (LD_VAR1, LD_LBFGS, LD_SLSQP, LD_MMA,
      -- LD_TNEWTON ...).
      algorithm = "LD_VAR1",

      -- If you do not want to use a particular tolerance termination, you can
      -- just set that tolerance to zero and it will be ignored.
      -- Relative tolerance on the optimization parameters.
      parameter_tolerance = 1.e-4,
      -- Relative tolerance on the cost function.
      cost_function_tolerance = 1.e-4,
      -- Maximum number of function evaluations. Criterion is disabled
      -- if the value is non-positive.
      Niteration_max = -1

   }

}
\end{frame_lua}



% ========================================================================
% Plugging in Verdandi
% ========================================================================
\chapter{Plugging in Verdandi}


\-This section of the documentation explains how to plug an external model and observations in \-Verdandi. \-The first step is to build an \hyperlink{plugging_model}{interface to the model}. \-The second step is either having an existing observation manager \hyperlink{plugging_observation}{read the observations}, or writing a \hyperlink{plugging_observation}{new observation manager}.

\hypertarget{plugging_in_verdandi_reference_notation}{}\section{\-Reference Notation}\label{plugging_in_verdandi_reference_notation}

\-The tables below list the variables involved in data assimilation. \-For each variable, the name of the \-C++ type (a {\ttfamily typedef}) and the recommended \-C++ variable name are given.

\-For details about the mathematical description of these variables see section \hyperlink{mathematical_notation}{mathematical notation}.

\hypertarget{plugging_in_verdandi_model_table}{}\subsection{\-Model}\label{plugging_in_verdandi_model_table}
\begin{TabularC}{3}
\hline
\-Variable(s) &\-Typedef &\-C++ \-Variable(s)  \\\cline{1-3}
$x, x^f, x^a$ &{\ttfamily state} &{\ttfamily x, xf, xa}  \\\cline{1-3}
$P, P^f, P^a$ &{\ttfamily state\-\_\-error\-\_\-variance} &{\ttfamily \-P, \-Pf, \-Pa}  \\\cline{1-3}
\-Row of $P, P^f, P^a$ &{\ttfamily state\-\_\-error\-\_\-variance\-\_\-row} &{\ttfamily \-P\-\_\-row, \-Pf\-\_\-row, \-Pa\-\_\-row}  \\\cline{1-3}
$Q$ &{\ttfamily error\-\_\-variance} &{\ttfamily \-Q}  \\\cline{1-3}
$\bar e^m$ &{\ttfamily systematic\-\_\-error} &{\ttfamily em\-\_\-bar}  \\\cline{1-3}
$\mathrm{M}$ &{\ttfamily tangent\-\_\-linear\-\_\-operator} &{\ttfamily \-M}  \\\cline{1-3}
&{\ttfamily matrix\-\_\-state\-\_\-observation} &{\ttfamily }  \\\cline{1-3}
\end{TabularC}


{\ttfamily matrix\-\_\-state\-\_\-observation} determines the type of matrices of size $n \times m$.\hypertarget{plugging_in_verdandi_observation_table}{}\subsection{\-Observation Manager}\label{plugging_in_verdandi_observation_table}
\begin{TabularC}{3}
\hline
\-Variable(s) &\-Typedef &\-C++ \-Variable(s)  \\\cline{1-3}
$y$ &{\ttfamily observation} &{\ttfamily y}  \\\cline{1-3}
$R$ &{\ttfamily observation\-\_\-error\-\_\-variance} &{\ttfamily \-R}  \\\cline{1-3}
$\bar e^o$ &{\ttfamily observation\-\_\-systematic\-\_\-error} &{\ttfamily eo\-\_\-bar}  \\\cline{1-3}
$H$ &{\ttfamily tangent\-\_\-linear\-\_\-operator} &{\ttfamily \-H}  \\\cline{1-3}
\end{TabularC}


\par
\hypertarget{plugging_in_verdandi_Notes}{}\subsection{\-Notes}\label{plugging_in_verdandi_Notes}
\-In the assimilation algorithms, the same {\ttfamily typedef}s are defined with {\ttfamily model\-\_\-} or {\ttfamily observation\-\_\-} prepended. \-There are two exceptions\-: nothing is not prepended to {\ttfamily matrix\-\_\-state\-\_\-observation} and {\ttfamily observation} ( $y$).

\-The {\ttfamily typedef}s should be public in the model class and the observation class, so that the assimilation method may access to them.

\-In the assimilation methods, the following variables are also used.

\begin{TabularC}{3}
\hline
\-Variable(s) &\-Meaning &\-C++ \-Variable(s)  \\\cline{1-3}
$l$ &\-Number of model parameters (size of $p$) &{\ttfamily \-Nparameter}  \\\cline{1-3}
$m$ &\-Number of observations (size of $y$) &{\ttfamily \-Nobservation}  \\\cline{1-3}
$n$ &\-Size of the state vector $x$ &{\ttfamily \-Nstate}  \\\cline{1-3}
\end{TabularC}



\hypertarget{plugging_model}{}\section{\-Plugging a C++ Model}\label{plugging_model}

\hypertarget{plugging_model_own_model}{}\subsection{\-Create your Own Model}\label{plugging_model_own_model}
\-Start from the {\ttfamily  \hyperlink{model_template}{\-Model\-Template}}. \-The complete interface of the model class is described {\ttfamily  \hyperlink{model_template}{here}}. With a complete interface, one can apply any data assimilation method in Verdandi. But for a given data assimilation method, not all methods are required. Use the \hyperlink{model_requirement_page}{\-Model requirements page} to know precisely which methods you will need to implement in your model.


\begin{DoxyItemize}
\item \-In the model directory, copy the {\ttfamily  \hyperlink{model_template}{\-Model\-Template}} and rename it to "\-My\-Model". \-E.\-g., under \-Linux or \-Mac\-O\-S, in command line\-:

\begin{frame_bash}
host<~/> cd verdandi/model/
host<~/> cp \-Model\-Template.\-hxx \-My\-Model.\-hxx
host<~/> cp \-Model\-Template.\-cxx \-My\-Model.\-cxx
\end{frame_bash}

\item \-Open the files {\ttfamily \-My\-Model.$\ast$xx}, rename the preprocessing variables.

\begin{frame_cpp}
#ifndef VERDANDI_FILE_MODEL_MODELTEMPLATE_*XX
#define VERDANDI_FILE_MODEL_MODELTEMPLATE_*XX
\end{frame_cpp}

into

\begin{frame_cpp}
#ifndef VERDANDI_FILE_MODEL_MYMODEL_*XX
#define VERDANDI_FILE_MODEL_MYMODEL_*XX
\end{frame_cpp}


\item \-Replace all \char`\"{}\-Model\-Template\char`\"{} occurrences with \char`\"{}\-My\-Model\char`\"{}.


\item \-In a first step, it is advised to write the interface for the \hyperlink{class_verdandi_1_1_forward_driver}{\-Forward\-Driver} method which requires only a limited number of methods to be implemented.

\-Create a directory {\ttfamily my\-\_\-model} in the {\ttfamily example} directory. \-Copy in {\ttfamily my\-\_\-model} the following files\-: {\ttfamily example/quadratic\-\_\-model/\-S\-Construct}, {\ttfamily example/quadratic\-\_\-model/forward.\-cpp} and the configuration file {\ttfamily example/quadratic\-\_\-model/configuration/truth.\-lua}. \-E.\-g.\-:

\begin{frame_bash}
host<~/>  cd verdandi/example/
host<~/> mkdir -p my_model/configuration
host<~/> cp quadratic_model/{SConstruct,forward.cpp} my_model/
host<~/> cp quadratic_model/configuration/truth.lua my_model/configuration/
\end{frame_bash}


\-Edit the {\ttfamily \-S\-Construct} file to specify your {\ttfamily verdandi\-\_\-path/} by adding this line\-:

 \begin{frame_python}
verdandi_path = "your_verdandi_path"
\end{frame_python}



\item \-In the file {\ttfamily \hyperlink{forward_8cpp_source}{forward.\-cpp}} replace all \char`\"{}\-Model\-Template\char`\"{} occurrences with \char`\"{}\-My\-Model\char`\"{}.


\begin{frame_cpp}
#define VERDANDI_DEBUG_LEVEL_4 [1]
#define SELDON_WITH_BLAS
#define SELDON_WITH_LAPACK

#define VERDANDI_WITH_ABORT

#include "Verdandi.hxx" [2]

#include "model/MyModel.cxx"
#include "method/ForwardDriver.cxx"


int main(int argc, char** argv)
{
    VERDANDI_TRY;

    if (argc != 2)
    {
        string mesg  = "Usage:\n";
        mesg += string("  ") + argv[0] + " [configuration file]";
        std::cout << mesg << std::endl;
        return 1;
    }

    Verdandi::ForwardDriver<Verdandi::MyModel<double> >
        driver;

    driver.Initialize(argv[1]);

    while (!driver.HasFinished())
    {
        driver.InitializeStep();
        driver.Forward();
        driver.FinalizeStep();
    }

    driver.Finalize();

    VERDANDI_END;

    return 0;
}
\end{frame_cpp}

\begin{enumerate}
\item \emph{Verdandi} options are described in Section \ref{tips_options}.
\item {\ttfamily \hyperlink{_verdandi_8hxx_source}{\-Verdandi.\-hxx}} has to be included in any program. It is located in the directory {\ttfamily \-Verdandi-\/\mbox{[}version\mbox{]}/} expanded from the archive.
\end{enumerate}



\item \-Compile the program \hyperlink{forward_8cpp_source}{forward.\-cpp}.

\begin{frame_bash}
host<~/> scons forward
\end{frame_bash}


\item \-Run the forward program.

\begin{frame_bash}
host<~/> ./forward configuration/truth.\-lua
\end{frame_bash}

\-At run time, if a method is needed in the model class, and if this method is not implemented, the program will launch an exception. \-For instance, if the method \hyperlink{class_verdandi_1_1_model_template_a4aa54740408c0e5ef7e6b1c8a10a4c2d}{\-Has\-Finished} is undefined, an exception will be thrown to report you this error. \-Then, see the contract of this method (\hyperlink{class_verdandi_1_1_model_template_a4aa54740408c0e5ef7e6b1c8a10a4c2d}{\-Has\-Finished}) and implement it. \-You can also have a look into the example models in {\ttfamily verdandi/model/}.


\end{DoxyItemize}\hypertarget{plugging_model_existing_model}{}\subsection{\-Plugging an Existing Model}\label{plugging_model_existing_model}
\-Usually, one wants to create an interface for an existing model and to rely on existing model compilation tools.

\-We recommend the following procedure\-:
\begin{enumerate}
\item \-Create a class which {\bfseries encapsulates} the existing model and which implements the \hyperlink{namespace_verdandi}{\-Verdandi} model interface (follow the same steps as in the previous section, \hyperlink{plugging_model_own_model}{\-Create your own model}).

\paragraph{Example}



\begin{frame_cpp}
class ExampleModel
{

    private:
        //! Size of the displacement vector.
        int Ndisplacement;
        //! Displacement vector.
        double* displacement;
        //! Size of the velocity vector.
        int Nvelocity;
        //! Velocity vector.
        double* velocity;

        ...

    public:
        // Constructor and destructor.
        ExampleModel();
        ~ExampleModel();

        int GetNdisplacement();
        double* GetDisplament();
        int GetNvelocity();
        double* GetVelocity();


        	...
}
\end{frame_cpp}

\marginnote{
  \begin{tikzpicture}

        % MÃ©thode d'assimilation.
        \draw[rounded corners, fill = blue!50] (7., 2.) -- (10.4, 2.)
        node[anchor=north east] {ModelTemplate} -- (10.4, -3.3) -- (7., -3.3) -- (7., -2.2)
        -- (7.3, -2.2) -- (7.3, -2.6) -- (9.4, -2.6) node[anchor=south
        east](interior_down) {} -- (9.4, 1.3) -- (7.3, 1.3)
        node(interior_up)[anchor=north west] {} -- (7.3, .9) -- (7., .9) --
        cycle;

        % ModÃ¨le.
        \draw[rounded corners, fill = black] (interior_up) rectangle
        (9.3, -2.4);
        \path (interior_up) -- (9.3, -2.4) node[midway, text
        width=1.5cm, text centered, color = white]{Example Model};

      \end{tikzpicture}}

\begin{frame_cpp}
class ModelTemplate: public Verdandi:VerdandiBase
{
    //! Type of the state vector.
     typedef Vector<double> state;

    private:
        //! Encapsulated example model.
        ExampleModel model_;
        //! State vector.
        state x_;

    public:
        // Constructor and destructor.
        ModelTemplate();
        ~ModelTemplate();

        ...

        // Access methods.
        int GetNstate();
        state& GetState();
        void StateUpdated();

	...
}
\end{frame_cpp}

For each method needed in the model class, see the contract provided by the  {\ttfamily  \hyperlink{model_template}{\-Model\-Template}} and implement it. For example, the
\hyperlink{class_verdandi_1_1_model_template_a44b42fdd4448173cbcb8c2b64733e534}{\-Get\-Nstate} () method  contract and its corresponding implementation are:

\textbf{Contract}\\

int \hyperlink{class_verdandi_1_1_model_template_a44b42fdd4448173cbcb8c2b64733e534}{\-Get\-Nstate} () const
\begin{DoxyCompactList}\small\item\em \-Returns the state vector size. \end{DoxyCompactList}


\textbf{Implementation}\\

\begin{frame_cpp}
    int ModelTemplate::GetNstate()
    {
        return model_.GetNdisplacement() + model_.GetNvelocity();
    }
\end{frame_cpp}


\paragraph{Accessing the Model State by Copy}

Access to the model state vector can be performed by copy or reference. Here is described the procedure to access the model state by copy.

\textbf{Contract}\\

\hyperlink{class_verdandi_1_1_model_template_a6bb9efb7898f067bb21780159b497ba7}{state} \& \hyperlink{class_verdandi_1_1_model_template_ae014bde61361001da52aab36d89f0048}{\-Get\-State} ()
\begin{DoxyCompactList}\small\item\em \-Provides the controlled state vector. \end{DoxyCompactList}


\textbf{Implementation}\\

\begin{frame_cpp}
    ModelTemplate::state& ModelTemplate::GetState()
    {
        x_.Reallocate(model_.GetNdisplacement() + model_.GetNvelocity());
        int position = 0;
        for (int i = 0; i < model_.GetNdisplacement(); i++)
            x_(position++) = model_.GetDisplacement()[i];
        for (int i = 0; i < model_.GetNvelocity(); i++)
            x_(position++) = model_.GetVelocity()[i];
        return x_;
    }
\end{frame_cpp}


\textbf{Contract}\\
\hypertarget{class_verdandi_1_1_model_template_a885248c5bbe5a173277a551b3f253277}{
void \hyperlink{class_verdandi_1_1_model_template_a885248c5bbe5a173277a551b3f253277}{\-State\-Updated} ()}
\label{class_verdandi_1_1_model_template_a885248c5bbe5a173277a551b3f253277}
\begin{DoxyCompactList}\small\item\em \-Performs some calculations when the update of the model state is done. \end{DoxyCompactList}

\textbf{Implementation}\\

\begin{frame_cpp}
    void ModelTemplate::StateUpdated()
    {
        int position = 0;
        for (int i = 0; i < model_.GetNdisplacement(); i++)
           model_.GetDisplacement()[i] = x_(position++);
        for (int i = 0; i < model_.GetNvelocity(); i++)
            model_.GetVelocity()[i] = x_(position++);
    }
\end{frame_cpp}


\paragraph{Accessing the Model State by Reference}

In case of large-scale model, it is advised to pass the model state vector by reference. The type of the model state vector
has to be changed from a \href{http://www.seldon.sourceforge.net}{\tt \-Seldon}  dense vector to a \href{http://www.seldon.sourceforge.net}{\tt \-Seldon}  collection vector  (a structure for distributed vectors):

\begin{frame_cpp}
class ModelTemplate: public Verdandi:VerdandiBase
{
    //! Type of the state vector.
     typedef Vector<double, Collection> state;
	...
}
\end{frame_cpp}

\textbf{Contract}\\

void \hyperlink{class_verdandi_1_1_model_template_a986ea8e6681bff1219716418a351fab0}{\-Initialize} (string configuration\-\_\-file)
\begin{DoxyCompactList}\small\item\em \-Initializes the model. \end{DoxyCompactList}


\textbf{Implementation}\\

\begin{frame_cpp}
    void ModelTemplate::Initialize(string configuration_file)
    {
    	...

        Vector<double> displacement;
        // This method sets the inner vector displacement pointer
        // to the 'ModelExample' array containing elements.
        displacement.SetData(model_.GetDisplacement());
        Vector<double> velocity;
        // This method sets the inner vector velocity pointer
        // to the 'ModelExample' array containing elements.
        velocity.SetData(model_.GetVelocity());

        // Adds a vector to the list of vectors.
        x_.AddVector(displacement, "displacement");
        // The vector is "appended" to the existing data.
        x_.AddVector(velocity, "velocity");

        // Clears the vector without releasing memory.
        // On exit, the vector is empty and the memory has not been
        // released.
        displacement.Nullify();
        velocity.Nullify();

        ...
    }
\end{frame_cpp}

\textbf{Contract}\\

\hyperlink{class_verdandi_1_1_model_template_a6bb9efb7898f067bb21780159b497ba7}{state} \& \hyperlink{class_verdandi_1_1_model_template_ae014bde61361001da52aab36d89f0048}{\-Get\-State} ()
\begin{DoxyCompactList}\small\item\em \-Provides the controlled state vector. \end{DoxyCompactList}


\textbf{Implementation}\\

Copies are no longer required since the  {\ttfamily  \hyperlink{model_template}{\-Model\-Template}} state is a collection of vectors whose each inner pointer is set to the 'ModelExample' array containing state elements.

\begin{frame_cpp}
    ModelTemplate::state& ModelTemplate::GetState()
    {
    	return x_;
    }
\end{frame_cpp}


\textbf{Contract}\\
\hypertarget{class_verdandi_1_1_model_template_a885248c5bbe5a173277a551b3f253277}{
void \hyperlink{class_verdandi_1_1_model_template_a885248c5bbe5a173277a551b3f253277}{\-State\-Updated} ()}
\label{class_verdandi_1_1_model_template_a885248c5bbe5a173277a551b3f253277}
\begin{DoxyCompactList}\small\item\em \-Performs some calculations when the update of the model state is done. \end{DoxyCompactList}

\textbf{Implementation}\\

In this case, calculations when the update of the model state is done are no longer required.

\begin{frame_cpp}
    void ModelTemplate::StateUpdated()
    {

    }
\end{frame_cpp}


\item \-Create an object file from this class using your own compilation tools.
\item \-Add this object file to the \hyperlink{namespace_verdandi}{\-Verdandi} \-S\-Construct {\ttfamily dependency\-\_\-list} variable. \-Edit {\ttfamily \-S\-Construct} file from the current project directory so that it looks like this\-:

\begin{frame_python}
import os

# Put the path to Verdandi.
# Also editable from command line with option "verdandi".
verdandi_path = "MY_VERDANDI_PATH/verdandi-[version]"

dependency_list = ["MyModel.o"]

execfile(os.path.join(verdandi_path, "share/SConstruct"))
\end{frame_python}


\item \-In the same way, update the \hyperlink{namespace_verdandi}{\-Verdandi} \-S\-Construct {\ttfamily include\-\_\-path} variable.
\item \-If your model has other dependencies, add the required include paths and library paths to the {\ttfamily include\-\_\-path} and {\ttfamily library\-\_\-path} variables.
\item \-Compile your program with \-S\-Cons.


\end{enumerate}



\hypertarget{tips_options}{}\subsection{\emph{Verdandi} \-Options}\label{tips_options}
\-Here is the list of \-\emph{Verdandi} options you may define. \-To define an option {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-O\-P\-T\-I\-O\-N}, add this line to your program\-:

 \begin{frame_cpp}
#define VERDANDI_OPTION
\end{frame_cpp}


\-Defining {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-W\-I\-T\-H\-\_\-\-A\-B\-O\-R\-T} makes the program abort if a \-\emph{Verdandi} exception is raised (see explanation below in section \hyperlink{debugging_exceptions_and_debugging}{\-Exceptions and debugging} of page \hyperlink{debugging}{\-Debugging}).

\-Defining {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-I\-G\-N\-O\-R\-E\-\_\-\-M\-E\-S\-S\-A\-G\-E} skips the processing of messages sent between the objects.

\-You may define either {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-N\-S\-E} or {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-S\-P\-A\-R\-S\-E}, respectively to work with dense or sparse matrices for the error variances and the observation tangent operator. \-If none of these options is defined, the error variances and the observation operator are not stored in a matrix, and the computation is made row by row. \-The options defined with {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-N\-S\-E} are {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-T\-A\-N\-G\-E\-N\-T\-\_\-\-L\-I\-N\-E\-A\-R\-\_\-\-O\-P\-E\-R\-A\-T\-O\-R\-\_\-\-D\-E\-N\-S\-E} and {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-S\-T\-A\-T\-E\-\_\-\-E\-R\-R\-O\-R\-\_\-\-D\-E\-N\-S\-E}. \-The options defined with {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-S\-P\-A\-R\-S\-E} are {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-T\-A\-N\-G\-E\-N\-T\-\_\-\-L\-I\-N\-E\-A\-R\-\_\-\-O\-P\-E\-R\-A\-T\-O\-R\-\_\-\-S\-P\-A\-R\-S\-E}, {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-O\-B\-S\-E\-R\-V\-A\-T\-I\-O\-N\-\_\-\-E\-R\-R\-O\-R\-\_\-\-S\-P\-A\-R\-S\-E} and {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-S\-T\-A\-T\-E\-\_\-\-E\-R\-R\-O\-R\-\_\-\-S\-P\-A\-R\-S\-E}. \-If you want to mix dense and sparse structures, you may define the option of your choice for each matrix (error variances and the observation tangent operator).

\-A level of priority for the logger messages can be set by defining {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-L\-O\-G\-G\-I\-N\-G\-\_\-\-L\-E\-V\-E\-L}.\marginnote{The  documentation of the Logger is available in Section  \ref{debugging_logger}.}


\hypertarget{plugging_python}{
\section{Plugging a Python Model}
\label{plugging_python}
}


Start from the PythonModelTemplate. The complete interface of the model class is described here. With a complete interface, one can apply any data assimilation method in Verdandi. But for a given data assimilation method, not all methods are required. Use the Model requirements page, or the Python script
 {\ttfamily  bin/methods\_requirements} to know precisely which methods you will need to implement in your model.

In the model directory, copy the PythonModelTemplate and rename it to "MyModel". E.g., under Linux or MacOS, in command line:

\begin{frame_bash}
host<~/> cd verdandi/model/
host<~/> cp PythonModelTemplate.py MyModel.py
\end{frame_bash}


Rename the name of the class to MyModel.

In a first step, it is advised to write the interface for the ForwardDriver method which requires only a limited number of methods to be implemented.

Create a directory  {\ttfamily my\_model} in the example directory. Copy in  {\ttfamily my\_model} the following files: {\ttfamily example/quadratic\-\_\-model/\-S\-Construct}, {\ttfamily example/quadratic\-\_\-model/forward.\-cpp} and the configuration file {\ttfamily example/quadratic\-\_\-model/configuration/truth.\-lua}. \-E.\-g.\-:

\begin{frame_bash}
host<~/> cd verdandi/example
host<~/> mkdir -p my_model/configuration
host<~/> cp quadratic_model/{SConstruct,forward_python.cpp} my_model/
host<~/> cp quadratic_model/configuration/truth.lua my_model/configuration/
\end{frame_bash}


In the file  {\ttfamily my\_model/configuration/truth.\-lua} replace all the values in the python\_model field by the corresponding ones on your model .

\begin{frame_lua}
python_model = {

   module = "MyModel",
   directory = "my_model/model/",
   class_name = "MyModel"

}
\end{frame_lua}

Compile the program  {\ttfamily forward\_python.cpp}.

\begin{frame_bash}
host<~/> scons forward_python
\end{frame_bash}

Run the program.

\begin{frame_bash}
host<~/> ./forward_python configuration/truth.lua
\end{frame_bash}


At run time, if a method is needed in the model class, and if this method is not implemented, the program will launch an exception. For instance, if the method HasFinished is undefined, an exception will be thrown to report you this error. Then, see the contract of this method (HasFinished) and implement it. You can also have a look into the example models in {\ttfamily verdandi/model}.




\hypertarget{model_template}{
\section{Complete Interface of the Model Class}
\label{model_template}
}

The complete interface of the model class is described here. With a complete interface, one can apply any data assimilation method in Verdandi. But for a given data assimilation method, not all methods are required. Use the \hyperlink{model_requirement_page}{\-Model requirements page} to know precisely which methods you will need to implement in your model.



\subsection{\-Public \-Types}
\begin{DoxyCompactItemize}
\item
\hypertarget{class_verdandi_1_1_model_template_ad7aa99fa36b5f4057adbd2b347e742d3}{
typedef double \hyperlink{class_verdandi_1_1_model_template_ad7aa99fa36b5f4057adbd2b347e742d3}{value\-\_\-type}}
\label{class_verdandi_1_1_model_template_ad7aa99fa36b5f4057adbd2b347e742d3}

\begin{DoxyCompactList}\small\item\em \-The numerical type (e.\-g., double). \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_model_template_a051aba295b633cc6d463ad1c5f998bc3}{
typedef \-Matrix$<$ double $>$ \hyperlink{class_verdandi_1_1_model_template_a051aba295b633cc6d463ad1c5f998bc3}{state\-\_\-error\-\_\-variance}}
\label{class_verdandi_1_1_model_template_a051aba295b633cc6d463ad1c5f998bc3}

\begin{DoxyCompactList}\small\item\em \-Type of the state error variance. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_model_template_a01455126ac4fcc8b3218aad839d494bd}{
typedef \-Vector$<$ double $>$ \hyperlink{class_verdandi_1_1_model_template_a01455126ac4fcc8b3218aad839d494bd}{state\-\_\-error\-\_\-variance\-\_\-row}}
\label{class_verdandi_1_1_model_template_a01455126ac4fcc8b3218aad839d494bd}

\begin{DoxyCompactList}\small\item\em \-Type of a row of the state error variance. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_model_template_a86766eaee9b075944260fed957cf5ac4}{
typedef \-Matrix$<$ double $>$ \hyperlink{class_verdandi_1_1_model_template_a86766eaee9b075944260fed957cf5ac4}{matrix\-\_\-state\-\_\-observation}}
\label{class_verdandi_1_1_model_template_a86766eaee9b075944260fed957cf5ac4}

\begin{DoxyCompactList}\small\item\em \-Type of the state/observation crossed matrix. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_model_template_a014f883415120d5ba6655c710467a651}{
typedef \-Matrix$<$ double $>$ \hyperlink{class_verdandi_1_1_model_template_a014f883415120d5ba6655c710467a651}{tangent\-\_\-linear\-\_\-operator}}
\label{class_verdandi_1_1_model_template_a014f883415120d5ba6655c710467a651}

\begin{DoxyCompactList}\small\item\em \-Type of the tangent linear model. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_model_template_a79f36f136ce2c12e7fcb9e476af57d8c}{
typedef \-Matrix$<$ double $>$ \hyperlink{class_verdandi_1_1_model_template_a79f36f136ce2c12e7fcb9e476af57d8c}{error\-\_\-variance}}
\label{class_verdandi_1_1_model_template_a79f36f136ce2c12e7fcb9e476af57d8c}

\begin{DoxyCompactList}\small\item\em \-Type of the model error variance. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_model_template_a6bb9efb7898f067bb21780159b497ba7}{
typedef \-Vector$<$ double $>$ \hyperlink{class_verdandi_1_1_model_template_a6bb9efb7898f067bb21780159b497ba7}{state}}
\label{class_verdandi_1_1_model_template_a6bb9efb7898f067bb21780159b497ba7}

\begin{DoxyCompactList}\small\item\em \-Type of the state vector. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_model_template_ac387d42c1587d4a9c9b15682de1a5741}{
typedef \-Vector$<$ double $>$ \hyperlink{class_verdandi_1_1_model_template_ac387d42c1587d4a9c9b15682de1a5741}{uncertain\-\_\-parameter}}
\label{class_verdandi_1_1_model_template_ac387d42c1587d4a9c9b15682de1a5741}

\begin{DoxyCompactList}\small\item\em \-Type of an uncertain parameter. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection{\-Public \-Member \-Functions}
\begin{DoxyCompactItemize}
\item
\hypertarget{class_verdandi_1_1_model_template_a00cad2113808cca9aabb01186b8341da}{
\hyperlink{class_verdandi_1_1_model_template_a00cad2113808cca9aabb01186b8341da}{\-Model\-Template} ()}
\label{class_verdandi_1_1_model_template_a00cad2113808cca9aabb01186b8341da}

\begin{DoxyCompactList}\small\item\em \-Constructor. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_model_template_a45e5f8cc1b78eac465da8c8cd8e7d1f5}{
\hyperlink{class_verdandi_1_1_model_template_a45e5f8cc1b78eac465da8c8cd8e7d1f5}{$\sim$\-Model\-Template} ()}
\label{class_verdandi_1_1_model_template_a45e5f8cc1b78eac465da8c8cd8e7d1f5}

\begin{DoxyCompactList}\small\item\em \-Destructor. \end{DoxyCompactList}\item
void \hyperlink{class_verdandi_1_1_model_template_a986ea8e6681bff1219716418a351fab0}{\-Initialize} (string configuration\-\_\-file)
\begin{DoxyCompactList}\small\item\em \-Initializes the model. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_model_template_a88d02538f57aa4af33c29d5322624e24}{
void \hyperlink{class_verdandi_1_1_model_template_a88d02538f57aa4af33c29d5322624e24}{\-Initialize\-Step} ()}
\label{class_verdandi_1_1_model_template_a88d02538f57aa4af33c29d5322624e24}

\begin{DoxyCompactList}\small\item\em \-Initializes the current time step for the model. \end{DoxyCompactList}\item
void \hyperlink{class_verdandi_1_1_model_template_ae5ee9df8c20641f4cda9db782fdf6af8}{\-Forward} ()
\begin{DoxyCompactList}\small\item\em \-Advances one step forward in time. \end{DoxyCompactList}\item
void \hyperlink{class_verdandi_1_1_model_template_ae9fad4cbd97cfbe2dff2da24569997f7}{\-Backward\-Adjoint} (\hyperlink{class_verdandi_1_1_model_template_a6bb9efb7898f067bb21780159b497ba7}{state} \&observation\-\_\-term)
\begin{DoxyCompactList}\small\item\em \-Performs one step backward in adjoint model. \end{DoxyCompactList}\item
bool \hyperlink{class_verdandi_1_1_model_template_a4aa54740408c0e5ef7e6b1c8a10a4c2d}{\-Has\-Finished} () const
\begin{DoxyCompactList}\small\item\em \-Checks whether the model has finished. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_model_template_a180366edced1408d025f2fa8d8967f6c}{
void \hyperlink{class_verdandi_1_1_model_template_a180366edced1408d025f2fa8d8967f6c}{\-Finalize\-Step} ()}
\label{class_verdandi_1_1_model_template_a180366edced1408d025f2fa8d8967f6c}

\begin{DoxyCompactList}\small\item\em \-Finalizes the current time step for the model. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_model_template_aa97fa8c00583e0bc8ca7eadef3378c50}{
void \hyperlink{class_verdandi_1_1_model_template_aa97fa8c00583e0bc8ca7eadef3378c50}{\-Finalize} ()}
\label{class_verdandi_1_1_model_template_aa97fa8c00583e0bc8ca7eadef3378c50}

\begin{DoxyCompactList}\small\item\em \-Finalizes the model. \end{DoxyCompactList}\item
void \hyperlink{class_verdandi_1_1_model_template_a51ccbc28bb54012db77988d62fc3a070}{\-Apply\-Operator} (\hyperlink{class_verdandi_1_1_model_template_a6bb9efb7898f067bb21780159b497ba7}{state} \&x, bool forward=false, bool preserve\-\_\-state=true)
\begin{DoxyCompactList}\small\item\em \-Applies the model to a given vector. \end{DoxyCompactList}\item
void \hyperlink{class_verdandi_1_1_model_template_ad0dac987004be92a6b66032c82122bb8}{\-Apply\-Tangent\-Linear\-Operator} (\hyperlink{class_verdandi_1_1_model_template_a6bb9efb7898f067bb21780159b497ba7}{state} \&x)
\begin{DoxyCompactList}\small\item\em \-Applies the tangent linear model to a given vector. \end{DoxyCompactList}\item
void \hyperlink{class_verdandi_1_1_model_template_a64074bf180b5170923d31019d3987132}{\-Get\-Tangent\-Linear\-Operator} (\hyperlink{class_verdandi_1_1_model_template_a014f883415120d5ba6655c710467a651}{tangent\-\_\-linear\-\_\-operator}\&) const
\begin{DoxyCompactList}\small\item\em \-Gets the tangent linear model. \end{DoxyCompactList}\item
double \hyperlink{class_verdandi_1_1_model_template_a72c2c923640d73406675dec9898b6548}{\-Get\-Time} () const
\begin{DoxyCompactList}\small\item\em \-Returns the current time. \end{DoxyCompactList}\item
void \hyperlink{class_verdandi_1_1_model_template_a815893e2e04bc0593ec3552c9c8d59b4}{\-Set\-Time} (double time)
\begin{DoxyCompactList}\small\item\em \-Sets the time of the model to a given time. \end{DoxyCompactList}\item
int \hyperlink{class_verdandi_1_1_model_template_a44b42fdd4448173cbcb8c2b64733e534}{\-Get\-Nstate} () const
\begin{DoxyCompactList}\small\item\em \-Returns the state vector size. \end{DoxyCompactList}\item
int \hyperlink{class_verdandi_1_1_model_template_af4834669228239d8b3e6c07dc8175cce}{\-Get\-Nfull\-\_\-state} () const
\begin{DoxyCompactList}\small\item\em \-Returns the size of the full state vector. \end{DoxyCompactList}\item
\hyperlink{class_verdandi_1_1_model_template_a6bb9efb7898f067bb21780159b497ba7}{state} \& \hyperlink{class_verdandi_1_1_model_template_ae014bde61361001da52aab36d89f0048}{\-Get\-State} ()
\begin{DoxyCompactList}\small\item\em \-Provides the controlled state vector. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_model_template_a885248c5bbe5a173277a551b3f253277}{
void \hyperlink{class_verdandi_1_1_model_template_a885248c5bbe5a173277a551b3f253277}{\-State\-Updated} ()}
\label{class_verdandi_1_1_model_template_a885248c5bbe5a173277a551b3f253277}

\begin{DoxyCompactList}\small\item\em \-Performs some calculations when the update of the model state is done. \end{DoxyCompactList}\item
\hyperlink{class_verdandi_1_1_model_template_a6bb9efb7898f067bb21780159b497ba7}{state} \& \hyperlink{class_verdandi_1_1_model_template_a9335ddd8893b9d69e07b488100aee1bd}{\-Get\-Full\-State} ()
\begin{DoxyCompactList}\small\item\em \-Provides the full state vector. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_model_template_acf994c6ae52551dd1da95d6bdfcb9b01}{
void \hyperlink{class_verdandi_1_1_model_template_acf994c6ae52551dd1da95d6bdfcb9b01}{\-Full\-State\-Updated} ()}
\label{class_verdandi_1_1_model_template_acf994c6ae52551dd1da95d6bdfcb9b01}

\begin{DoxyCompactList}\small\item\em \-Performs some calculations when the update of the model state is done. \end{DoxyCompactList}\item
\hyperlink{class_verdandi_1_1_model_template_a6bb9efb7898f067bb21780159b497ba7}{state} \& \hyperlink{class_verdandi_1_1_model_template_a2d8a56a887c98f929ad2a097fcf57fd5}{\-Get\-State\-Lower\-Bound} ()
\begin{DoxyCompactList}\small\item\em \-Provides the state lower bound. \end{DoxyCompactList}\item
\hyperlink{class_verdandi_1_1_model_template_a6bb9efb7898f067bb21780159b497ba7}{state} \& \hyperlink{class_verdandi_1_1_model_template_acfb65c09590c706eba2c9c5280b4c322}{\-Get\-State\-Upper\-Bound} ()
\begin{DoxyCompactList}\small\item\em \-Provides the state upper bound. \end{DoxyCompactList}\item
void \hyperlink{class_verdandi_1_1_model_template_a8e8945fad8e7749fcdc0cc58880b0226}{\-Get\-Adjoint\-State} (\hyperlink{class_verdandi_1_1_model_template_a6bb9efb7898f067bb21780159b497ba7}{state} \&state\-\_\-adjoint)
\begin{DoxyCompactList}\small\item\em \-Returns the adjoint state vector. \end{DoxyCompactList}\item
void \hyperlink{class_verdandi_1_1_model_template_aebaaeb3454b04d913b30376904313675}{\-Set\-Adjoint\-State} (const \hyperlink{class_verdandi_1_1_model_template_a6bb9efb7898f067bb21780159b497ba7}{state} \&state\-\_\-adjoint)
\begin{DoxyCompactList}\small\item\em \-Sets the adjoint state vector. \end{DoxyCompactList}\item
int \hyperlink{class_verdandi_1_1_model_template_a9f148c07e411497f256c6e02c83156ba}{\-Get\-Nparameter} ()
\begin{DoxyCompactList}\small\item\em \-Returns the number of parameters to be perturbed. \end{DoxyCompactList}\item
\hyperlink{class_verdandi_1_1_model_template_ac387d42c1587d4a9c9b15682de1a5741}{uncertain\-\_\-parameter} \& \hyperlink{class_verdandi_1_1_model_template_a1d9ac6be99fd06a40f68927b410454f3}{\-Get\-Parameter} (int i)
\begin{DoxyCompactList}\small\item\em \-Gets the i-\/th uncertain parameter. \end{DoxyCompactList}\item
void \hyperlink{class_verdandi_1_1_model_template_a3f8b06eb70e68eec3e110a87a89ff988}{\-Set\-Parameter} (int i, \hyperlink{class_verdandi_1_1_model_template_ac387d42c1587d4a9c9b15682de1a5741}{uncertain\-\_\-parameter} parameter)
\begin{DoxyCompactList}\small\item\em \-Sets the i-\/th uncertain parameter. \end{DoxyCompactList}\item
\-Vector$<$ double $>$ \& \hyperlink{class_verdandi_1_1_model_template_a29a7935dc36751fb73685b4e74684859}{\-Get\-Parameter\-Correlation} (int i)
\begin{DoxyCompactList}\small\item\em \-Returns the correlation between the uncertain parameters. \end{DoxyCompactList}\item
string \hyperlink{class_verdandi_1_1_model_template_a06e4708e75e1d6ac65d0e13e0e7a1e2b}{\-Get\-Parameter\-P\-D\-F} (int i)
\begin{DoxyCompactList}\small\item\em \-Returns the \-P\-D\-F of the i-\/th parameter. \end{DoxyCompactList}\item
\-Matrix$<$ double, \-Symmetric, \*
\-Row\-Sym\-Packed $>$ \& \hyperlink{class_verdandi_1_1_model_template_ac83908d647612b292ef3f633bc245609}{\-Get\-Parameter\-Variance} (int i)
\begin{DoxyCompactList}\small\item\em \-Returns the covariance matrix associated with the i-\/th parameter. \end{DoxyCompactList}\item
\-Vector$<$ double $>$ \& \hyperlink{class_verdandi_1_1_model_template_a2f247a7e524aa3cacfe789b14f4603e9}{\-Get\-Parameter\-Parameter} (int i)
\begin{DoxyCompactList}\small\item\em \-Returns parameters associated with the \-P\-D\-F of some model parameter. \end{DoxyCompactList}\item
string \hyperlink{class_verdandi_1_1_model_template_a94f9838475042455debb9a72333e8780}{\-Get\-Parameter\-Option} (int i)
\begin{DoxyCompactList}\small\item\em \-Returns the perturbation option of the i-\/th parameter. \end{DoxyCompactList}\item
void \hyperlink{class_verdandi_1_1_model_template_ab8d1adf15435a3550ae4670b139a98c1}{\-Get\-State\-Error\-Variance\-Row} (int row, \hyperlink{class_verdandi_1_1_model_template_a01455126ac4fcc8b3218aad839d494bd}{state\-\_\-error\-\_\-variance\-\_\-row} \&\-P\-\_\-row)
\begin{DoxyCompactList}\small\item\em \-Computes a row of the variance of the state error. \end{DoxyCompactList}\item
\hyperlink{class_verdandi_1_1_model_template_a051aba295b633cc6d463ad1c5f998bc3}{state\-\_\-error\-\_\-variance} \& \hyperlink{class_verdandi_1_1_model_template_aba253cf4134fa5884b2d9a36dbbe42be}{\-Get\-State\-Error\-Variance} ()
\begin{DoxyCompactList}\small\item\em \-Returns the state error variance. \end{DoxyCompactList}\item
\hyperlink{class_verdandi_1_1_model_template_a79f36f136ce2c12e7fcb9e476af57d8c}{error\-\_\-variance} \& \hyperlink{class_verdandi_1_1_model_template_a2eff74bc61c0381b483e82b536618859}{\-Get\-Error\-Variance\-Sqrt} ()
\begin{DoxyCompactList}\small\item\em \-Returns the square root of the model error variance. \end{DoxyCompactList}\item
void \hyperlink{class_verdandi_1_1_model_template_a8b787fd575cf312d61aa739200ece96d}{\-Get\-State\-Error\-Variance\-Sqrt} (\hyperlink{class_verdandi_1_1_model_template_a051aba295b633cc6d463ad1c5f998bc3}{state\-\_\-error\-\_\-variance} \&\-L, \hyperlink{class_verdandi_1_1_model_template_a051aba295b633cc6d463ad1c5f998bc3}{state\-\_\-error\-\_\-variance} \&\-U)
\item
const \hyperlink{class_verdandi_1_1_model_template_a051aba295b633cc6d463ad1c5f998bc3}{state\-\_\-error\-\_\-variance} \& \hyperlink{class_verdandi_1_1_model_template_a36eadce626e1b7f6b37d27d8462a14b9}{\-Get\-State\-Error\-Variance\-Inverse} () const
\begin{DoxyCompactList}\small\item\em \-Returns the inverse of the background error variance ( $B^{-1}$). \end{DoxyCompactList}\item
string \hyperlink{class_verdandi_1_1_model_template_a1451871cba68257c573f23f5ba39083a}{\-Get\-Name} () const
\begin{DoxyCompactList}\small\item\em \-Returns the name of the class. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_model_template_a202b6841e06cae68b9739e57f5073f48}{
void \hyperlink{class_verdandi_1_1_model_template_a202b6841e06cae68b9739e57f5073f48}{\-Message} (string message)}
\label{class_verdandi_1_1_model_template_a202b6841e06cae68b9739e57f5073f48}

\begin{DoxyCompactList}\small\item\em \-Receives and handles a message. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection{\-Static \-Public \-Member \-Functions}
\begin{DoxyCompactItemize}
\item
\hypertarget{class_verdandi_1_1_verdandi_base_a6dcc96ec9661a4cbf152955adb9dc990}{
static void \hyperlink{class_verdandi_1_1_verdandi_base_a6dcc96ec9661a4cbf152955adb9dc990}{\-Static\-Message} (void $\ast$object, string message)}
\label{class_verdandi_1_1_verdandi_base_a6dcc96ec9661a4cbf152955adb9dc990}

\begin{DoxyCompactList}\small\item\em \-Receives and handles a message with a static method. \end{DoxyCompactList}\end{DoxyCompactItemize}




\hypertarget{model_requirement_page}{
\section{Methods Requirements for Models}
\label{model_requirement_page}
}



Here is listed for each assimilation method in Verdandi, the required methods to be implemented in a model. Note that each method also requires the functions
GetName and Message to be implemented, even if they are not listed here.

\subsection{EnsembleKalmanFilter}

\begin{itemize}
\item Finalize
\item FinalizeStep
\item Forward
\item FullStateUpdated
\item GetFullState
\item GetNfull\_state
\item GetNparameter
\item GetNstate
\item GetParameter
\item GetParameterCorrelation
\item GetParameterOption
\item GetParameterPDF
\item GetParameterParameter
\item GetParameterVariance
\item GetState
\item GetTime
\item HasFinished
\item Initialize
\item InitializeStep
\item SetParameter
\item SetTime
\item StateUpdated
\end{itemize}



\subsection{ExtendedKalmanFilter}

\begin{itemize}
\item ApplyTangentLinearOperator
\item Finalize
\item FinalizeStep
\item Forward
\item GetNstate
\item GetState
\item GetStateErrorVariance
\item GetStateErrorVarianceRow
\item GetTangentLinearOperator
\item GetTime
\item HasFinished
\item Initialize
\item InitializeStep
\item SetTime
\item StateUpdated
\end{itemize}

\subsection{ForwardDriver}

\begin{itemize}
\item Finalize
\item FinalizeStep
\item Forward
\item GetState
\item GetTime
\item HasFinished
\item Initialize
\item InitializeStep
\end{itemize}

\subsection{FourDimensionalVariational}

\begin{itemize}
\item AdjointStateUpdated
\item BackwardAdjoint
\item Finalize
\item FinalizeStep
\item Forward
\item GetAdjointState
\item GetNstate
\item GetState
\item GetStateErrorVariance
\item GetStateLowerBound
\item GetStateUpperBound
\item GetTime
\item HasFinished
\item Initialize
\item InitializeStep
\item SetTime
\item StateUpdated
\end{itemize}

\subsection{HamiltonJacobiBellman}

\begin{itemize}
\item ApplyOperator
\item Finalize
\item FinalizeStep
\item GetLength
\item GetNstate
\item Initialize
\item InitializeStep
\item SetTime
\end{itemize}

\subsection{MonteCarlo}

\begin{itemize}
\item Finalize
\item FinalizeStep
\item Forward
\item GetNparameter
\item GetParameter
\item GetParameterCorrelation
\item GetParameterOption
\item GetParameterPDF
\item GetParameterParameter
\item GetParameterVariance
\item GetState
\item GetTime
\item HasFinished
\item Initialize
\item InitializeStep
\item SetParameter
\end{itemize}

\subsection{ObservationGenerator}

\begin{itemize}
\item Finalize
\item FinalizeStep
\item Forward
\item GetState
\item GetTime
\item HasFinished
\item Initialize
\item InitializeStep
\end{itemize}

\subsection{OptimalInterpolation}

\begin{itemize}
\item Finalize
\item FinalizeStep
\item Forward
\item GetNstate
\item GetState
\item GetStateErrorVariance
\item GetStateErrorVarianceRow
\item GetTime
\item HasFinished
\item Initialize
\item InitializeStep
\item StateUpdated
\end{itemize}

\subsection{ReducedMinimax}

\begin{itemize}
\item ApplyOperator
\item ApplyTangentLinearOperator
\item Finalize
\item FinalizeStep
\item Forward
\item GetErrorVarianceSqrt
\item GetFullState
\item GetNstate
\item GetState
\item GetStateErrorVarianceSqrt
\item GetTime
\item HasFinished
\item Initialize
\item InitializeStep
\item SetFullState
\item SetState
\item SetTime
\end{itemize}

\subsection{ReducedOrderExtendedKalmanFilter}

\begin{itemize}
\item ApplyTangentLinearOperator
\item Finalize
\item FinalizeStep
\item Forward
\item GetNstate
\item GetState
\item GetStateErrorVarianceProjector
\item GetStateErrorVarianceReduced
\item GetTime
\item HasFinished
\item Initialize
\item InitializeStep
\item SetTime
\item StateUpdated
\end{itemize}

\subsection{ReducedOrderUnscentedKalmanFilter}

\begin{itemize}
\item ApplyOperator
\item Finalize
\item FinalizeStep
\item GetNstate
\item GetState
\item GetStateErrorVarianceProjector
\item GetStateErrorVarianceReduced
\item GetTime
\item HasFinished
\item Initialize
\item InitializeStep
\item StateUpdated
\end{itemize}

\subsection{UnscentedKalmanFilter}

\begin{itemize}
\item ApplyOperator
\item Finalize
\item FinalizeStep
\item GetNstate
\item GetState
\item GetStateErrorVariance
\item GetStateErrorVarianceRow
\item GetTime
\item HasFinished
\item Initialize
\item InitializeStep
\item StateUpdated
\end{itemize}



\hypertarget{observation_manager_template}{
\section{Complete Interface of the Observation Manager Class}
\label{observation_manager_template}
}

The complete interface of the Observation Manager class is described here. With a complete interface, one can apply any data assimilation method in Verdandi. But for a given data assimilation method, not all methods are required. Use the \hyperlink{observation_requirement_page}{\-Observation Manager requirements page} to know precisely which methods you will need to implement in your Observation Manager.


\subsection{\-Public \-Types}
\begin{DoxyCompactItemize}
\item
\hypertarget{class_verdandi_1_1_observation_manager_template_a01c360118f7c08c34de9cf1a406e4405}{
typedef \-Matrix$<$ double $>$ \hyperlink{class_verdandi_1_1_observation_manager_template_a01c360118f7c08c34de9cf1a406e4405}{tangent\-\_\-linear\-\_\-operator}}
\label{class_verdandi_1_1_observation_manager_template_a01c360118f7c08c34de9cf1a406e4405}

\begin{DoxyCompactList}\small\item\em \-Type of the tangent linear operator. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_observation_manager_template_a596a76a0e00b412f0b7cda4c7fb9d8f1}{
typedef \-Vector$<$ double $>$ \hyperlink{class_verdandi_1_1_observation_manager_template_a596a76a0e00b412f0b7cda4c7fb9d8f1}{tangent\-\_\-linear\-\_\-operator\-\_\-row}}
\label{class_verdandi_1_1_observation_manager_template_a596a76a0e00b412f0b7cda4c7fb9d8f1}

\begin{DoxyCompactList}\small\item\em \-Type of a row of the tangent linear operator. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_observation_manager_template_a6c945c41f11fb91cf83a2535b7516cc2}{
typedef \-Matrix$<$ double $>$ \hyperlink{class_verdandi_1_1_observation_manager_template_a6c945c41f11fb91cf83a2535b7516cc2}{error\-\_\-variance}}
\label{class_verdandi_1_1_observation_manager_template_a6c945c41f11fb91cf83a2535b7516cc2}

\begin{DoxyCompactList}\small\item\em \-Type of the observation error covariance matrix. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_observation_manager_template_ae5afff62ea0f6f0926e80467c6d14ec6}{
typedef \-Vector$<$ double $>$ \hyperlink{class_verdandi_1_1_observation_manager_template_ae5afff62ea0f6f0926e80467c6d14ec6}{observation}}
\label{class_verdandi_1_1_observation_manager_template_ae5afff62ea0f6f0926e80467c6d14ec6}

\begin{DoxyCompactList}\small\item\em \-Type of the observation vector. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection{\-Public \-Member \-Functions}
\begin{DoxyCompactItemize}
\item
\hypertarget{class_verdandi_1_1_observation_manager_template_a4135c9e6587ee59394027a56f3d40ea2}{
\hyperlink{class_verdandi_1_1_observation_manager_template_a4135c9e6587ee59394027a56f3d40ea2}{\-Observation\-Manager\-Template} ()}
\label{class_verdandi_1_1_observation_manager_template_a4135c9e6587ee59394027a56f3d40ea2}

\begin{DoxyCompactList}\small\item\em \-Default constructor. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_observation_manager_template_a3481d059bf1011f0705eba3db559197d}{
\hyperlink{class_verdandi_1_1_observation_manager_template_a3481d059bf1011f0705eba3db559197d}{$\sim$\-Observation\-Manager\-Template} ()}
\label{class_verdandi_1_1_observation_manager_template_a3481d059bf1011f0705eba3db559197d}

\begin{DoxyCompactList}\small\item\em \-Destructor. \end{DoxyCompactList}\item
{\footnotesize template$<$class Model $>$ }\\void \hyperlink{class_verdandi_1_1_observation_manager_template_aa3018c692c0ae146e25d87ec6297ff1f}{\-Initialize} (const \-Model \&model, string configuration\-\_\-file)
\begin{DoxyCompactList}\small\item\em \-Initializes the observation manager. \end{DoxyCompactList}\item
void \hyperlink{class_verdandi_1_1_observation_manager_template_af2305e2b0e2b70b6222e2092575e5bbe}{\-Discard\-Observation} (bool discard\-\_\-observation)
\begin{DoxyCompactList}\small\item\em \-Activates or deactivates the option 'discard\-\_\-observation'. \end{DoxyCompactList}\item
{\footnotesize template$<$class Model $>$ }\\void \hyperlink{class_verdandi_1_1_observation_manager_template_a5038bf02f0d6767d6cb726f584db461a}{\-Set\-Time} (const \-Model \&model, double time)
\begin{DoxyCompactList}\small\item\em \-Sets the time of observations to be loaded. \end{DoxyCompactList}\item
\hyperlink{class_verdandi_1_1_observation_manager_template_ae5afff62ea0f6f0926e80467c6d14ec6}{observation} \& \hyperlink{class_verdandi_1_1_observation_manager_template_a029160269b4234c4a73d678b4e9bf9d6}{\-Get\-Observation} ()
\begin{DoxyCompactList}\small\item\em \-Returns the observations. \end{DoxyCompactList}\item
{\footnotesize template$<$class state $>$ }\\\hyperlink{class_verdandi_1_1_observation_manager_template_ae5afff62ea0f6f0926e80467c6d14ec6}{observation} \& \hyperlink{class_verdandi_1_1_observation_manager_template_a81a85208bcd9f1517eb9057c7fc1a185}{\-Get\-Innovation} (const state \&x)
\begin{DoxyCompactList}\small\item\em \-Returns an innovation. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_observation_manager_template_a10b9ce979397f3fd0208a98c3eec4db0}{
bool \hyperlink{class_verdandi_1_1_observation_manager_template_a10b9ce979397f3fd0208a98c3eec4db0}{\-Has\-Observation} () const }
\label{class_verdandi_1_1_observation_manager_template_a10b9ce979397f3fd0208a98c3eec4db0}

\begin{DoxyCompactList}\small\item\em \-Indicates if some observations are available at current time. \end{DoxyCompactList}\item
bool \hyperlink{class_verdandi_1_1_observation_manager_template_a28a85c86b51e1b9e9d7de23a8b3b1a89}{\-Has\-Observation} (double time)
\begin{DoxyCompactList}\small\item\em \-Indicates if some observations are available at a given time. \end{DoxyCompactList}\item
int \hyperlink{class_verdandi_1_1_observation_manager_template_a833c18e713a3ba86504ec7ba4d7dbf23}{\-Get\-Nobservation} () const
\begin{DoxyCompactList}\small\item\em \-Returns the number of available observations. \end{DoxyCompactList}\item
{\footnotesize template$<$class state $>$ }\\void \hyperlink{class_verdandi_1_1_observation_manager_template_af74c6ac2db6ff368233646f435b8cb9a}{\-Apply\-Operator} (const state \&x, \hyperlink{class_verdandi_1_1_observation_manager_template_ae5afff62ea0f6f0926e80467c6d14ec6}{observation} \&y) const
\begin{DoxyCompactList}\small\item\em \-Applies the observation operator to a given vector. \end{DoxyCompactList}\item
{\footnotesize template$<$class state $>$ }\\void \hyperlink{class_verdandi_1_1_observation_manager_template_aa9333b527355f5995661cf4feebd5630}{\-Apply\-Tangent\-Linear\-Operator} (const state \&x, \hyperlink{class_verdandi_1_1_observation_manager_template_ae5afff62ea0f6f0926e80467c6d14ec6}{observation} \&y) const
\begin{DoxyCompactList}\small\item\em \-Applies the tangent linear operator to a given vector. \end{DoxyCompactList}\item
double \hyperlink{class_verdandi_1_1_observation_manager_template_a3c06471b6789417e55269b3e97cf624d}{\-Get\-Tangent\-Linear\-Operator} (int i, int j) const
\begin{DoxyCompactList}\small\item\em \-Returns an element of the tangent linear operator. \end{DoxyCompactList}\item
\hyperlink{class_verdandi_1_1_observation_manager_template_a596a76a0e00b412f0b7cda4c7fb9d8f1}{tangent\-\_\-linear\-\_\-operator\-\_\-row} \& \hyperlink{class_verdandi_1_1_observation_manager_template_a4e00d5879ce62a7bdfe98246a52a3578}{\-Get\-Tangent\-Linear\-Operator\-Row} (int row)
\begin{DoxyCompactList}\small\item\em \-Returns a row of the tangent linear operator. \end{DoxyCompactList}\item
const \hyperlink{class_verdandi_1_1_observation_manager_template_a01c360118f7c08c34de9cf1a406e4405}{tangent\-\_\-linear\-\_\-operator}\& \hyperlink{class_verdandi_1_1_observation_manager_template_a3f1ed2e9299c80552a5ab85bbd94a2fd}{\-Get\-Tangent\-Linear\-Operator} () const
\begin{DoxyCompactList}\small\item\em \-Returns the tangent linear operator. \end{DoxyCompactList}\item
{\footnotesize template$<$class state $>$ }\\void \hyperlink{class_verdandi_1_1_observation_manager_template_a95a25d20e85f2466e6872d64a4e701df}{\-Apply\-Adjoint\-Operator} (const state \&x, \hyperlink{class_verdandi_1_1_observation_manager_template_ae5afff62ea0f6f0926e80467c6d14ec6}{observation} \&y) const
\begin{DoxyCompactList}\small\item\em \-Applies the adjoint operator to a given vector. \end{DoxyCompactList}\item
double \hyperlink{class_verdandi_1_1_observation_manager_template_a9b12be0175cf5fdb72df2b1e15bf5af2}{\-Get\-Error\-Variance} (int i, int j) const
\begin{DoxyCompactList}\small\item\em \-Return an observation error covariance. \end{DoxyCompactList}\item
const \hyperlink{class_verdandi_1_1_observation_manager_template_a6c945c41f11fb91cf83a2535b7516cc2}{error\-\_\-variance} \& \hyperlink{class_verdandi_1_1_observation_manager_template_a2fa3d5af9aaf77b23c7d88c3cf16034a}{\-Get\-Error\-Variance} () const
\begin{DoxyCompactList}\small\item\em \-Returns the observation error variance. \end{DoxyCompactList}\item
const \hyperlink{class_verdandi_1_1_observation_manager_template_a6c945c41f11fb91cf83a2535b7516cc2}{error\-\_\-variance} \& \hyperlink{class_verdandi_1_1_observation_manager_template_a96022ffb205eea2dc4ed9c435b14d250}{\-Get\-Error\-Variance\-Inverse} () const
\begin{DoxyCompactList}\small\item\em \-Returns the inverse of the observation error covariance matrix. \end{DoxyCompactList}\item
string \hyperlink{class_verdandi_1_1_observation_manager_template_af140e2b090625126991ae3eae6ffb0e9}{\-Get\-Name} () const
\begin{DoxyCompactList}\small\item\em \-Returns the name of the class. \end{DoxyCompactList}\item
\hypertarget{class_verdandi_1_1_observation_manager_template_a93b7d2115d7166b58d6e1ba573fc5fc7}{
void \hyperlink{class_verdandi_1_1_observation_manager_template_a93b7d2115d7166b58d6e1ba573fc5fc7}{\-Message} (string message)}
\label{class_verdandi_1_1_observation_manager_template_a93b7d2115d7166b58d6e1ba573fc5fc7}

\begin{DoxyCompactList}\small\item\em \-Receives and handles a message. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection{\-Static \-Public \-Member \-Functions}
\begin{DoxyCompactItemize}
\item
\hypertarget{class_verdandi_1_1_verdandi_base_a6dcc96ec9661a4cbf152955adb9dc990}{
static void \hyperlink{class_verdandi_1_1_verdandi_base_a6dcc96ec9661a4cbf152955adb9dc990}{\-Static\-Message} (void $\ast$object, string message)}
\label{class_verdandi_1_1_verdandi_base_a6dcc96ec9661a4cbf152955adb9dc990}

\begin{DoxyCompactList}\small\item\em \-Receives and handles a message with a static method. \end{DoxyCompactList}\end{DoxyCompactItemize}



\hypertarget{observation_requirement_page}{
\section{Methods Requirements for Observation Managers}
\label{observation_requirement_page}
}



Here is listed for each assimilation method in Verdandi, the required methods to be implemented in a model. Note that each method also requires the functions
GetName and Message to be implemented, even if they are not listed here.

\subsection{EnsembleKalmanFilter}

\begin{itemize}
\item ApplyOperator
\item GetErrorVariance
\item GetObservation
\item GetTangentLinearOperator
\item HasObservation
\item Initialize
\item SetTime
\end{itemize}



\subsection{ExtendedKalmanFilter}

\begin{itemize}
\item GetErrorVariance
\item GetInnovation
\item GetNobservation
\item GetTangentLinearOperator
\item HasObservation
\item Initialize
\item SetTime
\end{itemize}

\subsection{ForwardDriver}

\begin{itemize}
\item Finalize
\item FinalizeStep
\item Forward
\item GetState
\item GetTime
\item HasFinished
\item Initialize
\item InitializeStep
\end{itemize}

\subsection{FourDimensionalVariational}

\begin{itemize}
\item DiscardObservation
\item GetErrorVarianceInverse
\item GetInnovation
\item GetNobservation
\item GetTangentLinearOperator
\item HasObservation
\item Initialize
\item SetTime
\end{itemize}

\subsection{HamiltonJacobiBellman}

\begin{itemize}
\item ApplyOperator
\item GetNobservation
\item GetObservation
\item HasObservation
\item Initialize
\item SetTime
\end{itemize}


\subsection{ObservationGenerator}

\begin{itemize}
\item ApplyOperator
\item GetNobservation
\item Initialize
\end{itemize}

\subsection{OptimalInterpolation}

\begin{itemize}
\item GetErrorVariance
\item GetInnovation
\item GetTangentLinearOperator
\item HasObservation
\item Initialize
\item SetTime
\end{itemize}

\subsection{ReducedMinimax}

\begin{itemize}
\item GetErrorVariance
\item GetObservation
\item GetTangentLinearOperator
\item HasObservation
\item Initialize
\item SetTime
\end{itemize}

\subsection{ReducedOrderExtendedKalmanFilter}

\begin{itemize}
\item GetErrorVarianceInverse
\item GetInnovation
\item GetNobservation
\item GetTangentLinearOperator
\item HasObservation
\item Initialize
\item SetTime
\end{itemize}

\subsection{ReducedOrderUnscentedKalmanFilter}

\begin{itemize}
\item DiscardObservation
\item GetErrorVariance
\item GetErrorVarianceInverse
\item GetInnovation
\item GetNobservation
\item HasObservation
\item Initialize
\item SetTime
\end{itemize}

\subsection{UnscentedKalmanFilter}

\begin{itemize}
\item ApplyOperator
\item GetErrorVariance
\item GetInnovation
\item GetNobservation
\item HasObservation
\item Initialize
\item SetTime
\end{itemize}

\hypertarget{debugging}{}\section{Debugging}\label{debugging}

\hypertarget{debugging_dumping_scons_environment}{}\subsection{\-Dumping S\-Cons Environment}\label{debugging_dumping_scons_environment}
\-If you need to access the \-S\-Cons environment variables, you may launch

\begin{frame_bash}
host<~/> scons dump_env=yes
\end{frame_bash}


\-This will create a file {\ttfamily scons\-\_\-env.\-log} that describes the entire \-S\-Cons environment.

\hypertarget{debugging_exceptions}{}\subsection{\-Exceptions}\label{debugging_exceptions}


\hypertarget{debugging_exceptions_options}{}\paragraph{\-Options}\label{debugging_exceptions_options}

\-\emph{Verdandi} is able to check for several mistakes\-:


\begin{itemize}
\item \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-C\-H\-E\-C\-K\-\_\-\-C\-O\-N\-F\-I\-G\-U\-R\-A\-T\-I\-O\-N\-: checks that there is no error in configurations.


\item \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-C\-H\-E\-C\-K\-\_\-\-I\-O\-: checks input/output operations on disk.


\item \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-C\-H\-E\-C\-K\-\_\-\-P\-R\-O\-C\-E\-S\-S\-I\-N\-G\-: checks some data processing.


\item \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-C\-H\-E\-C\-K\-\_\-\-A\-R\-G\-U\-M\-E\-N\-T\-: checks functions or methods arguments.


\item \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-C\-H\-E\-C\-K\-\_\-\-D\-I\-M\-E\-N\-S\-I\-O\-N\-S\-: checks that the dimensions of involved structures are compatible. \-Notice that there are methods in which the compatibility is not checked however.


\end{itemize}

\-Seldon is also able to check for several mistakes\-:


\begin{itemize}
\item \-S\-E\-L\-D\-O\-N\-\_\-\-C\-H\-E\-C\-K\-\_\-\-I\-O\-: checks input/output operations on disk.


\item \-S\-E\-L\-D\-O\-N\-\_\-\-C\-H\-E\-C\-K\-\_\-\-M\-E\-M\-O\-R\-Y\-: checks memory allocations and deallocations.


\item \-S\-E\-L\-D\-O\-N\-\_\-\-C\-H\-E\-C\-K\-\_\-\-D\-I\-M\-E\-N\-S\-I\-O\-N\-S\-: checks that the dimensions of involved structures are compatible. \-Notice that there are methods in which the compatibility is not checked however.


\item \-S\-E\-L\-D\-O\-N\-\_\-\-C\-H\-E\-C\-K\-\_\-\-B\-O\-U\-N\-D\-S\-: checks that indices are not out of range.


\end{itemize}

\-To enable {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-C\-H\-E\-C\-K\-\_\-\-I\-O}, for example, put

 \begin{frame_cpp}
 #define VERDANDI_CHECK_IO
 \end{frame_cpp}


\-Alternatively, there are debug levels\-:


\begin{itemize}
\item \-S\-E\-L\-D\-O\-N\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-0\-: nothing is checked.


\item \-S\-E\-L\-D\-O\-N\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-1\-: equivalent to \-S\-E\-L\-D\-O\-N\-\_\-\-C\-H\-E\-C\-K\-\_\-\-I\-O plus \-S\-E\-L\-D\-O\-N\-\_\-\-C\-H\-E\-C\-K\-\_\-\-M\-E\-M\-O\-R\-Y.


\item \-S\-E\-L\-D\-O\-N\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-2\-: equivalent to \-S\-E\-L\-D\-O\-N\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-1 plus \-S\-E\-L\-D\-O\-N\-\_\-\-C\-H\-E\-C\-K\-\_\-\-D\-I\-M\-E\-N\-S\-I\-O\-N\-S.


\item \-S\-E\-L\-D\-O\-N\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-3\-: equivalent to \-S\-E\-L\-D\-O\-N\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-2 plus \-S\-E\-L\-D\-O\-N\-\_\-\-C\-H\-E\-C\-K\-\_\-\-B\-O\-U\-N\-D\-S.


\item \-S\-E\-L\-D\-O\-N\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-4\-: equivalent to \-S\-E\-L\-D\-O\-N\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-3.


\end{itemize}


\begin{itemize}
\item \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-0\-: equivalent to \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-C\-H\-E\-C\-K\-\_\-\-C\-O\-N\-F\-I\-G\-U\-R\-A\-T\-I\-O\-N plus \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-C\-H\-E\-C\-K\-\_\-\-A\-R\-G\-U\-M\-E\-N\-T plus \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-C\-H\-E\-C\-K\-\_\-\-P\-R\-O\-C\-E\-S\-S\-I\-N\-G plus \-S\-E\-L\-D\-O\-N\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-0.


\item \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-1\-: equivalent to \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-0 plus \-S\-E\-L\-D\-O\-N\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-1 plus \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-C\-H\-E\-C\-K\-\_\-\-I\-O.


\item \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-2\-: equivalent to \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-1 plus \-S\-E\-L\-D\-O\-N\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-2 plus \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-C\-H\-E\-C\-K\-\_\-\-D\-I\-M\-E\-N\-S\-I\-O\-N\-S.


\item \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-3\-: equivalent to \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-2 plus \-S\-E\-L\-D\-O\-N\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-3.


\item \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-4\-: equivalent to \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-3 plus \-S\-E\-L\-D\-O\-N\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-4.


\end{itemize}

\-In practice, it is advocated to choose \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-4 in the development stage and \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-2 for the stable version. \-Indeed \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-4 slows down the program but checks many things and \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-D\-E\-B\-U\-G\-\_\-\-L\-E\-V\-E\-L\-\_\-2 should not slow down the program and ensures that it is reasonably safe.

\-Development stage\-:
\begin{frame_cpp}
#define VERDANDI_DEBUG_LEVEL_4
\end{frame_cpp}


\-Stable version\-:
\begin{frame_cpp}
#define VERDANDI_DEBUG_LEVEL_2
\end{frame_cpp}

 \hypertarget{debugging_exceptions_raised}{}\paragraph{\-Exceptions raised}\label{debugging_exceptions_raised}

\-The objects that may be launched by \-\emph{Verdandi} are of type\-: {\ttfamily  \hyperlink{class_verdandi_1_1_error_configuration}{\-Error\-Configuration}}, {\ttfamily  \hyperlink{class_verdandi_1_1_error_i_o}{\-Error\-I\-O}}, {\ttfamily  \hyperlink{class_verdandi_1_1_error_processing}{\-Error\-Processing}}, {\ttfamily  \hyperlink{class_verdandi_1_1_error_undefined}{\-Error\-Undefined}}, {\ttfamily  \hyperlink{class_verdandi_1_1_error_argument}{\-Error\-Argument}}. \-They all derive from {\ttfamily  \hyperlink{class_verdandi_1_1_error}{\-Error}}. \-They provide the method {\ttfamily  \hyperlink{class_verdandi_1_1_error_aa47cac6050d224b364a6105787ff46a2}{\-What()}} that returns a string explaining the error, and the method {\ttfamily  \hyperlink{class_verdandi_1_1_error_a8febb68b76e72696a384690ec9bfeb17}{\-Cout\-What()}} that displays on screen this explanation.

\hypertarget{debugging_exceptions_and_debugging}{}\paragraph{\-Exceptions and debugging}\label{debugging_exceptions_and_debugging}

\-Suppose your code contains an error and raises an exception. \-You probably want to identify the function that raised the exception. \-The error message should contain the name of the function. \-But you probably want to know the exact line where the error occurred and the sequence of calls. \-Then, you have two options, using a debugger.

\-One option is to place a breakpoint in {\ttfamily  \hyperlink{class_verdandi_1_1_error_aa424e0d7f1462881ca27f07ed9fa32a1}{\-Error\-::\-Error(string function = \char`\"{}\char`\"{}, string comment = \char`\"{}\char`\"{})}} (see file {\ttfamily \hyperlink{_error_8cxx_source}{share/\-Error.\-cxx}}) because this constructor should be called before the exception is actually raised.

\-Another option, more convenient because no breakpoint is to be placed, is to define {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-W\-I\-T\-H\-\_\-\-A\-B\-O\-R\-T}. \-With that flag activated, if a \-\emph{Verdandi} exception is raised, the program will simply abort. \-The call stack is then at hand.

\hypertarget{debugging_logger}{}\subsection{\-Logger}\label{debugging_logger}

\-\emph{Verdandi} offers the ability to write messages in a log file or in the standard output thanks to its static class {\ttfamily  \hyperlink{class_verdandi_1_1_logger}{\-Verdandi\-::\-Logger}}.

\hypertarget{debugging_logger_status}{}\paragraph{\-Logger status}\label{debugging_logger_status}


\-It is possible to change the logger status using the methods {\ttfamily  \hyperlink{class_verdandi_1_1_logger_a57ddb9e9bed114d33772f77f836f32de}{\-Verdandi\-::\-Logger\-::\-Activate()}} and {\ttfamily  \hyperlink{class_verdandi_1_1_logger_afbc87f7ddfd7a8ca1fd538877aaaaac7}{\-Verdandi\-::\-Logger\-::\-Deactivate()}}. \-These methods enable to activate or deactivate the logger.

{\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-L\-O\-G\-\_\-\-I\-S\-\_\-\-A\-C\-T\-I\-V\-E} specifies the logger status (active by default).

\-To deactivate the logger, put

 \begin{frame_cpp}
#define VERDANDI_LOG_IS_ACTIVE false
\end{frame_cpp}

 \hypertarget{debugging_logger_file_name}{}\paragraph{\-Logger file name}\label{debugging_logger_file_name}


{\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-L\-O\-G\-\_\-\-F\-I\-L\-E\-N\-A\-M\-E} defines the name of the log file ({\ttfamily verdandi.\-log} by default).

\-To change the log file name, for example, put

 \begin{frame_cpp}
#define VERDANDI_LOG_FILENAME "verdandi-%{D}.log"
\end{frame_cpp}


\-The special character {\ttfamily \%\{\-D\}} will be replaced by the current date.

\-It is also possible to define the log file in a configuration file, if the method \hyperlink{class_verdandi_1_1_logger_a52a592e84c95a69e8bd0d7d882ff0f2f}{\-Verdandi\-::\-Logger\-::\-Initialize(string file\-\_\-name, string section\-\_\-name)} is called. \-For instance\-:

 \begin{frame_cpp}
Logger::Initialize("configuration.cfg", "logger/");
\end{frame_cpp}


\-Then, in order to set the path of the log file, you have to define or to change the variable {\ttfamily \-File} in the section {\ttfamily logger} of the configuration file {\ttfamily configuration.\-cfg}.

\hypertarget{debugging_logger_methods}{}\paragraph{\-Two methods}\label{debugging_logger_methods}


\-The logger mainly comes with the methods {\ttfamily  \hyperlink{class_verdandi_1_1_logger_ab49f0d118882a7e67bb2e58239b5fafd}{\-Verdandi\-::\-Logger\-::\-Log()}} and {\ttfamily  \hyperlink{class_verdandi_1_1_logger_ad8110c7a55f37213bffae10a39f65035}{\-Verdandi\-::\-Logger\-::\-Std\-Out()}}.

{\ttfamily  \hyperlink{class_verdandi_1_1_logger_ab49f0d118882a7e67bb2e58239b5fafd}{\-Verdandi\-::\-Logger\-::\-Log()}} writes the messages in the log file, and also on the standard output when the messages are important enough. {\ttfamily  \hyperlink{class_verdandi_1_1_logger_ad8110c7a55f37213bffae10a39f65035}{\-Verdandi\-::\-Logger\-::\-Std\-Out()}} writes the messages on the standard output, and in the log file too (unless configured otherwise).

\hypertarget{debugging_logger_options}{}\paragraph{\-Logger options}\label{debugging_logger_options}

\-It is possible to tune where and how the messages are actually written\-:
\begin{itemize}
\item \-Usually, one wants the messages to appear in the log file. \-It is however possible to deactivate this with the method {\ttfamily  \hyperlink{class_verdandi_1_1_logger_aadc9abee03cd90b049b625a8eda28367}{\-Verdandi\-::\-Logger\-::\-Set\-File(bool)}}. \-After the call {\ttfamily \-Logger\-::\-Set\-File(false)}, the logger will not write the messages to the log file.


\item {\ttfamily  \hyperlink{class_verdandi_1_1_logger_ad8110c7a55f37213bffae10a39f65035}{\-Verdandi\-::\-Logger\-::\-Std\-Out()}} will always print its messages on the standard output. \-In the default setting, {\ttfamily  \hyperlink{class_verdandi_1_1_logger_ab49f0d118882a7e67bb2e58239b5fafd}{\-Verdandi\-::\-Logger\-::\-Log()}} will write the important messages on the standard output (see below the subsection about priorities). \-If you want that {\ttfamily  \hyperlink{class_verdandi_1_1_logger_ab49f0d118882a7e67bb2e58239b5fafd}{\-Verdandi\-::\-Logger\-::\-Log()}} writes all messages on the standard output, use {\ttfamily  \hyperlink{class_verdandi_1_1_logger_aacc96eb406473ecc22e42c7f541f67c9}{\-Verdandi\-::\-Logger\-::\-Set\-Stdout(bool)}}.


\item \-The method {\ttfamily  \hyperlink{class_verdandi_1_1_logger_a26c0a873e610b7053c6f73db0bf3a03f}{\-Verdandi\-::\-Logger\-::\-Set\-Uppercase(bool)}} determines whether the messages will be written in uppercase or not. \-The default behavior is not to write the log messages in uppercase.
\end{itemize}

\-Instead of calling the three previous methods, it is possible to set up the corresponding options with {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-L\-O\-G\-\_\-\-O\-P\-T\-I\-O\-N\-S}. \-These options are encoded using the constants called {\ttfamily \hyperlink{class_verdandi_1_1_logger_afd551de4b9597d95a0d8c66f6773caf3}{\-Verdandi\-::\-Logger\-::file\-\_\-}}, {\ttfamily \hyperlink{class_verdandi_1_1_logger_a1f0c578e791f7a11f3b99192bfa237d3}{\-Verdandi\-::\-Logger\-::stdout\-\_\-}} and {\ttfamily \-Verdandi\-::\-Logger\-::upper\-\_\-case\-\_\-}. \-The default value of {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-L\-O\-G\-\_\-\-O\-P\-T\-I\-O\-N\-S} is
\begin{frame_cpp}
#define VERDANDI_LOG_OPTIONS Verdandi::Logger::file_
\end{frame_cpp}


\-If you want to deactivate the log file, and activate the two other options (standard output and uppercase), then put the following definition before {\ttfamily \#include $<$\hyperlink{_verdandi_8hxx_source}{\-Verdandi.\-hxx}$>$}\-:

 \begin{frame_cpp}
#define VERDANDI_LOG_OPTIONS Verdandi::Logger::stdout_ | Verdandi::Logger::upper_case_
\end{frame_cpp}

 \hypertarget{debugging_formatting_messages}{}\paragraph{\-Formatting message}\label{debugging_formatting_messages}

{\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-L\-O\-G\-\_\-\-W\-I\-D\-T\-H} defines the number of characters per line (78 by default).

\hypertarget{debugging_level_of_priority}{}\paragraph{\-Level of priority}\label{debugging_level_of_priority}
\-A level of priority may be associated to each call of {\ttfamily  \hyperlink{class_verdandi_1_1_logger_ab49f0d118882a7e67bb2e58239b5fafd}{\-Verdandi\-::\-Logger\-::\-Log()}} using a template parameter. \-Only messages whose priority levels are greater than or equal to the level of verbosity are actually written.

{\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-L\-O\-G\-G\-I\-N\-G\-\_\-\-L\-E\-V\-E\-L} defines the level of verbosity (0 by default).

{\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-E\-X\-C\-E\-P\-T\-I\-O\-N\-\_\-\-L\-O\-G\-G\-I\-N\-G\-\_\-\-L\-E\-V\-E\-L} defines the priority level for exception messages (15 by default).

\-When a message is written on the standard output, it is also written in the log file if {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-S\-T\-D\-O\-U\-T\-\_\-\-L\-O\-G\-G\-I\-N\-G\-\_\-\-L\-E\-V\-E\-L} is greater than or equal to the logging level. \-In the default setting, this is the case since {\ttfamily \-V\-E\-R\-D\-A\-N\-D\-I\-\_\-\-S\-T\-D\-O\-U\-T\-\_\-\-L\-O\-G\-G\-I\-N\-G\-\_\-\-L\-E\-V\-E\-L} is set to 7.

\hypertarget{debugging_example}{}\paragraph{\-Example}\label{debugging_example}

\-Here is an example program:


\begin{frame_cpp}
#define VERDANDI_LOG_IS_ACTIVE false
#define VERDANDI_LOG_FILENAME "verdandi-%{D}.log"

#include "Verdandi.hxx"

using namespace Verdandi;

#include "Logger.cxx"


class ClassTest
{
public:

    string GetName() const
    {
        return "ClassTest";
    }


    void MemberFunction()
    {
        Logger::Log(*this, "ok");
    }
};


int main(int argc, char** argv)
{
    TRY;

    Logger::Log<5>("TEST 1", "ok");

    Logger::Activate();

    Logger::Log<5>("TEST 2", "ok");

    Logger::SetOption(Logger::stdout_ | Logger::file_, true);

    Logger::Log<5>("TEST 3", "ok");

    Logger::Log<-5>("TEST 4", "ok");

    Logger::Command("hline", "-", Logger::file_);

    Logger::InitializeOptions();

    ClassTest test;
    test.MemberFunction();

    END;

    return 0;
}
\end{frame_cpp}



\chapter{Parallelism in Verdandi}


Verdandi provides two level of parallelization: some data assimilation methods can instantiate several models in parallel, each of this model's instance could be itself parallelized. The data assimilation methods are parallelized by MPI and only models parallelized by MPI are yet supported. MPI has been chosen for its portability and its performance capabilities in both shared-memory multiprocessors (massively parallel machines) and distributed-memory multiprocessors (heterogeneous cluster).



\hypertarget{par-seq}{}\section{Parallel Method applied to Sequential Model}\label{par-seq}


This section describes the parallel data assimilation methods that can be applied to sequential models. The Section \ref{par-seq-algo} introduced the parallelization of the algorithms 'ReducedOrderExtendedKalmanFilter' \cite{Nerger-Thesis} and 'ReducedOrderUnscentedKalmanFilter'. The Section \ref{par-seq-example} explains  the use of these data assimilation methods applied to the sequential example model 'ClampedBar'. The performance of these algorithms are presented in Section \ref{par-seq-performance}.



\hypertarget{par-seq-algo}{}\subsection{Parallel Algorithms}\label{par-seq-algo}


\hypertarget{par-seq-algo-roekf}{}\paragraph{Parallelization of the 'ReducedOrderExtendedKalmanFilter'}\label{par-seq-algo-roekf}


\par \textcolor{red}{Algorithm}\\


\begin{DoxyEnumerate}
\item \-Prediction\-:
\begin{DoxyItemize}
\item $ x_{h+1}^f = \mathcal{M}_{h}(x_{h}^{a})$\par

\end{DoxyItemize}
\item \-Update\-:
\begin{DoxyItemize}
\item $ L_{h+1} = M_{h}L_h$\par

\item $ U_{h+1} = U_h + (H_{h+1}L_{h+1})^T R_{h+1}^{-1} H_{h+1}L_{h+1}$\par

\item $ x_{h+1}^a = x_{h+1}^f + L_{h+1}U_{h+1}^{-1}(H_{h+1}L_{h+1})^T R_{h+1}^{-1} (y_{h+1}-H_{h+1}x_{h+1}^f)$\par

\end{DoxyItemize}
\end{DoxyEnumerate}\-With\-: \par
 $x_h^f$ forecast state vector; \par
 $x_h^a$ analysis state vector; \par
 $y_h$ observation vector; \par
 $\mathcal{H}_h$ observation operator that maps the state space to the observation space; \par
 $H_h$ observation operator linearized at $x^f_h$; \par
 $Q_h$ model error covariance matrix; \par
 $R_h$ observational error covariance matrix; \par
 $\mathcal{M}_h$ model.\par



 \par \textcolor{red}{Parallelization of the $L$ computation}\\


We describe, in this part, the parallelization of the sensitivity matrix update:\\
 $ L_{h+1} = M_{h}L_h$\\

 During a simulation, every process used has its own instance of model. The columns of the matrix $L$ are distributed in equal amounts to all the processes (see Figure \ref{l_distribution}). The tangent model is applied in parallel on each column of the local sub matrix $L_p$.
 \marginnote{$L_p$ is the sub-matrix of $L$ available on the process of rank $p$.}

   \begin{figure}[htpb]
    \includegraphics[width=0.8\textwidth]{image/p91.pdf}
    \label{l_distribution}
    \caption{Distribution of the matrix $L$ into local sub-matrices $L_p$}
  \end{figure}

  \par \textcolor{red}{Parallelization of the $U$ computation}\\

  We focus in this part on the computation of the reduced covariance matrix $U$:\\
 $ U_{h+1} = U_h +  (H_{h+1}L_{h+1})^T R_{h+1}^{-1} H_{h+1}L_{h+1}$\\


  \begin{itemize}

\item The tangent observation operator is applied in parallel on each column of the local sub matrix $L_p$ (see Figure \ref{matrix_1}). The resulted matrix $HL_p$ is a sub-matrix of $HL$. The columns of $HL_p$ correspond to the same column indices as those available of matrix $HL_p$.

\begin{figure}[htpb]
        \includegraphics[width=0.6\textwidth]{image/p92.pdf}
        \caption{Matrix-matrix product type 1}
        \label{matrix_1}
\end{figure}


\item Each process sends its local sub-matrix $HL_p$ to all others (allgather operation). Thus, each process owns the entire matrix  $HL$.\\

\item Each process computes the sub-matrix  $(R_{h+1}^{-1} H_{h+1}L_{h+1})_p$ of  $R_{h+1}^{-1} H_{h+1}L_{h+1}$ :\\
$(R_{h+1}^{-1} H_{h+1}L_{h+1})_p = R_{h+1}^{-1} (H_{h+1}L_{h+1})_p$ (see Figure \ref{matrix_1})

\item Each process computes the sub-matrix   $(U_{h+1})_p$  of  the reduced covariance matrix $U_{h+1}$:\\
 $ (U_{h+1})_p = (U_h)_p +  (H_{h+1}L_{h+1})^T (R_{h+1}^{-1} H_{h+1}L_{h+1})_p$ (see Figure \ref{matrix_1})

 \item Each process sends its local sub-matrix  $ (U_{h+1})_p$ to all others (allgather operation). Thus, each process owns the entire matrix  $U_{h+1}$.\\

\end{itemize}



\par \textcolor{red}{Parallelization of the $x^a$ computation}\\

Below is explained the update of the model state vector:\\
$ x_{h+1}^a = x_{h+1}^f + L_{h+1}U_{h+1}^{-1}(H_{h+1}L_{h+1})^T R_{h+1}^{-1} (y_{h+1}-H_{h+1}x_{h+1}^f)$\\


 \begin{itemize}
  \item Each process computes the innovation: $z = (y_{h+1}-H_{h+1}x_{h+1}^f)$.

  \item  The computation $d_p = (R_{h+1}^{-1}H_{h+1}L_{h+1})_p^Tz$  is performed in parallel by each process. Only $k_p$ rows of matrix  $(R^{-1}HL)^T$  are available locally (transpose of a matrix distributed by column). The innovation vector $z$ is fully allocated on each process. Consequently, each process is able to compute locally the $k_p$ elements of the vector $d$ whose indices correspond to those of the row of $(R^{-1}HL)^T$ available locally  (see \ref{matrix_2}).

  \item Each process sends its local sub-vector  $d_p$ to all others (allgather operation). Thus, each process owns the entire vector  $d$.\\

    \begin{figure}[htpb]
        \includegraphics[width=0.6\textwidth]{image/p93.pdf}
        \caption{Matrix-matrix product type 2}
        \label{matrix_2}
      \end{figure}

 \item The system  $U_{h+1}c = d$ is solved by each process.

  \item Each process computes computes the local contribution $\Delta x_p = (L_{h+1})_p c$ :\\
  Only $k_p$ columns of matrix $L_{h+1}$ and $k_p$ rows of vector $c$ are available locally. The product $\Delta x_p = (L_{h+1})_p c$ is a vector of the same size of $x^a$ which elements represent a partial sum of the product $L_{h+1} c$ (see Figure \ref{matrix_3}). Thus, to obtain the product  $L_{h+1} c$, the contribution of all the processes have to be summed (all reduce operation).

     \begin{figure}[htpb]
        \includegraphics[width=0.6\textwidth]{image/p94.pdf}
        \caption{Matrix-matrix product type 3}
        \label{matrix_3}
\end{figure}



  \end{itemize}


\hypertarget{par-seq-algo-roukf}{}\paragraph{Parallelization of the 'ReducedOrderUnscentedKalmanFilter'}\label{par-seq-algo-roukf}

  \par \textcolor{red}{Algorithm}\\


  \begin{DoxyEnumerate}
\item \-Sampling\-:
\begin{DoxyItemize}
\item $ C_{h} = \sqrt{U_h^{-1}} $\par

\item $ x_{h}^{(i)a} = x_h^a + L_hC_hI^{(i)} \textrm{, } \quad 1\leq i \leq p+1 $\par

\end{DoxyItemize}
\item \-Prediction\-:
\begin{DoxyItemize}
\item $ x_{h+1}^f = E_\alpha(\mathcal{M}_{h}(x_{h+1}^{(*)a})) $\par

\item $ x_{h+1}^{(i)f} = x_{h+1}^f + [\mathcal{M}_{h}(x_{h}^{*a}) - x_{h+1}^f]D_{\alpha}^{1/2} \Upsilon_p I^(i), \textrm{ resampling with SVD} $\par

\item $ L_{h+1} = [x_{h+1}^{(*)f}]D_\alpha [V^*]^T \in \mathcal{M}_{n,p} $\par

\item $ P_{h+1}^f = L_{h+1} (P_{\alpha}^V)^{-1} L_{h+1}^T $
\end{DoxyItemize}
\item \-Update\-:
\begin{DoxyItemize}
\item $ [\tilde{y}] = [\mathcal{H}_{h+1}(x_{h+1}^{(*)f}) - E_\alpha(\mathcal{H}_{h+1}(x_{h+1}^{(*)f})) ]$\par

\item $ D_m = [\tilde{y}]^T R_{h+1}^{-1}[\tilde{y}] \in \mathcal{M}_r $\par

\item $ U_{h+1} = P_{\alpha}^V + [V^*] D_\alpha \bigl(1 + D_m(D_\alpha - D_V)\bigr)^{-1} D_m D_\alpha [V^*]^T \in \mathcal{M}_{p} $\par

\item $ \{HL\}_{h+1} = [\tilde{y}]( 1 + D_\alpha D_m)^{-1}\Bigl(1 + D_V \bigl( 1+D_m (D_\alpha-D_V) \bigr)^{-1} D_m \Bigr) D_\alpha[V^*]^T $\par

\item $ x_{h+1}^a = x_{h+1}^f + L_{h+1}U_{h+1}^{-1}\{HL\}_{h+1}^T R_{h+1}^{-1} (y_{h+1}-E_\alpha(y_{h+1}^{(*)}))$\par

\item $ P_{h+1}^a = L_{h+1} U_{h+1}^{-1} L_{h+1}^T$
\end{DoxyItemize}
\end{DoxyEnumerate}\-With\-: \par
 $x_h^f$ forecast state vector; \par
 $x_h^a$ analysis state vector; \par
 $y_h$ observation vector; \par
 $\mathcal{H}_h$ observation operator that maps the state space to the observation space; \par
 $H_h$ observation operator linearized at $x^f_h$; \par
 $P^f_h$ error covariance matrix of $x_h^f$; \par
 $P^a_h$ error covariance matrix of $x_h^a$; \par
 $R_h$ observational error covariance matrix; \par
 $\mathcal{M}_h$ model.



 \begin{itemize}
  \item  The particles  $x_{h}^{(i)a}$ are distibuted over the processes.
  \item Each process executes the sequential ROUKF algorithm with its local particles.
  \item The matrices $x_{h+1}$, $L_{h+1}$, $(HL)_{h+1}$ et $U_{h+1}$ are updated with the different parallel matrix-matrix products presented in Section \ref{par-seq-algo-roekf}.
  \end{itemize}


\hypertarget{par-seq-example}{}\subsection{Example Programs}\label{par-seq-example}


The examples are located in the {\ttfamily example/clamped\_bar} directory.\marginnote{To have a summary of \emph{Verdandi} contents see Section \ref{overview}.}


\hypertarget{par-seq-example-compilation}{}\paragraph{Compilation}\label{par-seq-example-compilation}

First of all, the preprocessor variable $ VERDANDI\_WITH\_MPI $ has to be defined in files  \textbf{reduced\_order\_extended\_kalman\_filter.cpp} and \textbf{reduced\_order\_unscented\_kalman\_filter.cpp}:

\begin{frame_cpp}
#define VERDANDI_DEBUG_LEVEL_4
#define SELDON_WITH_BLAS
#define SELDON_WITH_LAPACK

#define VERDANDI_WITH_ABORT
#define VERDANDI_DENSE

#define VERDANDI_WITH_MPI

#if defined(VERDANDI_WITH_MPI)
#include <mpi.h>
#endif


#include "Verdandi.hxx"
#include "seldon/SeldonSolver.hxx"

#include "model/ClampedBar.cxx"
#include "observation_manager/LinearObservationManager.cxx"
#include "method/ReducedOrderUnscentedKalmanFilter.cxx"


int main(int argc, char** argv)
{

    VERDANDI_TRY;

    ...
}
\end{frame_cpp}

Then, compile the program \textbf{generate\_observation.cpp}:


\begin{frame_bash}
$ scons generate_observation
\end{frame_bash}

Finally, compile the programs \textbf{reduced\_order\_extended\_kalman\_filter.cpp} and \textbf{reduced\_order\_unscented\_kalman\_filter.cpp}  with the option 'mpi=yes':
\begin{frame_bash}
$ scons reduced_order_extended_kalman_filter mpi=yes
$ scons reduced_order_unscented_kalman_filter mpi=yes
\end{frame_bash}



\hypertarget{par-seq-example-observation}{}\paragraph{Observation}\label{par-seq-example-observation}

\-Since no observations are given yet, we have to generate some. \-Execute the following command\-:
\begin{frame_bash}
host<~/> ./generate_observation configuration/truth.lua
\end{frame_bash}
  to run the model with the initial conditions described in {\ttfamily truth.\-lua}, without data assimilation. \-This should generate a result file ({\ttfamily truth-\/state\-\_\-forecast.\-bin}) in the directory {\ttfamily example/clamped\-\_\-bar/result/}. \-This file store the state (displacement, velocity, $ \theta_{f} $) trajectory.

\-The generated state (displacement, velocity, $ \theta_{f} $) will serve as observations for the assimilation.



\hypertarget{par-seq-example-dam}{}\paragraph{Data Assimilation with ROEKF and ROUKF}\label{par-seq-example-dam}


\-To use the \hyperlink{reduced_order_extended_kalman_filter}{\-Reduced \-Order \-Extended \-Kalman \-Filter} and the \hyperlink{reduced_order_unscented_kalman_filter}{\-Reduced \-Order \-Unscented \-Kalman \-Filter} methods, execute the following commands.
\begin{frame_bash}
$ mpirun -n 2 reduced_order_extended_kalman_filter configuration/assimilation.lua
$ mpirun -n 2 reduced_order_unscented_kalman_filter configuration/assimilation.lua
\end{frame_bash}
  \-This runs the model with the initial conditions described in {\ttfamily example/clamped\-\_\-bar/configuration/assimilation.\-lua}. \-The simulation begins with erroneous values for the parameter $ \theta_f $. \-This should generate the same results as for the sequential simulation.\\


  \textbf{Warning:}  The number of processes should be less than or equal to the size of the reduced model state vector.



\hypertarget{par-seq-performance}{}\subsection{Performance}\label{par-seq-performance}

The figures \ref{titre2} and \ref{titre3} introduce the resulting performance of the ROEKF and ROUKF algorithms applied to the sequential model ClampedBar. These simulations were performed on 2 x 3 GHz Quad-Core Intel Xeon with a 16 GB of memory in which the processes used during simulation were placed at arbitrary cores relative to the process constructing the network.

\begin{figure}
    \caption{\label{titre2} Speed up of the parallel ROEKF algorithm applied to the sequential model ClampedBar with $N_{state} = 10^4$, $N_{observation} = 10^2$ and $N_{sigma\_point} = 16$.}

 \includegraphics{image/speed_up_roekf.pdf}

   \end{figure}



 \begin{figure}
  \caption{\label{titre3} Speed up of the parallel ROUKF algorithm applied to the sequential model ClampedBar with $N_{state} = 10^4$, $N_{observation} = 10^2$ and $N_{sigma\_point} = 16$.}

\includegraphics{image/speed_up_roukf.pdf}

\end{figure}


\newpage


\hypertarget{seq-par}{}\section{Sequential Method applied to Parallel Model}\label{seq-par}

Verdandi intends to provide the ability to apply its data assimilation methods to models whose state vector is distributed on several processes. In the case of large scale state vector, neither the model nor the data assimilation method can afford to allocate a variable of this size. Consequently, several data assimilation variables
could be distributed, for instance the sensitivity matrix and the variance. The number of components to be stored locally has to be compatible with the distributed model state vector for parallel matrix-vector operations.

The management of the types in Verdandi, detailed in Section \ref{seq-par-type}, enabled to implement this capability easily. The chosen solution was to create an interface between Seldon, the linear algebra library used in Verdandi, and PETSc a framework for parallel computing. This choice do not confine the type of the model state vector only to PETSc distributed structures since any MPI distributed structures can be encapsulated or copied in a PETSc object.


\hypertarget{seq-par-type}{}\subsection{Types Management in Verdandi}\label{seq-par-type}


The implementation of the Verdandi algorithms relies on the linear algebra library Seldon. This library provides different matrix and vector structures, and many functions for computations (linear algebra). It provides matrices for two main categories: dense matrices and sparse matrices. Among dense matrices, there are specific structures for rectangular matrices, symmetric matrices, hermitian matrices and triangular matrices. Each type includes several formats: rectangular dense matrices may be stored by rows or by columns; symmetric dense matrices may be stored as rectangular matrices or only upper part of the matrix is stored. Many different types
for sparse matrix are also available. All  of these matrix classes share the same interface. Linear algebra computation functions are template functions and many BLAS operations bringing into play different matrix types are implemented.


Example program which computes the product of a dense matrix by a sparse matrix:


\begin{frame_cpp}
// Dense  matrix.
Matrix<double, General, RowMajor> A(3, 3), C(3, 3);
A.Fill();
C.Fill();
// Sparse matrix.
Matrix<double, General, ArrayRowSparse> B(3, 3);
B(0, 0) = 2.0;
B(1, 0) = 1.0;
// Computes matrix-matrix product alpha*A*B + beta*C -> C.
// This function is overloaded for all types of matrices.
MltAdd(1.0, A, B, 2.0, C);
\end{frame_cpp}


In Verdandi, the model and the observation manager can provide their vector and matrix types to the data assimilation method thanks to the C++ 'typedef' mechanism. For instance :


\begin{frame_cpp}
class Model
{
    public:
        //! Type of the state error variance.
        typedef Matrix<double, General, RowSparse> state_error_variance;
        /*! \brief Type of the reduced matrix \f$U\f$ in the \f$LUL^T\f$
        decomposition of the state error variance. */
        typedef Matrix<double, General, RowMajor> state_error_variance_reduced;
        //! Type of the state vector.
        typedef Vector<double> state;
	...
}
\end{frame_cpp}


\begin{frame_cpp}
class ObservationManager
{
    public:
        //! Type of the tangent linear operator.
        typedef Matrix<double, General, RowSparse> tangent_linear_operator;
        //! Type of the observation vector.
        typedef Vector<double> observation;
	...
}
\end{frame_cpp}


Thus, the data assimilation method is able to get back the type of the object to instantiate. For instance, to fetch the type of the model state vector:

\begin{frame_cpp}
template <class Model, class ObservationManager>
class DataAssimilationMethod
{
...
        //! Type of the model state vector.
        typedef typename Model::state model_state;
...
}
\end{frame_cpp}



\hypertarget{seq-par-ds}{}\subsection{Distributed Structure in Seldon}\label{seq-par-ds}


To ensure the compatibility of the Verdandi data assimilation methods with distributed models,  it was sufficient to:

\begin{itemize}

\item add vector and matrix distributed structures to Seldon.

\item implement the linear algebra computation functions for these new types, required by the concerned data assimilation methods.

\end{itemize}

\hypertarget{seq-par-ds-vector}{}\paragraph{Distributed Vector}\label{seq-par-ds-vector}


The class Seldon$::$Vector$<$double, PETScPar$>$  encapsulate a distributed PETSc vector of type \textbf{VecMPI} . This class implement the same interface as a classic Seldon vector. The whole set of BLAS1 operations have been implemented for this type.

The source files of the class Seldon$::$Vector$<$double, PETScPar$>$  are located in the seldon/vector/ directory. Several methods are specific of  Seldon$::$Vector$<$double, PETScPar$>$ class:

\begin{frame_cpp}
template <class T, class Allocator>
class Vector<T, PETScPar, Allocator>: public PETScVector<T, Allocator>
{
	...

    // Returns a reference on the inner petsc vector.
    Vec& GetPetscVector();

    // Returns a const reference on the inner petsc vector.
    const Vec& GetPetscVector() const;

    // Sets the MPI communicator.
    void SetCommunicator(MPI_Comm mpi_communicator);

    // Inserts or adds values into certain locations of a vector.
    // \warning These values may be cached, so 'Flush' must be called after
    // all calls to SetBuffer() have been completed.
    void SetBuffer(int i, T value, InsertMode insert_mode = INSERT_VALUES);

    // Assembles the PETSc vector.
    void Flush();

    // Returns the range of indices owned by this processor.
    // The vectors are laid out with the first \f$n_1\f$ elements on the first
    // processor, next \f$n_2\f$ elements on the second, etc. If the current
    // processor is \f$k\f$, this method returns \f$n_k\f$ in \a i and
    // \f$n_{k+1}\f$ in \a j. If \a i is set to PETSC_NULL on entry, it is not
    // modified by this function. Same is true for \a j.
    void GetProcessorRange(int& i, int& j) const;

    ...
}
\end{frame_cpp}


\par These specific methods may be necessary during the construction of a distributed vector. These methods are never called by data assimilation methods which delegate the distributed variable initializations to models and observation managers.


\textbf{Distributed PETSc vector example program}


\begin{frame_cpp}

    Vec x, y;

    int N = 10;

    ierr = VecCreateMPI(PETSC_COMM_WOLRD, N, &x); CHKERRQ(ierr);
    ierr = VecCreateMPI(PETSC_COMM_WOLRD, N, &y); CHKERRQ(ierr);
    ierr = VecSet(x, 3.0); CHKERRQ(ierr);
    ierr = VecSet(y, 1.0); CHKERRQ(ierr);

    ierr = VecAssemblyBegin(x); CHKERRQ(ierr);
    ierr = VecAssemblyEnd(x); CHKERRQ(ierr);
    ierr = VecAssemblyBegin(y); CHKERRQ(ierr);
    ierr = VecAssemblyEnd(y); CHKERRQ(ierr);

    ierr = VecAXPY(y, -1.0, x); CHKERRQ(ierr);

    ierr = VecDestroy(&x); CHKERRQ(ierr);
    ierr = VecDestroy(&y); CHKERRQ(ierr);


\end{frame_cpp}


\textbf{The same example using the Vector$<$double, PETScPar$>$ class}

\begin{frame_cpp}

    Vector<double, PETScPar> x, y;
    x.Reallocate(10);
    y.Reallocate(10);
    x.Fill(3.);
    y.Fill(1.);

    Add(-1., x, y);

\end{frame_cpp}


\hypertarget{seq-par-ds-dmatrix}{}\paragraph{Distributed Dense Matrix}\label{seq-par-ds-dmatrix}


The class Seldon$::$Matrix$<$T, Prop, PETScMPIDense, Allocator$>$  encapsulate a  dense distributed PETSc matrix of type \textbf{MATMPIDENSE} . This class implement the same interface as a classic Seldon matrix.

The source files of the class Seldon$::$Matrix$<$T, Prop, PETScMPIDense, Allocator$>$   are located in the seldon/matrix/ directory. Several methods are specific of  Seldon$::$Matrix$<$T, Prop, PETScMPIDense, Allocator$>$  class:


\begin{frame_cpp}
template <class T, class Prop, class Allocator>
class Matrix<T, Prop, PETScMPIDense, Allocator>:
public PetscMatrix<T, Prop, RowMajor, Allocator>
{
	...

    // Returns a reference on the inner petsc matrix.
    Mat& GetPetscMatrix();
    // Returns a const reference on the inner petsc matrix.
    const Mat& GetPetscMatrix() const;


    // Sets the MPI communicator.
    void SetCommunicator(MPI_Comm mpi_communicator);
    // Returns the MPI communicator of the current PETSc matrix.
    MPI_Comm GetCommunicator() const;

    // Inserts or adds values into certain locations of a matrix.
    // \warning These values may be cached, so 'Flush' must be called after all
    // calls to SetBuffer() have been completed.
    void SetBuffer(int, int, T, InsertMode);

    // Assembles the PETSc matrix.
    void Flush() const;

    // Returns the range of row indices owned by this processor.
    // The matrix is laid out with the first \f$n_1\f$ rows on the first
    // processor, next \f$n_2\f$ rows on the second, etc. If the current
    // processor is \f$k\f$, this method returns \f$n_k\f$ in \a i and
    // \f$n_{k+1}\f$ in \a j. If \a i is set to PETSC_NULL on entry, it is not
    // modified by this function. Same is true for \a j.
    void GetProcessorRowRange(int& i, int& j) const;

    ...
}
\end{frame_cpp}


\par These specific methods may be necessary during the construction of a distributed matrix. These methods are never called by data assimilation methods which delegate the distributed variable initializations to models and observation managers.

\hypertarget{seq-par-ds-smatrix}{}\paragraph{Distributed Sparse Matrix}\label{seq-par-ds-smatrix}

The class Seldon$::$Matrix$<$T, Prop, PETScMPIAIJ, Allocator$>$  encapsulate a sparse distributed PETSc matrix of type \textbf{MATMPIAIJ} . This class has the same interface as the  Seldon$::$Matrix$<$T, Prop, PETScMPIDense, Allocator$>$ class  introduced previously.

The source files of the class Seldon$::$Matrix$<$T, Prop, PETScMPIAIJ, Allocator$>$   are located in the seldon/matrix/ directory



\hypertarget{seq-par-dm}{}\subsection{'PETScClampedBar' Distributed Model}\label{seq-par-dm}


Verdandi provides an implementation of the 'ClampedBar' model based on the distributed structures available in Seldon. The source files of the distributed 'PetscClampedBar' model are located in the verdandi/model/ directory.



\hypertarget{seq-par-dm-m}{}\paragraph{The 'PETScClampedBar' Model}\label{seq-par-dm-m}


The clamped bar model describes the vibration of a bar clamped at one end. The bar is discretized with $Nx$ finite elements of the same length. With the hypothesis of "small displacements", it follows the linear system:

\begin{center} $ M \ddot Y + C \dot Y + K Y = F_{\theta_f}$ \par
 \end{center}

 where $M$  is the mass matrix, $K$  is the stiffness matrix,  $C$  is the damp matrix and  $F(\theta_f) = \sin(\frac{\pi t}{t_f}) M_{\theta_f} (1 ... 1)^T$  is the effort vector.


 The clamped bar model is solved numerically using a Newmark scheme (middle point) for integration in time:

 $ \ddot Y_{h + \frac{1}{2}} = \frac{\ddot Y_{h+1} + \ddot Y_{h} }2 = \frac{\dot Y_{h+1} - \dot Y_{h} } {\Delta t} $ \par
$ \dot Y_{h + \frac{1}{2}} = \frac{\dot Y_{h+1} + \dot Y_{h} }2 = \frac{Y_{h+1} - Y_{h} } {\Delta t} $\\


Algorithmically, it follows:

$ \dot Y_{h + 1} = \frac{2}{\Delta t}(Y_{h+1} - Y_{h}) - \dot Y_{h} $ \par
$Newmark_1 = \frac{1}2K + \frac{1}{\Delta t}C + \frac{2}{\Delta t^2}M$ \par
$Newmark_0 = -\frac{1}2 K + \frac{1}{\Delta t}C + \frac{2}{\Delta t^2}M$ \par
$Newmark_1Y_{h+1} = Newmark_0Y_{h} + \frac{2}{\Delta t}M\dot Y_{h} + F_{h + \frac{1}{2}}(\theta_f)$\\

The matrices  $M$, $Newmark_0$ and $Newmark_1$ are sparse distributed matrices of type Matrix$<$T, Prop, PETScMPIAIJ, Allocator$>$. The effort vector $F$ is a distributed vector of type  Vector$<$double, PETScPar$>$:


\begin{frame_cpp}
template <class T>
class PetscClampedBar: public VerdandiBase
{
    public:

    ...

    //! Mass matrix.
    Matrix<T, General, PETScMPIAIJ> mass_;
    //! Newmark matrix 0.
    Matrix<T, General, PETScMPIAIJ> newmark_0_;
    //! Newmark matrix 1.
    Matrix<T, General, PETScMPIAIJ> newmark_1_;

    //! Force.
    Vector<T, PETScPar> rhs_;

    ...

}
\end{frame_cpp}


\hypertarget{seq-par-dm-sv}{}\paragraph{Management of the Model State Vector}\label{seq-par-dm-sv}

The model state vector contains the displacement vector $Y$, the velocity vector $\dot Y$ and the parameter vector $\theta_f$. The Table \ref{titre4} gives the distribution of the state vector over processes.


\begin{table}
    \caption{\label{titre4} Distribution of the 'PetscClampedBar' state vector over processes.}

   \vspace{1.5cm}

    \begin{tabular}{|c|c|c|c|c|}
      \hline
       & \multicolumn{4}{c|}{Processeurs}\\
      \hline
       & $0$ & $1$ & ... & $N_{process} - 1$\\
      \hline
      $Y$ & $Y^0 =  (Y_0... Y_{\frac{N_x}{N_{process}} -1})$ &   $Y^1 = (Y_{\frac{N_x}{N_{process} }} ... Y_{2.\frac{N_x}{N_{process}} - 1 })$ & ... &  $(Y_{\frac{(N_{process} - 1).N_x}{N_{process} }} ... Y_{N_x - 1 })$\\
      \hline
      $\dot Y$ & $\dot Y^0 =  (\dot Y_0 ... \dot Y_{\frac{N_x}{N_{process}} -1})$ & $\dot Y^1 = (\dot Y_{\frac{N_x}{N_{process} }} ... \dot Y_{2.\frac{N_x}{N_{process}} - 1 })$ & ... & $(\dot Y_{\frac{(N_{process} - 1).N_x}{N_{process} }} ... \dot Y_{N_x - 1 })$ \\
      \hline
     $\theta_f$ &  & & &  $\theta_f$ \\
     \hline
    \end{tabular}
  \end{table}


The displacement vector $Y$ and the velocity vector $\dot Y$ are distributed vectors. The parameter vector $\theta_f$ is a sequential vector stored on the process of rank $Nprocess - 1$. When $\theta_f$ is updated, this process is responsible for sending the updated vector $\theta_f$ to all other.


\begin{frame_cpp}
template <class T>
class PetscClampedBar: public VerdandiBase
{
    public:

        ...

        //! Type of the model state vector.
        typedef Vector<T, PETScPar> state;
        //! Type of the model parameter vector.
        typedef Vector<T> parameter;


        //! Displacement.
        state displacement_0_;
        //! Velocity.
        state velocity_0_;
        //! Force parameter.
        parameter theta_force_;

         //! Local size of state vector.
        int Nstate_local_;
        //! Model state.
        state state_;

        ...

}
  \end{frame_cpp}



\par \textcolor{red}{GetState}\\


The model state vector is passed to the data assimilation method by local copy:


$X^i = (Y^i, \dot Y^i), 0 \le i \le N_{process} - 2 $ \par
$X^{N_{process} - 1} = (Y^{N_{process} - 1}, \dot Y^{N_{process} - 1}, \theta_f)$


 \begin{frame_cpp}
template <class T>
typename PetscClampedBar<T>::state& PetscClampedBar<T>
::GetState()
{
    int disp_start, disp_end;
    displacement_0_.GetProcessorRange(disp_start, disp_end);
    int state_start, state_end;
    state_.GetProcessorRange(state_start, state_end);
    for (int i = disp_start; i < disp_end; i++)
    {
        state_.SetBuffer(state_start++, displacement_0_(i));
        state_.SetBuffer(state_start++, velocity_0_(i));
    }
    if (rank_ == Nprocess_ - 1)
        for (int j = 0; j < parameter_.GetVector(reduced_[i]).GetSize(); j++)
            state_.SetBuffer(state_start++, theta_force_(j));
    state_.Flush();
    return state_;
}
  \end{frame_cpp}



\par \textcolor{red}{StateUpdated}\\


When the model state vector is updated, it is necessary to update the vectors $Y$ and $\dot Y$. The process $N_{process} - 1$ must broadcast the updated vector $\theta_f$ to all other processes.

\begin{frame_cpp}
template <class T>
void PetscClampedBar<T>
::StateUpdated()
{
    int disp_start, disp_end;
    displacement_0_.GetProcessorRange(disp_start, disp_end);
    int state_start, state_end;
    state_.GetProcessorRange(state_start, state_end)
    for (int i = disp_start; i < disp_end; i++)
    {
        displacement_0_.SetBuffer(i, state_(state_start++));
        velocity_0_.SetBuffer(i, state_(state_start++));
    }
    if (rank_ == Nprocess_ - 1)
        for (int j = 0; j < Ntheta_force_; j++)
            theta_force_(j) = state_(state_start++);
    displacement_0_.Flush();
    velocity_0_.Flush();
    MPI_Bcast(theta_force_.GetData(), Ntheta_force_, MPI_DOUBLE, Nprocess_ - 1, mpi_communicator_);
}
\end{frame_cpp}



\hypertarget{seq-par-dm-cm}{}\paragraph{Covariance Matrix}\label{seq-par-dm-cm}

The 'PetscClampedBarModel' provides a decomposition of the state error covariance matrix ($P$) as a product $LUL^T$.

The matrix $U$ is a matrix of small size, it is implemented as a sequential dense matrix.

The matrix $L$ is a matrix of $\mathcal{M}_{N_{state}, N_{reduced}}$, it is implemented as a distributed dense matrix. Each row of $L$ is distributed over processes with the same distribution as the one of the model state vector.

\hypertarget{seq-par-dm-p}{}\paragraph{Performance}\label{seq-par-dm-p}


Figure  \ref{fig:forward_time} introduces the performance of the 'PetscClampedBar' model.


\begin{figure}
  \caption{Simulation time of the 'PetscClampedBar' model with $N_{state} = 5.10^6$ }
  \label{fig:forward_time}

\includegraphics{image/Forward_CB2.eps}
\end{figure}



\hypertarget{seq-par-roukf}{}\subsection{'ReducedOrderUnscentedKalmanFilter'}\label{seq-par-roukf}


\hypertarget{seq-par-rouk-algof}{}\paragraph{Algorithm}\label{seq-par-roukf-algo}

Sampling:\\
  $ x_{h}^{(i)a} = x_h^a + L_h\sqrt{U_h^{-1}}I^{(i)} \textrm{, } \quad 1\leq i \leq p+1 $\\
  Prediction:\\
  $ x_{h+1}^f = E_\alpha(\mathcal{M}_{h}(x_{h+1}^{(*)a})) $\\
  $ x_{h+1}^{(i)f} = \mathcal{M}_{h}(x_{h}^{(i)a})$\\
  $ L_{h+1} = [x_{h+1}^{(*)f}]D_\alpha [V^*]^T \in \mathcal{M}_{n,p} $\\

  Update:\\
  $ y_{h+1}^{(i)} = \mathcal{H}_{h+1}(x_{h+1}^{(i)f})$\\
  $ \{HL\}_{h+1} = [y_{h+1}^{*}]D_\alpha [V^*]^T$\\
  $ U_{h+1} = P_{\alpha}^V +  \{HL\}_{h+1}^T R_{h+1}^{-1} \{HL\}_{h+1} \in \mathcal{M}_{p}$\\
  $ x_{h+1}^a = x_{h+1}^f + L_{h+1}U_{h+1}^{-1}\{HL\}_{h+1}^T R_{h+1}^{-1} (y_{h+1}-E_\alpha(y_{h+1}^{(*)}))$\\




\hypertarget{seq-par-roukf-ds}{}\paragraph{Distributed Structure in 'ReducedOrderUnscentedKalmanFilter'}\label{seq-par-roukf-ds}


The goal is that no variable of the model state size is allocated by any process. The concerned variables are  $x^a$, $L \in \mathcal{M}_{N_{state}, N_{sigma\_point}}$ and $ [x^{(*)f}] \in \mathcal{M}_{N_{state}, N_{reduced}}$.


\begin{itemize}

\item The state vector is a distributed dense vector whose management is delegated to the model (see Section \ref{seq-par-dm-sv}). The model state access are performed thanks to Model$::$GetState and Model$::$StateUpdated methods.

\item The sensitivity matrix $L$ is a row distributed dense matrix whose management is delegated to the model. The model is responsible for defining a a row distribution compatible with the one of the state vector (see Section \ref{seq-par-dm-cm}). The $L$ access is performed using Model$::$GetStateErrorVarianceProjector method.

\item The matrix $ [x^{(*)f}]$ must be defined as a distributed dense matrix which distribution is compatible with the one of the matrix $L$. Since the matrix  $ [x^{(*)f}]$ is peculiar to the ROUKF algorithm, its management can't be delegated to the model. Thus, it is necessary to allocate this matrix in the data assimilation method. $ [x^{(*)f}]$ construction requires two information: the type of the matrix (dense distributed) and the distribution over the processes ($[x^{(*)f}]$ distribution compatible with $L$ distribution).


$ [x^{(*)f}]$ construction must be modular: ROUKF implementation must be the same in sequential and in parallel.


\par \textcolor{red}{Specification of $ [x^{(*)f}]$ type}\\

In PETSc, the types of the structures are managed dynamically. Every matrix has the same static type 'Mat', the real type of the matrix is defined during the execution by the following function call:

\begin{frame_cpp}
Mat A;
MatSetType(A, MATMPIDENSE);
\end{frame_cpp}


Indeed, PETSc is written in C language, thus template function can't be defined for linear algebra operations. In Seldon the type of the matrices and vectors are statics. The type of $[x^{(*)f}]$ is the same as the one of $L$. It is no longer required to call any function to specify the type. (The management of the types in Verdandi is detailed in Section \ref{seq-par-type})

\par \textcolor{red}{Distribution of $ [x^{(*)f}]$}\\

The distribution of  $ [x^{(*)f}]$ is performed during the allocation. The distribution of $L$ must be provided to the constructor of matrix $[x^{(*)f}]$.



Allocation of a sequential matrix of  $\mathcal{M}_{m, n}$ :
\begin{frame_cpp}
Matrix<double> A;
A.Reallocate(m, n);
\end{frame_cpp}
Allocation of a parallel matrix of  $\mathcal{M}_{m, n}$  with a distribution of $mlocal$ rows on the local process:
\begin{frame_cpp}
Matrix<double> A;
A.Reallocate(m, n, mlocal);
\end{frame_cpp}

In order to have the same code in sequential and in parallel, the following template function is defined:
\begin{frame_cpp}
template <class Model, class T, class Prop, class Storage, class Allocator>
void Allocate(const Model& model, Matrix<T, Prop, Storage, Allocator>& A, int n, int m)
{
	A.Reallocate(m, n);
}
\end{frame_cpp}

This template function is overloaded for distributed dense matrices:
\begin{frame_cpp}
template <class Model, class T, class Prop, class Allocator>
void Allocate(const Model& model, Matrix<T, Prop, PETScMPIDense, Allocator>& A, int n, int m)
{
	A.Reallocate(m, n, model.GetLocalM());
}
\end{frame_cpp}


The allocation of  $ [x^{(*)f}]$ is perfumed in ROUKF by the following call:
\begin{frame_cpp}
Allocate(model_, X_i, Nstate, Nsigma_point);
\end{frame_cpp}

So, the implementation of ROUKF is the same in sequential and in parallel. In sequential, this implementation does not required the addition of any methods to the model interface. In parallel, the model should defined the method Model$::$GetLocalM()
which provides the number of local rows in the $L$ distribution.

\end{itemize}


\hypertarget{seq-par-roukf-p}{}\paragraph{Performance}\label{seq-par-roukf-p}

The proposed implementation enables to apply the ROUKF algorithm to a distributed model.  No variable of the model state size is allocated by any process. Thus the memory complexity is divided by the number of processes used.

Concerning the time performance, during the prediction step:

\begin{itemize}
 \item the computation  $ x_{h+1}^{(i)f} = \mathcal{M}_{h}(x_{h}^{(i)a})$ has the same speed up as the one of the model.
 \item the computation  $ L_{h+1} = [x_{h+1}^{(*)f}]D_\alpha [V^*]^T $ has a speed up equal to the number of processes.
 \end{itemize}
During the update step :
\begin{itemize}
\item the computation  $ x_{h+1}^a = x_{h+1}^f + L_{h+1}U_{h+1}^{-1}\{HL\}_{h+1}^T R_{h+1}^{-1} (y_{h+1}-E_\alpha(y_{h+1}^{(*)})) $ has a speed up equal to the number of processes.\\
\end{itemize}

The performances of the ROUKF algorithm are introduced in Figure  \ref{fig:roukf_time}.


\begin{figure}
  \caption{Simulation time of the sequential  ROUKF applied to the 'PetscClampedBar' model with $N_{state} = 5.10^6$}
  \label{fig:roukf_time}

\includegraphics{image/ROUKF_Seq_CB_Par_2.pdf}
\end{figure}



\hypertarget{seq-par-ep}{}\subsection{Example Programs}\label{seq-par-ep}

The example programs are located in the  verdandi/example/petsc\_clamped\_bar directory.


\hypertarget{seq-par-ep-c}{}\paragraph{Compilation}\label{seq-par-ep-c}


\par \textcolor{red}{Dependencies}\\


\textbf{OpenMPI}\\

\begin{itemize}

\item Download the following archive:\\
\href{http://www.open-mpi.org/software/ompi/v1.6/}{http://www.open-mpi.org/software/ompi/v1.6/}.

\item  Extract the archive and execute the following command in the source directory:

\begin{frame_bash}
$ ./configure   \
     CC=/usr/bin/gcc-4.2 \
     CPP=/usr/bin/cpp-4.2 \
     CXX=/usr/bin/g++-4.2 \
     F77=/usr/bin/gfortran \
     FC=/usr/bin/gfortran \
     F90=/usr/bin/gfortran \
     CFLAGS=-m64 \
     CXXFLAGS=-m64 \
     FFLAGS=-m64 \
     FCFLAGS=-m64 \
     LDFLAGS=-m64 \
\end{frame_bash}

\end{itemize}


\textbf{PETSc-3.3}\\

\begin{itemize}

\item Download the following archive:\\
\href{http://www.mcs.anl.gov/petsc/download/index.html}{http://www.mcs.anl.gov/petsc/download/index.html}.

\item  Extract the archive and execute the following command in the source directory:

\begin{frame_bash}
$ export PETSC_DIR=/Users/Shared/Library/Petsc
$ export PETSC_ARCH=macosx-10.7-debug
$ python config/configure.py  CXXFLAGS=-m64   CFLAGS=-m64  FCFLAGS=-m64  FFLAGS=-m64  LDFLAGS=-m64  --with-debugging=yes  --with-dynamic-loading  --with-shared-libraries  --with-parmetis-include=/Users/Shared/Library/ParMetis  --with-parmetis-lib="-L/Users/Shared/Library/ParMetis -lparmetis -lmetis" --with-metis-include=/Users/Shared/Library/Metis/64/Lib  --with-metis-lib="-L/Users/Shared/Library/Metis/64 -lmetis"  --with-superlu_dist-lib="-L/Users/Shared/Library/SuperLUDIST/lib -lsuperlu_dist"  --with-superlu_dist-include=/Users/Shared/Library/SuperLUDIST/SRC  --with-scalapack-lib="-L/Users/Shared/Library/SCALAPACK -lscalapack"  --with-scalapack-include=/Users/Shared/Library/SCALAPACK/SRC  --with-blacs-lib="-L/Users/Shared/Library/BLACS/LIB -lblacs -lblacsCinit -lblacsF77init"  --with-blacs-include=/Users/Shared/Library/BLACS/SRC  --with-mumps-include=/Users/Shared/Library/Mumps/include/ --with-mumps-lib="-L/Users/Shared/Library/Mumps/lib/ -ldmumps -lzmumps -lmumps_common -lpord -lgfortran" --with-mpi-dir=/Users/Shared/Library/OpenMPI
\end{frame_bash}

\end{itemize}


\par \textcolor{red}{Example Programs}\\


Compile the program \textbf{generate\_observation.cpp}:

\begin{frame_bash}
$ scons generate_observation mpi=yes
\end{frame_bash}

Then compile the program \textbf{reduced\_order\_unscented\_kalman\_filter.cpp}:
\begin{frame_bash}
$ scons reduced_order_unscented_kalman_filter mpi=yes
\end{frame_bash}



\hypertarget{seq-par-ep-o}{}\paragraph{Observation}\label{seq-par-ep-o}


Since no observations are given yet, we have to generate some. Execute the following command:

\begin{frame_bash}
$ mpirun -n 2 generate_observation configuration/truth.lua
\end{frame_bash}

to run the model with the initial conditions described in truth.lua, without data assimilation. This should generate a result file  \textbf{truth-state\_forecast.bin}  in the directory \textbf{example/result}. This file store the state (displacement, velocity, $\theta_f$) trajectory.
The generated state (displacement, velocity, $\theta_f$) will serve as observations for the assimilation.



\hypertarget{seq-par-ep}{}\paragraph{Data Assimilation with 'ReducedOrderUnscentedKalmanFilter'}\label{seq-par-ep}


To use the ROUKF method, execute the following command:

\begin{frame_bash}
$ mpirun -n 4 reduced_order_unscented_kalman_filter configuration/assimilation.lua
\end{frame_bash}

All processes are assigned to the model. The results should be the same as those obtained in sequential.

\hypertarget{par-par}{}\section{Parallel Method applied to Parallel Model}\label{par-par}


\hypertarget{par-par-pr}{}\subsection{Parallel 'ReducedOrderUnscentedKalmanFilter'}\label{par-par-pr}


\hypertarget{par-par-pr-mc}{}\paragraph{MPI Communicator}\label{par-par-pr-mc}


The objective is to apply the parallel ROUKF algorithm introduced in Section \ref{par-seq} on  a distributed model. We want to implement the capabilities in Verdandi to instantiate several models in parallel, and to assign several processes to each model task. A possible solution consist in using the grid topology provided by MPI:


\begin{itemize}

\item each process is defined in a MPI processor grid.

\item each process is identified by its coordinates in the grid. Figure \ref{fig:mpi_grid} represents an example of a mapping table of process rank and their corresponding grid coordinates.

\item  for each row of the grid,  a communicator containing the subgrid that includes the processes of the row is created. For instance,  in Figure \ref{fig:mpi_grid}, the group of the second row communicator is composed of processes 4, 5, 6 and 7 from $MPI\_COMM\_WORLD$ . Process 0 in second row communicator is the same as process 4 in $MPI\_COMM\_WORLD$, process 1 the same as process 5...

\item for each column of the grid,  a communicator containing the subgrid that includes the processes of the column is created.

\end{itemize}

\begin{figure}
  \caption{$4*4$ MPI Processor Grid }
  \label{fig:mpi_grid}
  \includegraphics[scale=0.6]{image/grid.pdf}

\end{figure}



Each column communicator correspond to an instance of model. In Figure \ref{fig:mpi_grid}, there is 4 instance of model. The first column communicator, composed of processes 0, 4, 8 and 12, is assigned to the first model instance. Then, the second column communicator is assigned to the second model instance...

Some changes  about the configuration of MPI communicators in the distributed model may be required. Indeed, the distributed model are not allowed to performed computations in the global MPI communicator $MPI\_COMM\_WORLD$. To enable several parallel model instances, $MPI\_COMM\_WORLD$ has to be replaced by a communicator of disjoint process sets in which each of the model instance operates. The column communicators to be assigned to the model instances are generated by the data assimilation method. These communicators are assigned to the model instances thanks to the following method:

\begin{frame_cpp}
namespace Verdandi
{


    //! This class is a model template.
    class ModelTemplate: public VerdandiBase
    {
        public:
            ...
            // Parallel model.
#ifdef VERDANDI_WITH_MPI
            void SetMPICommunicator(MPI_Comm& mpi_communicator);
#endif
            ...
    }

}
\end{frame_cpp}

The row communicators enable the parallel ROUKF algorithm to update its distributed variables $x^a$, $L \in \mathcal{M}_{n,p}$ and $ [x^{(*)f}] \in \mathcal{M}_{n,r}$.


\hypertarget{par-par-pr-a}{}\paragraph{Algorithm}\label{par-par-pr-a}

This Section describes the parallel ROUKF algorithm applied to a parallel model. The processes are mapped to a process grid by using row-major order (see Section \ref{par-par-pr-mc}).


\par \textbf{Initialization}

  \begin{itemize}

 \item First column  of the MPI grid (processes 0, 4, 8, 12; instance of model 0) allocates matrix $L$.\\

 \end{itemize}

 \par  \textbf{Sampling}


 \begin{itemize}

  \item First column  of the MPI grid computes  $ x_{h}^{(i)a} = x_h^a + L_h\sqrt{U_h^{-1}}I^{(i)} \textrm{, } \quad 1\leq i \leq p+1 $.

  \item First column  of the MPI grid distributes particles  $ x_{h}^{(i)a} $ over all columns.\\

 \end{itemize}

  \par  \textbf{Prediction}

   \begin{itemize}

  \item Each column  of the MPI grid computes in parallel  $ x_{h+1}^{(i)f} = \mathcal{M}_{h}(x_{h}^{(i)a})$ with its local particles.

  \item Each column of the MPI grid sends its local particles  $ x_{h+1}^{(i)f}$ to the first column.

   \item Each column of the MPI grid  computes in parallel  $ y_{h+1}^{(i)} = \mathcal{H}_{h+1}(x_{h+1}^{(i)f})$.

    \item Each column of the MPI grid sends its local particles   $ y_{h+1}^{(i)} = \mathcal{H}_{h+1}(x_{h+1}^{(i)f})$ to the first column.

  \item First column  of the MPI grid computes  $ L_{h+1} = [x_{h+1}^{(*)f}]D_\alpha [V^*]^T $.


 \end{itemize}

 \par  \textbf{Update}\\

 \begin{itemize}

 \item First column  of the MPI grid computes $ \{HL\}_{h+1} = [y_{h+1}^{*}]D_\alpha [V^*]^T$.

 \item  First column  of the MPI grid computes  $ U_{h+1} = P_{\alpha}^V +  \{HL\}_{h+1}^T R_{h+1}^{-1} \{HL\}_{h+1}$.

  \item First column  of the MPI grid computes $ x_{h+1}^a = x_{h+1}^f + L_{h+1}U_{h+1}^{-1}\{HL\}_{h+1}^T R_{h+1}^{-1} (y_{h+1}-E_\alpha(y_{h+1}^{(*)}))$.\\

 \end{itemize}



\hypertarget{par-par-ep}{}\subsection{Example Programs}\label{par-par-ep}


The example programs are located in the  verdandi/example/petsc\_clamped\_bar directory.


\hypertarget{par-par-ep-c}{}\paragraph{Compilation}\label{par-par-ep-c}


First of all, the preprocessor variable $ VERDANDI\_WITH\_MPI $ has to be defined in files  \textbf{reduced\_order\_extended\_kalman\_filter.cpp} and \textbf{reduced\_order\_unscented\_kalman\_filter.cpp}:

\begin{frame_cpp}
#define VERDANDI_DEBUG_LEVEL_4
#define SELDON_WITH_BLAS
#define SELDON_WITH_LAPACK

#define VERDANDI_WITH_ABORT
#define VERDANDI_DENSE

#define VERDANDI_WITH_MPI

#if defined(VERDANDI_WITH_MPI)
#include <mpi.h>
#endif


#include "Verdandi.hxx"
#include "seldon/SeldonSolver.hxx"

#include "model/PetscClampedBar.cxx"
#include "observation_manager/PetscLinearObservationManager.cxx"
#include "method/ReducedOrderUnscentedKalmanFilter.cxx"


int main(int argc, char** argv)
{

    VERDANDI_TRY;

    ...
}
\end{frame_cpp}

Compile the program \textbf{generate\_observation.cpp}:

\begin{frame_bash}
$ scons generate_observation mpi=yes
\end{frame_bash}

Then compile the program \textbf{reduced\_order\_unscented\_kalman\_filter.cpp}:
\begin{frame_bash}
$ scons reduced_order_unscented_kalman_filter mpi=yes
\end{frame_bash}



\hypertarget{par-par-ep-o}{}\paragraph{Observation}\label{par-par-ep-o}


Since no observations are given yet, we have to generate some. Execute the following command:

\begin{frame_bash}
$ mpirun -n 2 generate_observation configuration/truth.lua
\end{frame_bash}

to run the model with the initial conditions described in truth.lua, without data assimilation. This should generate a result file  \textbf{truth-state\_forecast.bin}  in the directory \textbf{example/result}. This file store the state (displacement, velocity, $\theta_f$) trajectory.
The generated state (displacement, velocity, $\theta_f$) will serve as observations for the assimilation.


\hypertarget{par-par-ep}{}\paragraph{Data Assimilation with 'ReducedOrderUnscentedKalmanFilter'}\label{par-par-ep}


The parameters of the ROUKF method are described in the configuration file  \textbf{configuration/assimilation.lua}.

It is necessary to define the dimension of the MPI grid. The number of model instances and the number of processes assigned to each model instance must be defined:

\textbf{assimilation.lua}\\
\begin{frame_lua}
-- Simulation with assimilation using ROUKF.
reduced_order_unscented_kalman_filter = {

 	...

   mpi_grid = {

      -- The number of processes for each model task.
      Nrow = 2,
      -- The number of model tasks.
      Ncol = 3
   }

}

\end{frame_lua}

To use the ROUKF method, execute the following command:

\begin{frame_bash}
$ mpirun -n 6 reduced_order_unscented_kalman_filter configuration/assimilation.lua
\end{frame_bash}

\textbf{Warning:} The number of processes must be equal to $mpi\_grid.Nrow * mpi\_grid.Nco$.


The results should be the same as those obtained in sequential.

\hypertarget{par-par-p}{}\section{Performance}\label{par-par-p}


\begin{figure}
  \caption{PetscClampedBar parameter estimation using ROUKF (parallel) with $N_{state} = 10^5$ and $N_{observation} = 10^4$ }

  \vspace{1cm}

  \label{fig:roukf_par_time}
 \hspace{-3cm}
\includegraphics[width=2.0\linewidth]{image/roukf_par_3_test.pdf}
\end{figure}


We can see in Figure \ref{fig:roukf_par_time} that when the number of processes is less than or equal to four, it is more in efficient to instantiate only one model and to assign all processes to this instance. On the other hand, when the number of processes increases, the most effective is to own
several model instances:

\begin{itemize}

\item when the number of processes is equal to sox, the most efficient is to define two model instances running on three processes.

\item when the number of processes is equal to sox, the optimal configuration is to have two model instances running on four processes.

\end{itemize}


As intended, this second level of parallelism provides a better scalability. At the fist level of parallelism, when the efficiency of ROUKF algorithm decreases, this second level of parallelism contributes to better take advantage of the  available computation resources.




\appendix
\chapter{Coding Standards}\label{coding_standards}


%%%%%%%%%%%%%%%%%%
%% INTRODUCTION %%
%%%%%%%%%%%%%%%%%%


\section{Introduction}
\label{part:introduction}

Many coding standards may be found on-line: see, for instance, the list
provided at \url{http://www.chris-lott.org/resources/cstyle/}. In particular,
the \textit{C++ Coding Standard} by Todd Hoff, available at
\url{http://www.possibility.com/Cpp/CppCodingStandard.html} provided useful
guidelines for the present standard.

The general conventions of part~\ref{part:general} shall be applied to all
computer codes, in any language. C++ conventions follow in
part~\ref{part:cpp}.


%%%%%%%%%%%%%%%%%%%
%% GENERAL RULES %%
%%%%%%%%%%%%%%%%%%%


\section{General Conventions}
\label{part:general}

The following conventions must be applied in all languages.

\subsection{Development}

\begin{enumerate}
\item \rule{Codes must be written in American English. This includes variable
    names, file names, comments,~\ldots{}} \justification{A code should be
    open to anyone.  Even if a code is not intended to be shared initially,
    this may change.  Moreover parts of it may be reused in another project.}
\item \rule{Optimize only the parts of the code that lead to significant
    overheads.} \commentcs{In addition, remember that the compilers partially
    optimize your code.} \justification{An optimized code is usually less
    readable than its straightforward version.}
\item \rule{A code must compile without warnings.}  \commentcs{At development
    stage, compile your code with the most restrictive compilation options and
    with all warning messages enabled.} \justification{It increases
    portability, and it may help avoiding mistakes.}
\item \rule{Global variables must be avoided.} \justification{Units of a code
    should be independent from their environment so that they may be reused
    and so that the overall code may be safer.}
  \setcounter{points}{\value{enumi}}
\end{enumerate}


\subsection{Names}

\begin{cenumerate}
\item \rule{Use explicit and meaningful names.} \commentcs{You should first
    consider that the length does not matter. Actually it does, but many
    programmers tend to use too short and therefore uninformative
    names. Usually, the wider scope, the longer name.}  \justification{New
    programmers should be able to read the code without learning the meaning
    of the variables and the functions in use. Explicit names also save
    unnecessary comments.  Example (in C++):}
\begin{frame_cpp}
if (Species.GetName() == target_species)
    output_concentration = Species.Concentration();
\end{frame_cpp}
  \justificationf{is better than:}
\begin{frame_cpp}
// Checks whether current species is the target species.
if (sp.GetName() == species)
    // Retrieves the output concentration.
    c = sp.Concentration();
\end{frame_cpp}
\item \rule{Avoid contractions. If you really need a contraction, only use it
    as a suffix.} \commentcs{Accepted contractions are: tmp (temporary), in
    (input), out (output), obs (observation). Example: \code{value\_in}.}
  \justification{Contractions can easily collide (including with a full word)
    or have meanings depending on the context. Besides, not all developers may
    understand your contractions, depending on their habits and maybe their
    native language. For instance, French developers often contract
    \code{number} into \code{nb} whereas a native English speaker would use
    \code{num}.}
\item \rule{Unless a more explicit name is found, preferably use {\rm
      \code{i}} for an index. As for dimensions, use {\rm \code{h}} for time
    index, {\rm \code{i}} along x, {\rm \code{j}} along y and {\rm \code{k}}
    along z.} \justification{This is a common practice.}
\item \rule{Avoid plural forms.} \commentcs{Even the name of a vector should not
    be in plural form. For instance, a vector of observations can be called
    \code{observation}, and the i-th observation is \code{observation(i)}
    which is perfectly clear. If the plural form seems to be required,
    consider appending \code{\_list}: e.g., \code{location =
      location\_list(i)}, even if \code{location\_list} is not an instance of
    the STL class \code{list}.} \justification{The use of plural forms makes
    it difficult to guess or remember the names of variables and methods. It
    is quickly unclear whether the plural form was used or not for such and
    such methods. The same is true with a complex object that stores many data
    sets: should it be named with plural form because it contains a list, or
    should the singular be preferred because it appears as a single
    block/object? The easiest way to avoid the confusion is to avoid plural
    forms.}
\item \rule{A fixed number of \code{xxx} should be named \code{Nxxx}.}
  \commentcs{Example: \code{Nstep} for the number of steps (if it is fixed),
    \code{Narray} for a number of arrays.}
\item \rule{The Boolean methods should have a prefix like \code{Is} or
    \code{Has}.} \commentcs{Examples: \code{IsReady}, \code{HasObservation},
    \code{IsEmpty}.} \justification{It makes it clear that the method returns
    a Boolean. The question that the method answers is very clear too.}
\end{cenumerate}


\subsection{Formatting}

\paragraph{Spaces and Parens}
\label{sec:spaces-parens}

\begin{cenumerate}
\item \rule{Put one blank space before and one blank space after the
    operators: \code{+}, \code{-}, \code{/}, \code{*} (multiplication),
    \code{=}, \code{+=}, \code{-=}, \code{*=}, \code{/=}, \code{|}, \code{\&},
    \code{||}, \code{\&\&}, \code{<}, \code{<=}, \code{>}, \code{>=},
    \code{==}, \code{!=}, \code{<{}<}.}  \commentcs{You might break this rule in
    inner parens (at a deep level, e.g., some array index like \code{i+1} in a
    complex formula).} \justification{It makes the code much more readable. It
    is also a very common practice.}
\item \rule{Put one blank space after each comma.} \justification{It makes the
    code more readable. It is a very common practice.}
\item \rule{Do not add trailing spaces at the end of code lines.} \commentcs{A
    script can remove the trailing spaces for you---such a script should be
    run before any commit to the repository of your revision control
    system. Emacs users may have their editor removing the trailing spaces
    whenever they save a file. They can also have Emacs show them the trailing
    whitespaces; e.g., in Python mode:}
\begin{frame_lisp}
(setq whitespace-style '(trailing))
(add-hook 'python-mode-hook 'whitespace-mode)
\end{frame_lisp}
  \njustification{Browsing the code, moving blocks, copies,~\ldots{} are
    slowed down because of trailing spaces. In addition, the differences
    between two revisions of a file should not include such noise.}
\item \rule{No space between the function name and its arguments list.}
  \commentcs{Write}
\begin{frame_cpp}
  func(a, b)
\end{frame_cpp}
  \commentf{instead of}
\begin{frame_cpp}
  func (a, b)
\end{frame_cpp}
\item \rule{No space after an opening paren or a closing paren.}
  \commentcs{Write}
\begin{frame_cpp}
  func(a, b)
\end{frame_cpp}
  \commentf{instead of}
\begin{frame_cpp}
  func( a, b )
\end{frame_cpp}
\item \rule{Put a space between a language keyword and the following paren.}
  \commentcs{Write}
\begin{frame_cpp}
  while (error > epsilon)
\end{frame_cpp}
  \commentf{instead of}
\begin{frame_cpp}
  while(error > epsilon)
\end{frame_cpp}
  \njustification{Keywords and functions should be distinguishable.}
\item \rule{Do not put unnecessary parens in logical expressions, except to
    clarify the order of evaluation.}  \commentcs{For instance (in C++), write}
\begin{frame_cpp}
  if (i != 0 && j > 5)
\end{frame_cpp}
\commentf{instead of}
\begin{frame_cpp}
  if ((i != 0) && (j > 5))
\end{frame_cpp}
\njustification{Unncessary parens slow down the reading.}
\end{cenumerate}

\paragraph{Comments}

\begin{cenumerate}
\item \rule{A comment line is placed before the lines or the block it
    comments.}  \commentcs{Observe where each comment line is placed:}
\begin{frame_cpp}
// Checks the availability of observations. Note that the call implicitly
// loads the observations at current date.
if (observation_manager.HasObservation())
// Assimilates the available observations.
{
    Analyze();
    if (positive_state)
        // Enforces the positivity of the state vector.
        for (int i = 0; i < Nstate; i++)
            state(i) = max(0., state(i));
}
\end{frame_cpp}
  \njustification{Since an explanation may address several lines, the scope of
    a comment placed after is unclear.}
\item \rule{Like a sentence, a comment starts with a capital and ends with a
    dot (even a one-word comment).}  \justification{All comment lines should
    be consistent. This rule is clear and easy to follow.}
\item \rule{Use simple present to explain what a line does or what a sequence
    of lines does.} \commentcs{See the example above.} \justification{A comment
    introduces to what a line {\it does}. So \code{// Extracts data.}
    implicitly means \code{// This line extracts data.}}
\item \rule{When referring to a variable, surround the variable name with
    simple quotes.} \commentcs{Example: \code{// Updates 'state' so that it
      should be consistent with 'full\_state'.}}  \justification{Reading
    comments, with variable names included, can be really difficult because
    the variable names are often words: one cannot identify at first sight
    that the variable name is a special element. Think of a comment line like
    \code{// Makes a consistent with the location.}  instead of \code{// Makes
      'a' consistent with the location.}}
\end{cenumerate}

\paragraph{Function and Method Definition}

\begin{cenumerate}
\item \rule{Arguments are sorted from input variables to output variables.
    Dimensions are provided first.} \commentcs{The only exception is for
    optional arguments if they are necessarily the last arguments (as in C++
    and Python). Try to sort all arguments so that the order makes sense. For
    instance, if the input variables are a number of points along $x$, the
    abscissae and the values of a function $f$ at these abscissae, then
    provide them in that order. Indeed, one needs first the number of points
    $n$, then the positions $x_i$ of the points ($i\in\llbracket{}0,
    n-1\rrbracket$) and finally the associated values $f(x_i)$.}
  \justification{A code line is read from left to right, and obviously an
    input comes before an output.}
\end{cenumerate}


\subsection{Language Features}

\paragraph{Standard}

\begin{cenumerate}
\item \rule{Build a fully standard-compliant code. If a compiler does not
    understand it, discard it or maybe maintain specific code for it.}
  \justification{This ensures portability and makes the code perennial.}
\end{cenumerate}


%%%%%%%%%
%% C++ %%
%%%%%%%%%


\section{C++}
\label{part:cpp}


\subsection{Development}

\begin{cenumerate}
\item \rule{Compilation with GNU G++ and with options {\rm \code{-Wall -ansi
        -pedantic}} should not issue any warning.} \justification{It increases
    portability (through compliance with the C++ standard), and it may help
    avoiding mistakes.}
\end{cenumerate}


\subsection{Names}

\paragraph{Common Conventions}

\begin{cenumerate}
\item \rule{Do not add a prefix to a set of objects to avoid conflicts.}
  \commentcs{Use name spaces instead.}
\end{cenumerate}

\paragraph{Classes and Methods}

\begin{cenumerate}
\item \rule{A name is one word or a concatenation of words. The first letter
    of each word (including the first one) is uppercase.}  \commentcs{Examples:}
\begin{frame_cpp}
class FormatBinary;
double Data::GetMax() const;
void Data::Print() const;
void LoadPreviousAnalysis(...);
\end{frame_cpp}
  \njustification{Two other conventions are widely used: \code{formatBinary}
    and \code{format\_binary}. With the latter convention, classes and methods
    are not easily identified in a code. The former convention is a bit
    inconsistent: one-word methods are not as emphasized as two-word methods
    are.}
\item \rule{The accessors should be named with {\rm \code{Get}} or {\rm
      \code{Set}} (prefixed).} \commentcs{Example: \code{GetDate},
    \code{SetPosition}}.
\end{cenumerate}

\paragraph{Functions}

\begin{cenumerate}
\item \rule{Same rules as for the methods.} \commentcs{Meanwhile, the name of a
    small function (e.g., a single formula, or an extension of the C++
    libraries) may be lowercase with underscores to delimit the words.}
\item \rule{Extern functions should be lowercase with underscores to delimit
    the words, and they should be prefixed by an underscore.}  \commentcs{The
    name of an extern function is defined by the compiler. If the compiler
    does comply with this convention, define a macro that follows this
    convention. Example:}
\begin{frame_cpp}
#define _linear_interpolation linear_interpolation_
\end{frame_cpp}
  \njustification{Fortran functions are usually named with one or two
    underscores at the end. The rule is consistent with the addition of an
    underscore, but as a prefix in order to avoid conflicts (with attributes,
    see below).}
\end{cenumerate}

\paragraph{(Local) Variables}

This section also applies to method arguments and function arguments.

\begin{cenumerate}
\item \rule{Use lower case and words delimited with underscores.}
  \justification{Many variables are naturally lowercase, like the indexes. In
    addition, one may declare an instance of a class, say \code{Data} or
    \code{ObservationManager}, with the same name as the class: \code{Data
      data} or \code{ObservationManager observation\_manager}.}
\end{cenumerate}

\paragraph{Attributes}

\begin{cenumerate}
\item \rule{Same rules as for variables, except that an underscore must be
    appended at the end of the name.} \commentcs{This rule might be broken in
    case the attribute is public or for consistency with a public attribute
    that has no appended underscore.} \justification{The underscore at the end
    enables to distinguish attributes from local variables within the
    methods. The scope is an important property of a variable. In addition,
    the method arguments may have the same names as the attributes, without
    the underscore. For example:}
\begin{frame_cpp}
void ExtendedStream::SetDelimiter(delimiter)
{
    delimiter_ = delimiter;
}
\end{frame_cpp}
\end{cenumerate}

\paragraph{References, Pointers, Global Variables and Constant Variables}

\begin{cenumerate}
\item \rule{No special notation is associated with references, pointers,
    global variables or constant variables.} \justification{Constant variables
    are declared as such (keyword \code{const}); no alteration of these
    variables can occur.  Global variables should be avoided. References are
    used in C++ to manipulate variables just like others: a notation to
    distinguish them would break this advantage.  Programmers sometimes prefix
    a 'p' for pointers, but the syntax is usually clear enough to show that a
    pointer is in use.}
\end{cenumerate}

\paragraph{Name Spaces}

\begin{cenumerate}
\item \rule{Name spaces are mainly used for libraries. A name space has the
    exact name of its library.} \commentcs{Example:}
\begin{frame_cpp}
namespace Verdandi;
\end{frame_cpp}
\end{cenumerate}

\paragraph{Type Names (typedef)}

\begin{cenumerate}
\item \rule{Use lower case and words delimited with underscores. Do not append
    an underscore even if the type name is defined in a class.}
  \justification{Type names are used as shortcuts for what may be seen as a
    low-level type, just like a \code{string} or a \code{double} in the
    \code{main()} function.}
\end{cenumerate}

\paragraph{Macros}

\begin{cenumerate}
\item \rule{Use upper case and words delimited by underscores.}
  \justification{Macros should be clearly identified because of their really
    specific nature. In addition, this is common practice.}
\item \rule{In case a macro is related to a library, the first word of the
    macro must be the library name.} \commentcs{Example:}
\begin{frame_cpp}
  #define VERDANDI_DEBUG_LEVEL_4
\end{frame_cpp}
  \njustification{This avoids conflicts with macros from other libraries, and
    it better indicates what the macro is for.}
\end{cenumerate}


\subsection{Formatting}
\label{sec:formatting}

\paragraph{Indentation and Braces}
\label{sec:indentation-braces}

\begin{cenumerate}
\item \rule{Use the Allman standard for indentation.} \commentcs{This
    indentation style is called BSD under Emacs. It looks like this:}
\begin{frame_cpp}
    if (i == f(a, b))
        i += 5;  // No braces for a single line.
    else
    {   // Instead of "else {".
        while (i != 5)
        {
            j = 3 * f(4, b);
            i++;
        }
        i--;
    }
\end{frame_cpp}
  \commentf{Note the (compulsory) 4-space depth for the indentation. Emacs
    users can enforce this convention with the following code (placed in
    \code{.emacs}):}
\begin{frame_lisp}
(defun verdandi-c++-mode ()
  (interactive)
  (c-set-style "bsd")
  (setq c-basic-offset 4)
  (add-hook 'before-save-hook 'delete-trailing-whitespace t t))
(defun verdandi-c++-mode-hook ()
  (if (string-match "verdandi" buffer-file-name)
      (verdandi-c++-mode)))
(add-hook 'c++-mode-hook 'verdandi-c++-mode-hook)
\end{frame_lisp}
  \commentf{The hook \code{delete-trailing-whitespace} will remove trailing
    spaces when the file is saved, which is another formatting rule (see
    section~\ref{sec:spaces-parens}). The \emph{Verdandi} C++ mode will be applied to
    any file that contains the word ``verdandi'' in its absolute path.}
  \justification{Consistent indentation is utterly required at least to browse
    the code and to grasp its structure. In addition, differences between two
    versions of a same code are easier to parse with a standard indentation.}
\item \rule{Tabulations are forbidden. They should be replaced with
    spaces.}\commentcs{Emacs users can add the following line in their
    \code{.emacs}:}
\begin{frame_lisp}
(setq-default indent-tabs-mode nil)
\end{frame_lisp}
  \njustification{Tabulation-based indentation may be more convenient for code
    browsing than space-based indentation: moving in the code may be
    faster. Unfortunately, the length of a tabulation may vary from one
    environment to another (usual values are 4 or 8 spaces, maybe 2
    sometimes). This can cause misalignment. Take for example:}
\begin{verbatim}
< TAB >if (condition)
< TAB >< TAB >long_function_name(a, b, c,
< TAB >< TAB >< TAB >< TAB >....h, j, i);
\end{verbatim}
  \justificationf{where \code{< TAB >} is a tabulation and \code{.} is a
    whitespace. If the tabulation length is decreased, the code may look
    misaligned:}
\begin{verbatim}
<TAB>if (condition)
<TAB><TAB>long_function_name(a, b, c,
<TAB><TAB><TAB><TAB>....h, j, i);
\end{verbatim}
  \justificationf{where \code{h, j, i} is not properly placed. A clever
    solution is to use tabulations for block indentation and to use spaces for
    alignment:}
\begin{verbatim}
< TAB >if (condition)
< TAB >< TAB >long_function_name(a, b, c,
< TAB >< TAB >...................h, j, i);
\end{verbatim}
  \justificationf{In that configuration, the formatting will be fine whatever
    the tabulation length. Unfortunately, it seems that only Emacs and vi
    implement that formatting. In addition, the interaction between such a
    convention and the limit on the line length may be an issue. To conclude,
    the safest indentation strategy is to use spaces only, which any decent
    editor should handle:}
\begin{verbatim}
....if (condition)
........long_function_name(a, b, c,
...........................h, j, i);
\end{verbatim}
\item \rule{The indentation depth is four spaces.} \justification{The
    indentation depth is usually four spaces (like in GNU coding standards) or
    eight spaces (like in Linux kernel). In scientific computing, several
    indentation levels are commonly required---for example for loops in
    three-dimensional space. A eight-space indentation depth is not practical
    in that context.}
\item \rule{Do not put a useless semi-colon at the end of a block.}
  \commentcs{Only classes and structures declarations require a semi-colon after
    the closing brace.}
\end{cenumerate}

\paragraph{Comments and Documentation}
\label{sec:comm-docum}

\begin{cenumerate}
\item \rule{Use \code{//}, not \code{/*}, except for Doxygen comments.}
\item \rule{Include Doxygen comments for every class, every attribute, every
    method and every function.}
\item \rule{With respect to Doxygen comments of functions and methods:
    \begin{itemize}
    \item there must be a brief description, introduced by {\rm \code{//!}},
      or {\rm \code{$\backslash$*! $\backslash$brief}} if the description does
      not fit into a single line;
    \item there must be a description for every argument and for the returned
      value:
      \begin{itemize}
      \item only use {\rm \code{$\backslash$param[in]}}, {\rm
          \code{$\backslash$param[in,out]}} and {\rm
          \code{$\backslash${param[out]}}} to introduce the description for an
        argument;
      \item the description for an argument starts lowercase and ends with a
        dot;
      \item the description for a returned value starts with a capitalized
        word and ends with a dot.
      \end{itemize}
    \item a full description should also be added whenever necessary, just
      before the arguments description;
    \item any reference to an argument, say {\rm \code{x}}, should be
      introduced with the Doxygen command {\rm \code{$\backslash$a}}: {\rm
        \code{$\backslash$a x}}.
    \end{itemize}~}
    \commentcs{Template:}
\begin{frame_cpp}
//! Here comes the brief description.
/*! Here comes the long description, if needed.
  \param[in] x description of the first parameter. It may include several
  sentences on several lines.
  \param[in,out] value another parameter.
  \param[out] error true if and only if an error occurred.
*/
\end{frame_cpp}
  \commentf{Another template:}
\begin{frame_cpp}
/*! \brief Here goes a brief description that does not fit into a single
  line. */
/*! Here comes the long description, if any.
  \param[in] value description of the argument.
  \return The sign of \a value.
*/
\end{frame_cpp}
  \njustification{These rules ensure that the Doxygen documentation is
    complete and clean.}
\item \rule{Doxygen comments for functions and methods are put before the
    definition in the source file, not before the declaration in the header
    file.} \justification{Headers should be as light as possible so that one
    may browse them quickly.}
\item \rule{Doxygen comments for classes and attributes are put before their
    declarations, in the header file.} \commentcs{For attributes, the
    description is introduced by {\rm \code{//!}}, or {\rm
      \code{$\backslash$*! $\backslash$brief}} if it does not fit into a
    single line.} \justification{There is no other suitable place.}
\item \rule{The code may be organized in sections and subsections that are
    introduced as follows.}  \commentcs{Section:}
\begin{frame_cpp}
  <two blank lines>
  ////////////////////////
  // READS INPUT FIELDS //
  ////////////////////////
  <two blank lines>
\end{frame_cpp}
  \commentf{Long section (especially in libraries, with many functions in the
    section---otherwise prefer the previous format):}
\begin{frame_cpp}
  <two blank lines>
  ///////////////////////////
  // MATRIX FACTORIZATIONS //
  <two blank lines>
  [ code of the long section ]
  <two blank lines>
  // MATRIX FACTORIZATIONS //
  ///////////////////////////
  <two blank lines>
\end{frame_cpp}
\commentf{Heavy subsection:}
\begin{frame_cpp}
  <two blank lines>
  /****************
   * Binary files *
   ****************/
  <two blank lines>
\end{frame_cpp}
\commentf{Light subsection (prefer this to the heavy subsection, except if the
  subsection is long---you may then nest light subsections inside the heavy
  subsection):}
\begin{frame_cpp}
  <one blank line>
  /*** Binary files ***/
  <one blank line>
\end{frame_cpp}
\item \rule{Name spaces are inserted this way:}
\begin{frame_cpp}
<two blank lines>
namespace AtmoData
{
<two blank lines>
    [ code ]
<two blank lines>
} // namespace AtmoData.
<two blank lines>
\end{frame_cpp}
\end{cenumerate}

\paragraph{Lines}
\label{sec:lines}

\begin{cenumerate}
\item \rule{Only one statement should be put on a single line.}
  \commentcs{Write}
\begin{frame_cpp}
int j;
string line;
if (i == 5)
    cout << "Done." << endl;
\end{frame_cpp}
  \commentf{instead of}
\begin{frame_cpp}
int j; string line;
if (i == 5) cout << "Done." << endl;
\end{frame_cpp}
  \commentf{There should never be two semi-colons on the same line, except in
    \code{for} statements:}
\begin{frame_cpp}
for (i = 0; i < 10; i++)
    cout << i << endl;
\end{frame_cpp}
  \njustification{This usually makes the code clearer. It avoids misleading
    implementations like:}
\begin{frame_cpp}
if (i == 5)
    cout << "Done." << endl; i++;
\end{frame_cpp}
\item \rule{Functions and methods definitions should be separated by two blank
    lines.}  \justification{There should be more space between two functions
    than between two blocks in a function.}
\item \rule{A line should not contain strictly more than 78 characters.}
  \justification{This ensures that the code may be properly printed and that
    it could be displayed on a screen in text mode. Furthermore, one often
    needs to display two source files side by side. The differences between
    two files can also be displayed side by side.}
\item \rule{If you need to break a line that introduces the definition of a
    method, never separate the two colons \code{::} from the name of the
    method.} \commentcs{Write}
\begin{frame_cpp}
ClassName
::MethodName(...long argument list...)
\end{frame_cpp}
  \commentf{instead}
\begin{frame_cpp}
ClassName::
MethodName(...long argument list...)
\end{frame_cpp}
  \njustification{One often searches for the definition of a given method in a
    source file. With this rule, one can search for \code{::MethodName} (using
    the search ability of one's text editor) to quickly find the definition. A
    search for \code{MethodName} may be inefficient because there may be many
    calls to the method, at different places.}
\end{cenumerate}

\paragraph{Variable Definition}

\begin{cenumerate}
\item \rule{Do not systematically declare all variables at the beginning of a
    program or a function. Declare small bunches of variables instead.}
  \commentcs{Old languages require that all variables are declared at the very
    beginning. This is the reason why this convention is still in use, even in
    modern programming languages. It is good idea to declare at the beginning
    a few variables that will be used at many places in the current block,
    like an index \code{i}. Otherwise, declare the variables more locally.}
  \justification{A variable declaration should be close to the lines where it
    is used so that the programmer can easily access to this declaration and
    so that the scope of the variable can be restricted.}
\item \rule{Characters \code{*} and \code{\&} should be directly connected to
    the type, not the variable.} \commentcs{Write}
\begin{frame_cpp}
  int& i;
\end{frame_cpp}
\commentf{instead of}
\begin{frame_cpp}
  int &i;
\end{frame_cpp}
\njustification{In the previous example, the type of \code{i} is \code{int\&},
  and it should appear as such.}
\item \rule{Constants are declared with a {\rm \code{const}} statement, not
    with {\rm \code{\#define}} or so.}
\end{cenumerate}

\paragraph{Class Definition}

\begin{cenumerate}
\item \rule{All attributes should be protected ({\rm \code{protected}}).}
  \commentcs{Public attributes are a bad idea because there are really
    unsafe. If there are so many attributes that maintaining accessors is
    difficult, this rule might be broken. Private attributes can be fine, but
    they cannot be accessed by the derived classes, which is rarely a useful
    feature.} \justification{Attributes should be accessed and modified only
    with methods, so as to allow miscellaneous checks, and so as to guaranty
    at any time the consistency of the object.}
\item \rule{In a class definition, put, in this order:
    \begin{enumerate}
    \item the {\rm \code{typedef}} declarations;
    \item the attributes;
    \item the constructor(s);
    \item the destructor;
    \item the public methods;
    \item the protected methods;
    \item the private methods.
    \end{enumerate}In the source file, the definitions must follow the same
    order as the declarations in the header file.}
\item \rule{Provide constant methods ({\rm \code{const}}) whenever possible.}
  \justification{It makes the code safer, and such methods are compulsory to
    manipulate \code{const} objects.}
\item \rule{Declare a virtual destructor in case the class is derived and
    contains virtual methods.} \justification{If a pointer to an instance of a
    derived class is used, then } \code{delete} \justificationf{will only call
    the base destructor. In addition, some compilers will issue a warning.}
\end{cenumerate}

\paragraph{Another Rule}

\begin{cenumerate}
\item \rule{Floating-point numbers should always have a decimal point.}
  \commentcs{While manipulating floating-point numbers, write}
\begin{frame_cpp}
double x = 2.; // or 2.0
double y = 2. * x;
y = 1. + x / 3.;
\end{frame_cpp}
  \commentf{instead of}
\begin{frame_cpp}
double x = 2;
double y = 2 * x;
y = 1 + x / 3;
\end{frame_cpp}
  \njustification{It clearly shows what type of variable is manipulated. It
    can avoid mistakes like writing \code{2 / 3} (which is zero) instead of
    \code{2. / 3.} (which is of course not zero).}
\end{cenumerate}


\subsection{Files}
\label{sec:files}

\paragraph{General Rule}

\begin{cenumerate}
\item \rule{Definition shall never follow declaration. Put declarations in
    header files and definitions in source files. There must be a header file
    for any source file.}  \justification{First, a precompiled library can be
    built only if declarations and definitions have been split. Second, the
    contents of a library may be quickly browsed in its headers.}
\end{cenumerate}

\paragraph{Names}

\begin{cenumerate}
\item \rule{Extensions are {\rm \code{hpp}} or {\rm \code{hxx}} (for headers)
    and {\rm \code{cpp}} or {\rm \code{cxx}} (for sources). {\rm \code{*xx}}
    files should be used for libraries, exclusively.}  \justification{It is
    convenient to identify what is part of a software (to be compiled) and
    what is part of a library (to be included).}
\item \rule{For libraries, a header file and a source file should be
    associated to each class. Those files have the same name as the class and
    they match its case.}
\item \rule{The names of the directories and the names of the files to be
    compiled are lowercase with underscores to delimit the words.}
  \commentcs{Lower case is used for the files not part of the core library
    (\code{*.cpp}): examples, unit tests,~\ldots{}} \justification{Browsing
    the code from command line is easier with lowercase directory names, and
    it is consistent with Linux/Unix conventions. A file name of the core
    library should be the same as the class it implements (see above), but
    other files should be lowercase also for convenience and consistency with
    the environment.}
\end{cenumerate}

\paragraph{Includes}

\begin{cenumerate}
\item \rule{All library files must have include guards.}
\item \rule{Include guards must be in the form \code{\{library name (upper
      case)\}\_FILE\_\{file name with its full path in the library (upper
      case; slashes and the dot are replaced with an underscore)\}}.}
  \commentcs{Example: \code{SELDON\_FILE\_SHARE\_VIRTUALALLOCATOR\_HXX} for the
    file ``VirtualAllocator.hxx'' in directory ``share'' of the library
    Seldon.}
\item \rule{Include libraries of the C++ standard with \code{<} and \code{>},
    and other libraries with double quotes.} \commentcs{Example:}
\begin{frame_cpp}
#include <vector>
#include "Seldon.hxx"
\end{frame_cpp}
\end{cenumerate}


\subsection{About C++ Features}

\paragraph{Exceptions}

\begin{cenumerate}
\item \rule{Use exceptions to manage errors.} \justification{First, exception
    are in C++ precisely to manage errors. In old languages, one adds an
    integer to the arguments of all functions in order to track errors. This
    is difficult to maintain and it is dangerous because errors may be
    detected without further action. The other practice is to simply terminate
    the program (e.g., with \code{abort()}), but then the program cannot
    recover from the error.}
\item \rule{Do not use exception specifications.} \justification{It is a
    nightmare to keep these exception specifications up-to-date because of
    exceptions that may be thrown by nested functions.}
\item \rule{Check every memory allocation.} \commentcs{This is usually managed
    at a rather low level, in the libraries that provide the base structures.}
  \justification{If a memory allocation fails, a program should not keep
    running.}
\item \rule{Allow the user to mute error checking.} \commentcs{To achieve this,
    enclose any test and its throw statement by} \code{\#ifdef \{library name
    (upper case)\}\_DEBUG\_\{small description\}} \commentf{and}
  \code{\#endif}.  \commentf{Example:}
  \code{VERDANDI\_DEBUG\_CHECK\_DIMENSION} \justification{Some tests may
    result in significant overheads. For instance, in the access to an element
    of a vector, checking the validity of the index requires a significant
    amount of time compared to the access itself. The test may be very
    helpful, but one should be able to deactivate it.}
\end{cenumerate}

\paragraph{Templates}

\begin{cenumerate}
\item \rule{For scientific computing, always consider template functions: most
    functions should have the numerical type as template parameter.}
  \commentcs{Do not fear templates! They are really helpful to build generic
    codes while maintaining high performance.}  \justification{In scientific
    computing, the type of the underlying data may change: \code{float},
    \code{double}, \code{complex<float>}, \code{complex<double>} or even a
    user-defined class. In addition, one never perfectly predicts what will be
    the eventual use of one's code; for instance, parts of it may be reused in
    another context, with other data structures.}
\end{cenumerate}

\paragraph{C++ Standard}

\begin{cenumerate}
\item \rule{Build a fully standard-compliant code. If a compiler does not
    understand it, discard it or write the code it needs within a {\rm
      \code{\#define}}/{\rm \code{\#endif}} block.} \justification{This
    ensures portability and makes the code perennial.}
\item \rule{Do not use C features if they have been replaced by C++ features.}
  \commentcs{Even if C++ features do not always seem better at first sight,
    trust the designers of the C++ standard.} \justification{C++ features are
    better than their C equivalents, except that they might lead to overheads
    in a few cases.}
\end{cenumerate}


\subsection{Other Conventions}

\begin{cenumerate}
\item \rule{In a loop, the stopping test should use an inclusive lower-bound
    or an exclusive upper-bound.}  \commentcs{Example:}
\begin{frame_cpp}
  for (unsigned int i = 0; i < 50; i++)
\end{frame_cpp}
\end{cenumerate}


%%%%%%%%%%%%
%% PYTHON %%
%%%%%%%%%%%%


\section{Python}
\label{part:python}

\begin{cenumerate}
\item \rule{Tabulations are forbidden. They should be replaced with spaces.}
  \justification{In Python, the indentation is part of the language since it
    defines the blocks. If the indentation changes because of a varying
    tabulation length and a mixing of spaces and tabulations, the code
    changes. This is a risk nobody is willing to take.}
\item \rule{The indentation depth is four spaces.} \justification{Same as in
    C++, see section~\ref{sec:indentation-braces}.}
\item \rule{A line should not contain strictly more than 78 characters.}
  \justification{Same as in C++, see section~\ref{sec:lines}.}
\item \rule{Use Doxygen, with similar to conventions to those for C++---section~\ref{sec:comm-docum}.}
\end{cenumerate}

This part of the document should be completed later. Note that the conventions
should be similar to C++. The ``Style Guide for Python Code'', by Guido van
Rossum and Barry Warsaw, \url{http://www.python.org/dev/peps/pep-0008/},
should serve as a sound background.


%%%%%%%%%%%%%%%%%%%%%
%% OTHER LANGUAGES %%
%%%%%%%%%%%%%%%%%%%%%


\section{Other Languages}

\begin{cenumerate}
\item \rule{Only use a limited number of languages.} \commentcs{For instance,
    with C++ and Python, one can cover all needs: from low-level
    high-performance computing to high level programming (scripts, command
    line).}  \justification{It is better to fully understand a few languages
    than poorly using many languages. Moreover adding dependencies (to other
    languages and, as a consequence, to other compilers and libraries) may
    decrease the portability and may increase the installation difficulty.}
\item \rule{Try to follow the rules associated with C++.} \commentcs{In case you
    {\it really} need to use another language, C++ conventions should cover
    most features of this additional language.}
\end{cenumerate}




\bibliography{reference}
\bibliographystyle{plain}



\end{document}